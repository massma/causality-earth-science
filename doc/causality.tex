\documentclass[12pt]{article}
\input{def}
\graphicspath{{figs/}}

\begin{document}

\title{Causality for clarification: examples from Earth science}

\author{Adam Massmann\thanks{Corresponding author:
    akm2203@columbia.edu}, Pierre Gentine, Jakob Runge, Elias Bareinboim}

\maketitle
\begin{abstract}
  Use of causal methods is exploding in Earth science. However, most
  applications focus on causal discovery: inferring the causal
  relationships and structure from data. This paper looks at causality
  through a different lens and examines how causal graphs, a
  fundamental from causal theory, can be used to clarify assumptions,
  identify tractable problems, and aid interpretation of results in
  Earth science research. We apply causal theory to generic graphs of
  the Earth system to identify where causal inference may be most
  tractable in Earth science. Specifically, causal inference may be
  particularly tractable when: (1) the state space of the system is
  reconstructable from lagged observations of the system; or: (2) the
  effect of interest is only causally affected by the observed portion
  of the state space; or: (3) The cause of interest can be assumed to
  be independent of the evolution of the systemâ€™s state. However, we
  also highlight through examples that inclusion of a causal graph in
  any analysis improves communication of assumptions and helps to
  structure analyses, even if causal inference is ultimately
  impossible from the data available.
\end{abstract}

\section{Introduction}

The use of causal tools is booming across Earth science
\citep[e.g.,][]{ebert-uphoff2012,
  samarasinghe-casuality,runge-causal-timeseries,runge2019inferring,goodwell-causality-2020}. However,
most of the recent use has focused on causal discovery, or the
inference (using data) of causal structure: ``links'' and directions
between variables.

This paper looks at causality through a very different lens and
examines how causal graphs \citep{pearl1995causal}, a fundamental from
causal theory, can be used to clarify assumptions, identify tractable
problems, and aid interpretation of results in Earth science
research. Our goal is to distill \citep{olah2017} the basics of the
graphical approach to causality in a way that is relatable for Earth
scientists, hopefully motivating more widespread use and adoption of
causal graphs in service of organizing anlayses and communicating
assumptions. These tools are relevant now more than ever, as the
cornocpia of new data analysis tools have inevitable led to more
opaque results and barriers to the communication of assumptions.

Beyond their usefulness as communication tools, if certain conditions
are met causal graphs can be used to calculate, from data, the
generalized functional form of relationships between Earth science
variables. Ultimately, deriving generalized functional relationships
is a primary goal science. While we can derive functional
relationships between some variables a priori, there are many
relationships we do not know \citep[e.g., ecosystem scale water and
carbon fluxes][]{massmann-2019} - \textit{(PIERRE: any reviews you'd
  like to see cited on this?)}, or that we do know but are
computationally intractable to calculate \citep[e.g., clouds and
microophysics at the global scale][]{randall2003, gentine2018,
  zadra2018} . In these types of applications, causal graphs give us a
path toward new scientific knowledge: generalized functional
relationships that were inaccessible with traditional tools.

The main contribution of this paper is to demonstrate how causal
graphs, a fundamental tool of causal inference introduced in Section
\ref{sec:what-caus-caus}, can be used to communicate assumptions, organize analyses, and
ultimately improve scientific understanding. We want to emphasize that
almost any study could benefit from inclusion of a causal graph in
terms of communication and clarification, even if in the end the
results cannot be interpreted causally. Causal graphs also encorouge
us to think deeply in the intitial stages of analysis about project
goals and how the system is structured, and can identify infeasible
studies early in the research process (before time spend aquiting data
or building/running models), saving us time and minimizing the chance
of (unintentionally) flawed studies. These points require a fair bit
of background and discussion, so the paper is broken up into sections,
allowing the reader to pick those sections that are most relevant
given their background knowledge and interests:

\begin{itemize}
\item Section \ref{sec:what-caus-caus}: Introduce and discuss causal graphs within the
  general philosophy of causality.
\item Section \ref{sec:causal-graphs-pearls}: Using a simple relatable example we will explain
  the problem of confounding and how causal graphs can be used to
  isolate the functional mapping between interventions on some
  variable(s) to their effect on other variable(s).
\item Section \ref{sec:causal-graphs-as}: We draw on a past example
  from our own research that bennefits from inclusion of a causal
  graph, in terms of communicating assuptions, and organizing and
  justifying analyses.
\item Section \ref{sec:necess-cond-caus}: We turn to more generic
  examples of graphs that are generally constistent with a wide
  variety of systems in Earth science, to highlight some of the
  difficulties we confront when using causal inference in Earth
  science and how we may be able to overcome these challenges.
\end{itemize}

We hope that this paper will increase understanding of causal graphs
and encourage more use of causal fundamentals in applications. We
believe wider adoption will set us on a path towards scientific
clarity.

\section{What is causality?: the causal graph perspective and its
  usefulness in Earth science}\label{sec:what-caus-caus}

We view causality through the lens of causal graphs, as introduced in
\citet{pearl1995causal}, mostly because we believe causal graphs are
pragmatically useful in Earth science, rather than because of any
particular philosophical argument for causal graphs as the ``true''
definition of causality.

Causal graphs are directed acyclic graphs that encode our assumptions
about the causal dependencies of a system.  To make a causal graph, a
domain expert simply draws directed edges (i.e. arrows) from variables
that are causes to effects. In other words, to make a causal graph you
simply draw a picture (Figure \ref{fig:toy}). Causal graphs are useful
tools because they can be drawn by any domain expert with no required
knowledge of math or probability, but they also represent formal
mathematical objects. Specifically, underlying each causal graph are a
set of equations: each node corresponds to a generating function for
that variable. The function's inputs are all of the node's parents
(plus a random variability term, which we will discuss in Section
\ref{sec:causal-graphs-pearls}). Parents are the other nodes in the
graph that point to our node of interest (e.g., in the most simple
graph $X \to Y$; $X$ is a parent of $Y$). So in reality, drawing
arrows from ``causes'' to ``effects'' is synonymous with drawing
arrows from function inputs to generating functions.

In this way, drawing a causal graph is another way to visualize and
reason about a complicated system of equations, which is a powerful
tool for the Earth scientist: we deal with very complicated systems of
equations and welcome any tool that helps us understand and reason
about their behavior. In some cases we may know a priori (from
physics) the equations for a given function in a causal
graph. However, in practice we often either do not know all of the
functions \citep[e.g., plant stomata response to VPD]{massmann-2019},
or some functions are computationally intractable to compute
\citep[e.g., turbulence, moist convection, and cloud microphysics in
large scale models]{zadra2018}.. In these scenarios the benefits of
causal graphs are fully realized: based on the causal graph we can
calulate from data, using the \textit{do-}calculus
\citep{pearl-1994-do-calculus}, the functional relationship between
target variables (i.e. effects) and interventions on any other
variables in the graph (i.e. causes).

By viewing causal graphs through this pragmatic lens of calculating
the functional form for functions that we cannot calculate a priori,
we simultaneously identify causa graphs' value for Earth scientists
while also side stepping philosophical arguments about the meaning of
causality. In Earth science we often need to estimate how the system
responds to interventions. For example, for sub-grid parameterization
we need to estimate time tendancies' response to interventions on the
large scale state. We also may desire to calulate experiments: for
example how changing land cover from forest to grasslands affects the
statistics of surface temperature. \textit{do-}calculus provides a way
to calculate this reponse to interventions without relying on
approximate numerical models or (potentially in feasible or unethical)
real world experimentation. While we want to maintain this emphasis on
causality as a method for calculating generalized functional forms of
responses to intervention, for consistency with the causal literature
we will call the response variables ``effects'', and the intervened
upon variables ``causes''.

One might challenge: ``what about regression as a method as a simple
method to calculate functional relationships from data?'' However as
we will demonstate (Section \ref{sec:causal-graphs-pearls}, and as
many are aware), uninformed regression is just a functional mapping of
associations between variables, not the response to
interventions. This is the problem that \textit{do-}calculus solves:
it identifies whcih data are needed and how we can use those data to
calculate the functional mapping of interventions, rather than just
associactions that may be attributable to other processes
entirely. Because interventions generalize much better than
associacions, \textit{do-}calculus is especially relevant for
scientists and engineers. Working through an example will hopefully
clarify some of these claims.

\section{A Toy Example: the problem of confounding and the necessity
  of \textit{do-}calculus for calculating interventions}
\label{sec:causal-graphs-pearls}
% intro causal graphs}

We demonstrate the problem of confounding and the necessity of
\textit{do-}calculus we use a very simple toy example involving
clouds, aerosols, and surface solar radiation/sunlight (Figure
\ref{fig:toy}A). Our causal graph consists of:

\begin{figure}
  % % consider \noindent\include... [width=0.75\textwidth]...
  % \includegraphics[height=0.4\textheight]{cloud-aerosol-bidirected.pdf}\\
  \scalebox{1.0}{\input{figs/cloud-aerosol.tex}}
  \caption{A toy graph example to demonstrate basic causal theory,
    involving cloud (C), aerosol (A), and surface solar radiation
    (S). In \textbf{A)} we observe all variables, while in \textbf{B)}
    we do not observe aerosol and we use the semantic of a dashed node
    to denote the unobserved variable. \textbf{C)} presents an
    alternative notation for representing an unobserved or hidden
    common cause that is popular in causal literature \citep[e.g.,
    ``semi-markovian graphs'',][]{shpitser2006}. When using this
    notation it is common practice to only include observed processes
    as nodes in the graph. However in Earth Science we often observe
    much less of the system relative to our knowledge of causal
    dependencies in the system, so we find it more conceptually clear
    to include unobserved common causes explicitly in the graph, and
    prefer the notation in \textbf{B)} to \textbf{C}). Any
    semi-markovian graph can be represented as a graph with unobserved
    nodes, and vice-versa \citep[e.g.,][]{lee2019structural}.}
  \label{fig:toy}
\end{figure}

\begin{enumerate}
\item An edge from aerosols to clouds because aerosols serve as cloud
  condensation nuclei and affect the probability of water vapor
  conversion to cloud.
\item An edge from aerosols to surface solar radiation, because
  aerosols can reflect sunlight back to space and reduce sunlight
  at the surface.
\item An edge from clouds to sunlight, because clouds also reflect
  sunlight back to space and can reduce sunlight at the surface.
\end{enumerate}

Causal graphs encode our assumptions about how the system behaves, and
the nodes and edges that are \textit{missing} from the graph often
represent strong assumptions. For example, in the
cloud-aerosol-sunlight example, clouds also affect aerosols; e.g., by
increasing the likelihood that aerosol will be scavenged from the
atmosphere during precipitation \citep[e.g.,][]{radke-scavenge-1980,
  jurado2008, blanco-alegre2018}. By not including an edge from
cloud to aerosol, we are making a strong assumption that we are
ignoring the effect of clouds on aerosols. Considering this example is
intended to be pedagogical for introducing causal theory to the
readers, we will continue with the graph as drawn in Figure
\ref{fig:toy} (Section \ref{sec:necess-cond-caus} explores realistic
Earth system graphs).

Even though mathematical reasoning is not required to construct a
causal graph, the resulting graph encodes specific mathematical
meaning. For example, the graph corresponds to a set fo underlying
functions for each variable:

\begin{align}
  \label{eq:2}
  aerosol &= f(U_{aerosol}) \\
  cloud &= f(aerosol, U_{cloud})\\
  sunlight &= f(aerosol, cloud, U_{sunlight})
\end{align}

where $U$ are random variables due to all the factors not represented
explicitly in the causal graph, and $f$ are deterministic functions
that generate each variable in the graph from their parents and
corresponding $U$.

The presence of the random variables $U$ introduce
a third meaning to the causal graph: they induce a specific
factorization of the joint distrition of the variables into
conditional and marginal facotors:

\begin{equation}
  P(A, C, S) = P(S \, | \,C, A) \, P(C \, | \, A) \, P(A),
\end{equation}

where $A$ represents aerosol, $C$ represents cloud, $S$ represents
surface sunlight/solar radiation, and $P(\cdot | \cdot)$ denotes
conditional probability (Appendix \ref{prob-theory} describes the
notation used in this paper and a brief introduction to probability
theory for unfamiliar readers). The inclusion of randomness in causal
graphs is a powerful tool: by positing a causal graph, we are not
stating that the variables in the graph are the only processes in the
system. Instead, we are stating that all other processes not included
in the graph induce variations in the graph's variables that are
independent of each other (e.g., all $U_{\cdot}$ in Equation
(\ref{eq:2}) are independent). For example, sources of aerosol
variability not considered in Figure \ref{fig:toy}A include
anthropogenic aerosol emission, the biosphere, fires, volcanoes,
etc. \citep[e.g.,][]{Boucher2015}. For cloud, this includes synoptic
forcing, atmospheric humidity,
etc. \citep[e.g.,][]{wallace2006atmospheric}. For radiation, this
includes variability of top of atmosphere radiation,
etc. \citep[e.g.,][]{hartmann2015global}. Figure \ref{fig:toy}A states
that all these external, or \textit{exogenous}, sources of variability
are independent of each other (in very technical terms, this means the
graph is ``\textit{Markovian}'').

We can apply causal graph theory
\citep[e.g.,][]{pearl1995causal,shpitser2006} to the assumptions
encoded in our causal graph to identify which distributions must be
estimated from data in order to calculate the response of effect(s)
(e.g. of sunlight) to an experimental intervention on the cause(s)
(e.g. presence or absence of a cloud). The challenge of causal
inference is to derive the response to the intervention in terms of
only observed distributions. This process of identifying the necessary
observed distributions is formally termed \emph{causal
  identification}. If a causal effect is not identifiable
(\emph{un}-identifiable), for example if calculating a causal effect
requires distributions of variables that we do not observe, then we
cannot use causal inference to calculate a causal effect, even with an
infinite sample of data.

% backdoor path}

A necessary condition for unidentifiability is the presence of an
unblocked backdoor path from cause to effect. Backdoor paths are any
paths going through parents of the cause to the effect. We can block
these paths by selectively observing variables such that no
information passes through them \citep{geiger-d-sep}. If we can
observe variables along the backdoor paths such that they are blocked,
then we have satisfied the \emph{back-door criterion}
\citep{pearl2009} and we can calculate unbiased causal effects from
data.

\begin{figure}
  \input{figs/mutilated-cloud-aerosol.tex}
  \caption{A mutilation of Figure \ref{fig:toy}(A), where we have
    removed directed causal paths from the cause (cloud) to the effect
    (surface solar radiation). There is covariability between cloud
    and surface solar radiation that is not due to the causal
    connection between cloud and surface solar radiation, but is
    instead due to aerosol's role as a common driver.}
  \label{fig:mutilated-toy}
\end{figure}

% backdoor path with example}
Understanding backdoor paths and the backdoor criterion is helped by
example. Returning to our toy example (Figure \ref{fig:toy}A), we
attempt to calculate the causal effect of clouds on sunlight. In other
words, we want to isolate the variability of sunlight due to the
causal link from cloud to sunlight (Figure \ref{fig:toy}A). However,
aerosols affect both cloud and sunlight, so if we naively calculate a
causal effect using correlations between sunlight and cloud, we would
get a biased estimate. To demonstrate this, consider simulated cloud,
aerosol, and sunlight data from a set of underlying equations
consistent with Figure \ref{fig:toy}A and Equation (\ref{eq:2}):


\begin{align}
  aerosol =& \; U_{aerosol}; \; U_{aerosol} \sim \text{uniform (0, 1]}\\
  cloud =& \; \text{Cloudy if } U_{cloud} + aerosol > 1; \;
           U_{cloud} \sim \text{uniform (0, 1]}\\
  sunlight =& \begin{cases}
    \text{Cloudy} &: 0.6 \cdot \text{downwelling clear sky radiation}  \\
    \text{Clear} &: \text{downwelling clear sky radiation}
  \end{cases}
                   \label{eq:1}
\end{align}

where:

\begin{equation*}
  \text{downwelling clear sky radiation} = U_{sunlight} \cdot (1 - aerosol); \;
  U_{sunlight} \sim \text{Normal(340 W m$^{-2}$, 30 \, W m$^{-2}$)}
\end{equation*}

Now, consider not knowing the underlying generative processes, but
instead just passively observing cloud and sunlight. If one were
interested in calculating the effect of cloud on sunlight, and aerosol
data were not available or one were very naive, one approach would be
to bin the data by cloudy and clear conditions and compare the amount
of sunlight between cloudy and clear observations (Figure
\ref{fig:naive-cloud-sunlight}). This approach suggests that clouds
reduce sunlight by, on average, 160 W m$^{-2}$; this is is a strong
overestimation of the true average effect of clouds (-68 W m$^{-2}$),
derived from Equation (\ref{eq:1}). Aerosol induces co-variability
between cloud and sunlight that is unrelated to the causal link from
cloud to sunlight. Graphically, this is clarified by removing all
edges from our cause (cloud) to children of our cause (in this case
sunlight) to create a ``mutilated'' graph (Figure
\ref{fig:mutilated-toy}). By ``mutilated'', we mean that the new graph
deviates from reality, in this case by breaking all causal paths from
our cause to our effect. We see that in this mulilated graph clouds
are not independent of surface solar radiation in the mutilated graph;
aerosol induces variability in both cloud and surface solar radiation
that is unrelated to causal paths.  However if aerosol were fixed
(e.g. observed or not varying), cloud and sunlight would be
independent of each other in the multiated graph (Figure
\ref{fig:mutilated-toy}). In other words, conditional on aerosol,
cloud and sunlight are independent in the mutilated graph (Figure
\ref{fig:mutilated-toy}), which does not include the causal path from
cloud to sunlight. And, conditional on aerosol in the true system
(Figure \ref{fig:toy}(A)), all co-variability between cloud and
sunlight is only due to the causal edge between cloud and sunlight.
We can mathematically incorporate the requirement that we must
condition on aerosol to isolate the causal effect of cloud on
radiation. Doing so gives the identification of the causal effect of
cloud and aerosol and satisfies the backdoor criterion with
\textit{adjustment} on aerosol:

\begin{figure}
  \includegraphics[]{naiveCloudSunlight.pdf}
  \caption{A naive approach to estimating the ``effect'' of clouds on
    sunlight: bin observations by cloudy and clear day, and compare
    the values of sunlight. This approach yields an average difference
    of 160.43 W m$^{-2}$ between cloudy and clear days, and is a large
    overestimation of the true causal effect of clouds on sunlight
    (-68.0 W m$^{-2}$) in this synthetic dataset.}
  \label{fig:naive-cloud-sunlight}
\end{figure}

\begin{equation}
  P(S | do(C = c)) = \int_{a} P(S \, | \, C = c,
  A=a) \, P(A=a) \; da,
  \label{eq:3}
\end{equation}

where the \textit{do}-calculus \citep{pearl2009} term
($P(S \, | \, do(C\, = \,c))$) represents the probability of sunlight
if we did an experiment where we intervened and set cloud to a value
of our choosing (in this case $c$, which could be ``True'' for the
presence of a cloud, or ``False'' for no cloud). In the case that
observations of aerosols are not available (e.g., Figure
\ref{fig:toy}B, C), our causal effect is not identifiable and we
cannot use causal inference no matter how large the sample size of our
data. This is a powerful research tool: after encoding our domain
knowledge in a causal graph, we can analyze the causal graph and
available observations to determine whether a causal calculation is
possible, \textit{without needing to collect, download, or manipulate
  any data}. For more complicated graphs, causal identification can be
automated \citep{shpitser2006}. We later use this theory to
theoretically assess which general problems are tractable in Earth
science using causal inference (Section \ref{sec:necess-cond-caus}).

Once we have established that a causal effect is identifiable from
data, we must estimate the required observational distributions
(Equation (\ref{eq:3})) from data. Often it may be more computationally
tractable to calculate an average causal effect, rather than the full
causal distribution $P(S | do(C=c))$. Returning to our toy example
(Figure \ref{fig:toy}(A)), the average effect is defined as:

\begin{equation}
  \mathbb{E}(S | do(C = c)) = \int_{s} s \, P(S = s
  | do(C=c)) \, ds,
  \label{eq:4}
\end{equation}

where $\mathbb{E}$ is the expected value. Substituting Equation
(\ref{eq:3}) into Equation (\ref{eq:4}), and rearranging gives:

\begin{equation}
  \mathbb{E}(S | do(C = c))  = \int_{a} P(A=a) \; \mathbb{E}(S \, | \,
  C=c, A=a) \, d a,
  \label{eq:5}
\end{equation}

Where $\mathbb{E}(S \, | \, C=c, A=a)$ is just a regression of sunlight on
cloud and aerosol. Estimating the marginal $P(A)$ is difficult, but
if we assume that our observations are independent and identically
distributed (IID) and we have a large enough sample, we can use the
law of large numbers to approximate Equation (\ref{eq:5}). The law of
large numbers states that if we observe $n$ IID samples of some process, in
this case $A$ (e.g., $a_1$, $a_2$, $\ldots$, $a_n$), then for any
function $f$ \citep{shalizi2013}:

\begin{equation}
  \frac{1}{n} \sum_{i=1}^n f(a_i) \to \int_a P(A=a) f(a) \, d a.
  \label{eq:lln}
\end{equation}

In Equation (\ref{eq:5}), $c$ is fixed by the intervention, so
$\mathbb{E}(S| C=c, A=a)$ is just a function of $a$, and we can use
Equation (\ref{eq:lln}) to justify an approximation to Equation
(\ref{eq:5}) with:

\begin{equation}
  \mathbb{E}(S | do(C = c))  \approx \frac{1}{n} \sum_{i=1}^n
  \mathbb{E}(S \, | \,
  C=c, A=a_i).
  \label{eq:6}
\end{equation}

Data or prior knowledge can inform the regression function for
$\mathbb{E}(S | C=c, A=a_i)$, and as always whatever regression method
is used, it should be checked to insure it is representative of the
data. In the toy example, a linear model conditional on cloud appears
to be a good choice of regression function (Figure
\ref{fig:linear})\footnote{However note that for most real problems in
  Earth science, we probably want to use some type of non linear
  regression (neural networks could be well suited to this
  task).}. The causal effect of clouds on sunlight as calculated using
Equation (\ref{eq:6})) (e.g.
$\mathbb{E}(S | do(C = \text{cloudy})) - \mathbb{E}(S | do(C =
\text{clear}))$) is -67.69 W m$^{-2}$, which closely matches the true
causal effect from Equation (\ref{eq:1}) of -68 W m$^{-2}$. This
example demonstrates how causal inference and theory can be used to
calculate unbiased average effects using regression. Further, causal
inference can be used to justify and communicate assumptions in any
observational analyses employing regression. In the best case, the
causal effect is identifiable from the available observations, and the
regression analysis can be framed as an average causal effect. In the
worst case that identification is not possible from the available
observations, one may present the regression as observed associations
between variables. However, presentation of a causal graph still aids
the reader: the reader can see from the causal graph what the
confounders and unobserved sources of covariability are between the
predictors and the output. In all cases, the presentation of a causal
graph makes explicit the assumptions about the causal dependencies of
the system. Wherever possible, we recommend including causal graphs
with any observation-based analyses.

In summary of the main points of this introduction to causal graphical
models and \textit{do-}calculus:

\begin{itemize}
\item Graphical causal models encode our assumptions about causal
  dependencies in a system (edges are drawn \emph{from} causes
  \emph{to} effects). ``Causal dependencies'' really just refer to
  functional dependencies between inputs (causes) and outputs
  (effect), which are useful in physical sciences.
\item In order to calculate an unbiased causal effect from data, we
  must isolate the covariability between cause and effect that is due
  to the directed causal path from cause to effect. The presence of
  non-causal dependencies between the cause and effect can be deduced
  from the causal graph: the presence of an unblocked backdoor path
  from the cause to the effect leads to non-causal dependencies (and
  co-variation).
\item The backdoor criterion identifies the distributions we must
  calculate from data in order to block all backdoor paths, remove
  non-causal dependence between the cause and effect, and calculate an
  unbiased causal effect from data.
\item The \emph{average} causal effect can be reliably approximated
  with regression (Equation (\ref{eq:6})) derived from the backdoor
  criterion. In this scenario, causal theory and graphs identify the
  variables that should (and should not be) included in the regression
  in order to calculate an unbiased causal effect.
\item Causal identification is a flexible tool that provides the
  distributions that must be estimated from data, while making no
  assumptions about the forms of those distributions. However,
  parametric assumptions can be applied to make the calculation of
  those distributions from data more computationally tractable.
\end{itemize}

\begin{figure}
  \includegraphics[]{aerosolSunlight.pdf}
  \caption{A linear relationship between aerosol and sunlight,
    conditional on cloud. If we use linear regression to calculate the
    average causal effect of cloud on sunlight, as in Equation
    (\ref{eq:6}), our result is very close to the true causal effect
    of -68.0 W m$^{-2}$.}
  \label{fig:linear}
\end{figure}

Here we focused on the backdoor criterion to block backdoor paths. An
un-blockable backdoor path from the cause to the effect is a necessary
condition for unidentifiability. However, it is not sufficient
(e.g. there are other identification strategies like the front door
criterion and instrumental variables that do not rely on observing
variables along the backdoor path). For a complete discussion of
sufficient conditions for unidentifiability we refer you to
\citet{shpitser2006}. For the purpose of identifying generally
tractable causal inference approaches in Earth science (Section
\ref{sec:necess-cond-caus}), we focus the backdoor criterion. Given
that the Earth system evolves continuously according to an underlying
dynamical system and we only partially observe the state space in both
space and time, these other identification strategies are not as
applicable, and an unblockable backdoor path is a sufficient condition
for unidentifiability in the types of graphs that are representative
of Earth science systems (Figure \ref{fig:generic})
\citep{tian2002general}. In other words, blocking backdoor paths is a
requirement for calculating a causal effect in graphs of the form
presented in Figure \ref{fig:generic}. REWORK THIS TO SAY SOMETHING
ABOUT OTHER FORMS, NOT FOCUS SO MUCH ON THE GENERIC GRAPH, AND
RECOMMEND CAUSL FUSION.

\section{Causal graphs as communicators, organizers, and time-savers}\label{sec:causal-graphs-as}

In Section \ref{sec:causal-graphs-pearls} we used a toy example to go
through a full causal analysis from drawing the graph, to calculating
the average response of sunlight (the effect) to an intervention on
cloud (the cause). However, often we may not be able to estimate the
causal effects from the available data, as there are serious
challenges with unobserved confounding in generic Earth science
problems (Section \ref{sec:necess-cond-caus}). We want to emphasize,
even if we cannot follow all the way through to calculating
successfully calcualting an interventional effect for our problem of
interest, drawing a causal graph at the beginning of the analysis, and
including it the disemination of results can pay huge dividents in
terms of organization, saving us time, preventing us from
unintentionally executing flawed studiess, and comunicating our
results. Drawing the causal graph at the beginning of the analysis is
not easy: it takes time and deep thought. But, this is thought that
will need to be done at some point in the analysis: we will need some
forumlation in our brain of how the system behaves and what are the
functional dependencies between processes in the system. Making these
dependencies explicit at the beginning of the analysis forces us to
clarify our thinking, exposing factors and potential problems that we
may not have realized until much later (or never) if we do not do the
deep thinking up front. If we realize issues much later, we will have
wasted a lot of time building a flawed analysis (e.g. downloading
data, running models). If we never realize the issues, then we
introduced confusion into the literature. So the causal graph is both
an organizer for scientific analysis, and because we can draw it at
the beginning of the analysis, it is a time-saver preventing us from
unwittingly investing in flawed analyses.

Once we have drawn a causal graph, there is no cost to including in in
presentations, papers, and discussions of our results. Making our
assumptions about dependencies in the system explicit greatly improves
the interpretability of our results. Perhaps our analysis and graph
meets the standards for a causal interpretation, but even if it does
not, the causal graph still helps the rest of the community asses the
sources of confounding in teh graph that were not controlled for, and
understand if their conceptualizzation of how the graph is structured
matches the author's assumptions (for rearch without a causal graph,
it is difficult to diagnose if we and the authors even view the system
in the same light).

To support the idea that many analysis would benefit from a causal
graph, we will detail how a past project benefits from a causal
graph. This example also moves beyond the toy example of Section
\ref{sec:causal-graphs-pearls}), and demonstrats causal graphs'
applicability to real problems in Earth science.

\subsection{An example from our past}

In \citet{massmann2017}, the lead author of this paper (Adam)
participated in a field campaign designed to study the impact of
microphysical rain regime (specifically the presence of ice from aloft
falling into orographic clouds) on orographic enhancement of
precipitation. This field campaign and analysis benefits from a causal
graph, and is a nice real example argument for the more common use of
causal graphs are research tools. Our retrospective causal graph of
orographic enhancement in the Nahuelbuta mountains under steady
conditions clearly communicates our assumptions about the system
(Figure \ref{fig:ccope}).

\begin{figure}
  \includegraphics[]{ccope.pdf}
  \caption{A graph representing steady conditions for orographic
    enhancement during the Chilean Coastal Orographic Precipitation
    Experiment \citep[CCOPE,][]{massmann2017}. We were interested in
    the effect of ``rain regime'' on ``orographic enhacement.''
    Observed quantites are represented by solid nodes, while
    unobserved quatnties are represented by dashed nodes. All backdoor
    paths are blocked by observed quantities, so the effect of rain
    regime on orographic enahcement is identifiable.}
  \label{fig:ccope}
\end{figure}

A few things to highlight about the graph: many of the variables are
quite general (and even vague) quantities. This can be a useful tool
for communicating assumptions, and we recommend startng with more
general/vague quantities. If logic needs clarifying, the graph can
become more explit (e.g., differentiating wind into speed, direction,
and spatial distribution, both horizontally and vertically). However
the more general graph approaches often yield more intuitive and
interpretable graphs, and are generally easier to reason about and
manage. ``Wind'', ``stability'', and ``atmospheric moisture'' all
refer to upwind conditions and we assume that these upwind conditions
are the relevant ``boundary condition'' for the downwind orographic
clouds and precipitation. These assumptions are encoded in the graph:
for example, if ``wind'' referred to the three dimensional distrubtion
of wind over the entire domain, then terrain would have to affect wind
as well.

BELOW TOO DETAILED?

An important assumption in this field campaign is that ``synoptic
forcing'' variability operates at larger horizontal spatial scales
(e.g., O(100km)) than the horizontal spatial scales over which the
orography influences physics and kinematics (O(10 km)). This allows us
to assume that upwind ``orographically unaffected'' observations of
synoptic quantities are relatively constant across the mountain
range. So, upwind observations of precipitation at our island and
coastal sites can be thought of as representative of background
``synoptic rain'' across the mountain network. If we define
``orographic enhacement'' as the difference between our mountain sites
and our coastal sites, then orographic enhancement is not directly
affected by synoptic forcing (e.g., we have ``subtracted'' the
synoptic rain out of our orographic metric).

It might be unclear why we are digressing into this discussion of the
choice of orographic enahcement metric: but the importance of this
choice is illuminated by the causal graph. When writing the paper, we
focused on ``orographic difference'' (``mountain sites'' minus
``upwind sites'') as the orographc enahcement metric that should be
used. However, it is common in mountain weatehr research to define
orographic enhacement in terms of the ``orographic ratio'', or the
ratio of mountain sites to upwind sites. Intuitively we felt that the
orographic precipitation metric should be invariant to changes in
background precipitation, which is true for ``orographic difference''
but false for ``orographic ratio.'' However, the causal graph makes
the argument for ``orographic difference'' clear and mathematically
explicit (supporting the ``intuitive'' description). If synoptic
forcing directly impacts our orographic enhacement metric, as is the
case for the ``orographic ratio'', then our causal graph would need an
additional edge from ``synoptic forcing'' to ``orographic
enhancement.'' Because we do not observe ``synoptic forcing'', this
would open up a backdoor path between ``rain regime'' and ``orographic
enhancement,'' so any estimate of the influence of rain regime on
orographic enahcement would be biased. The choice of orographic
enhacement metric matters, because it changes our graph from one where
the effect of interest is identifiable (``orographic difference'') to
one where it is unidenifiable (``orographic ratio''). If we used
orographic ratio, our estimate of warm rain's impact on orographic
enahcement would likely be biased very high: decreased synoptic
forcing decreases the chance of ice falling into orographic clouds
(increasing the likelihood of ``warm rain''), while also decreasing
upwind precipitation (which non-linearly increases the orographic
ratio, up to infinity as it approaches zero). We would falsley
attribute synoptic forcing's effect on orographic ratio to rain
regime. This example shows how causal graphs can provide clear and strong
evidence supporting ideas we ``intuitively know.''

However, perhaps the biggest advantage of including a causal graph in
the CCOPE case would have been in the funding stage. One of the
challenges of the CCOPE field campaign is that the campaign's
designers, Justin Minder, Rene Garreaud, Jefferson Snider, and David
Kingsmill were trying to do it on a relatively small budget. So, there
was no budget for traditional atmospheric field campaign tools like
scanning radars or aircraft that could measure the three dimensional
distribution of clouds, rain, aerosols, and help quantify important
quantites like ``synoptic forcing'' and ``orographic ascent.''
Instead, they proposed using upwind radiosondes to measure wind,
stability, and atmospheric moisture, and a coastal ground based
station to observe aerosol distribution. By assuming that these
measrurements are sufficiently representative of the ``upwind boundary
condition'' for orographic enhacement over the Nahuelbuta, they were
able to observe enough variables to identify the effect of rain regime
on orographic enhacement (Figure \ref{fig:ccope}). Given the PIs'
experience and thoughtfulness it is no suprise that the field campaign
design yeilded an idenifiable effect. However, inclusion of a causal
graph like Figure \ref{fig:ccope} communicates to proposal reviewers
the assumptions about the systems behavior, and very clearly
demonsrtates that the proposed observation plan allows us to calculate
the effect of interest given the rigorous framework of
\textit{do-}calculus. In other words, the causal graph thoretically
proves in some sense that the proposed field campaign is sound. Even
before writing the proposal, we could start with drawing a causal
graph, and then analyze the graph to determine which variables would
need to be observed in order to identify the effect of interest. If we
label each node in the graph with the cost of observation (from zero
to infinity), we can automatically determine the set of observations
that minimizes cost while still allowing us to calculate our effect of
interest. This analysis communicates to proposal reviewers that we
have rigorously optimized to minimize cost while still tractably
calculing our causal effect.

TODO: REWRITE BELOW, maybe cutting it out completely

The last important piece of this example is that many other mountain
weather experts may disagree with the causal graph we draw. In our
estimation, this is a good thing - we cannot disagree about things
that we do not know, and we believe that everyone has in their head
some notion of how the system behaves, and making that idea explicit
in a causal graph and allowing ourselves to reconcile that idea with
other's ideas (even if is through disagreement) is a good thing. The
thing we shoudl fear more than disagreement is confusion: and nothing
is more confusing than two researchers who think of a system in a
completely different way, trying to have a discussion about results
based on that system, without any knowledge that they fundamentally
believe in different structures to the system. Clearing up and
conciling differences in how we view dpendencies of a system seems to
be a productive prerequisite to reconciling contradictory results.

Just one last note - this causal graph would have also benefited the
layout and plan of analysis of the data. The paper itself ended up
being a bit add hoc in how it approached ``controlling'' for wind,
stability, and atmopsheric moisture, mostly just observing if there
are any differences in those quatnties between the two rain
regimes. Part of this was due to a lack of large sample sizes. But,
had we included the causal graph, I thinkwe could have presented a
statistical analysis that was much more clear and motivated by the
graph itself. Also, the small sample size itself is a common problem,
and can be overcome with ``shoe leather'' as David A. Freedman
recommends in his excellent (but at times overly scathing) critizim of
causal infference in the social sciences
(\cite{freedman2010statistical}). However Freedman argues against
causal graphs because on the grounds that we rarely have strong
apriori knowledge of the causal structure of systems of
interset. While this is likely true for the social sciences, in the
physical sciences we usually do have strong apriori knowledge, as
Figure \ref{fig:ccope} demonstrates. Additionally, Freedman misses the
organizational and conceptual benfits of causal graphs, even for
analyses were ``formal'' causal effects are not actually cacluclated:
they can be sueful for communicating assumptions and organzing
analyses. In some ways with CCOPE we did use the shoe leatehr
approach: we identified negligbley small differences in wind,
stability, and atmospheric moisture, and used that logic to suggest
that most of the observed differences in orogrpahic enahcement were
due to rain regime. However, the causal graph would have aided the
communication and focus of that shoe leather work. Also, because not
everythign goes to plan, we ended up hafving trouble with our aerosol
equipment, so that was a possible (unknwon) source of confoudning that
would have been made more clear with icnlsuion of the causal graph.

Which is all a long way to say the causal graphs are useful, they
force us to do a lot of the ``heavy thinking'' up front of our
analysis, which prevent us from wasting a bunch of time and resources
on more mundane research procedures like downloading or collecting
data, and running big, complicated numerical model. With the heavy
thinking done up front and the causal graph already made, we can then
use it to help communicate our results and structure our analysis
(e.g., motivate why we are doing regression, why we are includign the
variables we are in regression, etc.).

\subsection{Summary}

TODO: rewrite below?

This is one example: but the complexity and structure of causal graphs
will vary by field. Again, we think drawing the graph early will help
clarify and make explicit assumptions (both for ourselves, and also
for the rest fo the communication), and can help identify flawed or
intractable studies early in the research process. Causal graphs can
also be used as communication tools for very complicated
spatiotemproatl systems, including climate models, etc. They offer a
path to understanding and visualizing inherent assumptions in any
system (for a climate model: what are invariants; what are the inputs
into subgrid parameterizations?). Some of these graphs might be too
hard to visualize on printed papers, but researchers can link to and
use interactive visualization software to examine compilcated
graphs. Another sueful tool for visualizing complicated graphs are
plates \citep{bishop2006pattern}, which can represent repeated
structure like we often get in spatiotemporal systems. Additionally,
as we will see in the next section, we can draw quite general graphs
that are reprentative of many problems in Earth science.


\section{Overcoming unobserved confounding: tractable classes of
  problems in generic Earth systems}
\label{sec:necess-cond-caus}

So far we have focused on toy examples, and the utlity of causal
graphs as a communication and organziational tool. However, many may
want to apply a ``full causal analysis'' to an Earth science problem,
so it is useful to examine what common issues we may need encounter,
and how we can overcome them in generic Earth science systems.

Earth science systems are dynamical systems evolving through time
according to an underlying system state
\citep{lorenz-1963,lorenz1996predictability,majda-state}. This offers
both advantages and challenges for causal inference. When constructing
causal graphs we benefit from the temporal ordering of events: we know
that future events can have no causal effect on the past. However,
confounding due to incomplete observation of the system's state space
introduces challenges\footnote{Note that incomplete observation of the
  system precludes many ``causal discovery'' algorithms \citep[see ][
  for a great review]{runge2019inferring}. This paper focuses on a
  graphical approach to calculaing funcitonal relationships between
  causes and effects, but it is noteworthy that incomplete observation
  also leads to the invalidation of many assumptions in causal
  discovery.}

Causal identification and tractable causal inference to Earth science
requires assumptions about the unobserved portions of the state
space. Without such assumptions the unobserved portions of the state
space will introduce confounding for any causal affect of interest
(Figure \ref{fig:generic}a). For example, we generally do not observe
the state space at every time (e.g. $S(t-1/2)$ in Figure
\ref{fig:generic}a), and at any given time, we do not observe the
state space at all locations and for all state variables (e.g. $S(t)$
and $S(t-1)$ in Figure \ref{fig:generic}a). So, if we are interested
in the causal effect of any state variable at time $t$ on some
variable at time $t+1$ (e.g., $E$ in Figure \ref{fig:generic}a), then
the causal effect will be confounded by the unobserved portions of the
state space, and calculating a causal effect is impossible
(un-identifiable) without additional assumptions. We will apply causal
graph theory to identify the additional assumptions that would make
the calculations of causal effects tractable, and may be reasonable in
many Earth science situations.

\begin{figure}
  \input{figs/generic-graph.tex}
  \caption{Generic graphs of the Earth system state sequence, limited
    to a 3 time sequence subset of the infinite sequence. \textbf{A):}
    The reality of the observed earth system: unobserved nodes are
    outlined by dashed lines. We only observe the state space at
    certain times (e.g., no observations at $S(t-1/2)$). At times with
    observations, we only partially observe the full state ($S(t)$,
    $S(t-1)$). In the scenario that we are interested in calculating
    the causal effect of any portion of the state space at time $t$ on
    some effect ($E$) at time $t+1$, the causal effect will be
    confounded by the unobserved portions of the state space, and
    calculating the causal effect is impossible (un-identifiable)
    without additional assumptions. \textbf{B):} The reduction of the
    earth system graph under an assumption that we can reconstruct the
    state $S(t)$ from the observable portions of the state space at
    lagged times $< t$ (see Section
    \ref{sec:stat-reconstr-state}). \textbf{C):} The reduction of the
    earth system graph under an assumption that missing temporal
    observations (e.g. $S(t-1/2)$ in \textbf{A)}) induce independent
    random variations in the cause ($C(t)$) and effect
    ($E(t+1)$). $S'(t)$ denotes the state space, not including the
    cause $C(t)$ (see Sections
    \ref{sec:miss-temp-observ},\ref{sec:observ-port-state}).}
  \label{fig:generic}
\end{figure}

\subsection{Statistical reconstruction of the state space with time
  lagged observations}
\label{sec:stat-reconstr-state}

Takens' theorem implies that we can reconstruct the unobserved
portions of the state space using lagged observations back in time
\citep{takens1981detecting,deyle2011generalized,Sugihara496}. In this
case, the causal graph is greatly simplified (Figure
\ref{fig:generic}b). If we assume that the state is reconstructable,
then we can calculate the causal effect of any reconstructed state on
any future variable or process. The primary advantages of this
approach is that it is the minimum assumption required to calculate a
causal effect in the generic Earth system graph proposed in Figure
\ref{fig:generic}a. However this simplification comes at a cost: we
can only examine the effect of different global states on future
variables, and we cannot examine the causal effect of a specific
variable (e.g. $C(t)$) on another (e.g. $E(t+1)$), because the mapping
from individual observations to a state space reconstruction
transforms the individual observation's importance to additionally
include the unknowable and unobserved portions of the state space. So,
an intervention on any individual observation is of ambiguous meaning
(e.g. we do not know what are the unobserved variables we are
intervening on). Instead, we limit ourselves to only examining the
causal effect of changes in the entire state
holistically. Additionally, this approach requires a shift in
interpretation from the relatively straightforward interventions on
observable variables we have considered thus far to one where we
intervene on the entire state.

For example, consider that we reconstructed our state space from
available observations, and this reconstruction reduced to a discrete
state space of $N$ states, with associated patterns in the observations
at time $\leq t$. If we are interested in the effect of a change in
state on a process at time $t+1$, for example a change from state $1$
to state $2$, this corresponds to an intervention on the
\textit{entire state space at time $t$}. This includes the unobserved
portions of the state space. So, the intervention no longer consists
of just intervening on the observed variables to change them from
observations consistent with state $1$ to state $2$, but instead
intervening on the observed variables \emph{and all unobserved
  variables consistent with the system and changes from state $1$ to
  $2$.}  Conceptualizing unknowable changes in unobserved variables
represents a significant barrier to interpretation, and motivates the
exploration of stronger assumptions that result in a clearer
interpretation (see Section \ref{sec:miss-temp-observ},
\ref{sec:observ-port-state}, \ref{human}).

In practice we also do not know the number of lagged observations that
are required for reconstruction of the state space at time $t$. One
approach is to use the data for guidance. This involves reconstructing
the state at time $t$ with iteratively increasing numbers of lags. We
have confidence we have reproduced the state when the observations at
time $t$ are conditionally independent of each other given the state
reconstruction. However, this approach potentially introduces even
more problems, including but not limited to the assumptions required
in our conditional independence tests. This example highlights the
challenges associated with any method relying on state space
reconstruction with lagged observations: to be sure we reconstruct the
state space we must include observations from a potentially infinite
temporal extent, and there might not be any reliable way to check that
we successfully reconstructed the state space. *relate back to opening
questions: not good on interpretabgle*

\subsection{Missing temporal observations induce independent random
  variations in cause and effect}
\label{sec:miss-temp-observ}

If we can assume that the missing temporal observations
(e.g. $S(t-1/2)$ in Figure \ref{fig:generic}a) induce independent
random variations in the cause and effect, conditional on $S(t-1)$,
then the causal graph reduces to Figure \ref{fig:generic}c. In this
case, if we can reconstruct the state space at time $t-1$ using lagged
observations at time t $\leq t-1$, then we can block all backdoor
paths between our cause $C(t)$ and any future effect $E(t+1)$. In this
case, the causal effect would be calculated as:

\begin{equation}
  P(E(t+1)| do(C(t)=c)) = \int_{S(t-1)} P(E(t+1) \, | \, C(t)=c,
  S(t-1) = s
  )\; P(S(t-1)=s) \, d s,
\end{equation}

where $S(t-1)$ is reconstructed from time lags of observations at
times $\leq t-1$. From the graph it may appear that we could also
block backdoor paths by conditioning on $S'(t)$. However, under these
assumptions $S'(t)$ is incalculable because if we attempt to
reconstruct $S'(t)$ using lagged observations of the state space, the
reconstruction will estimate $S$ rather than $S'$, which includes
$C(t)$ because $C$ is a part of the state space. So, a portion of the
cause's role in the system's evolution will be falsely incorporated
into the reconstruction of the state space, and our causal effect will
be biased.

The assumption that missing temporal observations induce independent
random variations in the cause and effect is required because
otherwise there would be an open backdoor path between the cause and
effect through the unobserved time slice (e.g. at time $t-1/2$ in
Figure \ref{fig:generic}a). Relative to Section
\ref{sec:stat-reconstr-state}, the advantage of this approach to
causal inference is that we can calculate the causal effects of
individual observations (e.g, $C(t)$ on $E(T)$), rather than needing
to interpret the causal impact of the entire state holistically (e.g.,
$S(t)$ on $E(T)$). However, this approach requires an additional
assumption that the missing temporal observations do not induce
dependencies between the cause and effect of interest. As with Section
\ref{sec:stat-reconstr-state}, we must be able to reconstruct the
state space, which may not always be possible, and may also confuse
interpretation. *relate back to opening questions, not good for interpreatble*


\subsection{The unobserved portion of the state space does not affect
  the effect}
\label{sec:observ-port-state}

If we assume that we observe all portions of the state space that
affect the effect, then we can calculate the effect of any state
variable on future processes. In this case, the graph is as in Figure
\ref{fig:generic}c, but $S'(t)$ corresponds to all observations at
time $t$ not including $C$, and so can be used to block all backdoor
paths. If we can assume that there are no interactions between
observations at time $t$ then we can calculate the causal effect as:

\begin{equation}
  P(E(t+1)| do(C(t)=c)) = \int_{S'(t)} P(E(t+1) \, | \, C(t)=c,
  S'(t) = s
  )\; P(S'(t-1)=s) \, d \, s,
\end{equation}

where $S'(t)$ are all observations at time $t$, not including the
cause $C(t)$. However, when blocking backdoor paths with simultaneous
observations it is important to consider whether there are
interactions between observations at time $t$, and whether the
observations are truly simultaneous. Whether there are interactions
between observations is a function of the temporal and spatial extent
of the observations. If observations are instantaneous point
observations indexed in time, then interactions between them can
likely be ignored. However, often the spatial and/or temporal extents
of observations overlap, and in this case an assumption of zero
interactions between observations is not justified. In this case, we
can still block backdoor paths by conditioning on past observations
($S(t-1)$):

\begin{equation}
  P(E(t+1)| do(C(t)=c)) = \int_{S(t-1)} P(E(t+1) \, | \, C(t)=c,
  S(t-1) = s
  )\; P(S(t-1)=s) \, d \, s.
\end{equation}

The assumption that we observe all variables relevant to an effect is
a strong assumption. However, it provides significant benefits both in
terms of the statistical complexity of estimating the causal effect,
as well as in interpretation of the causal effect. We do not need to
reconstruct the state space  using lagged observations, which can be a
statistically and computationally challenging problem. Additionally,
the assumption that we observe everything relevant to the effect is
much easier to interpret relative to an assumption about the degree to
which we can (or cannot) reconstruct the relevant state space with
lagged observations.

\subsection{Applications at the human-Earth system interface: when the
  cause is approximately independent of the system.}
\label{human}

Causal inference becomes substantially more tractable under an
assumption that our causes of interest are independent from the
evolution of the state space (Figure \ref{fig:forcing}). While such a
strong assumption may seem unjustifiable due to tight coupling within
the Earth system, recent historical examples suggest that this
assumption may be applicable to some situations. For example,
coordinated global human response to global warming is relatively
independent of the climate state \citep{arto2014drivers}. We have
failed to reduce green house gas emissions even as global temperature
increased. Instances of reduced rises in global green house gas
emissions are usually due to global economic recession (e.g. the 2008
financial crisis) or pandemic (COVID-19 crisis) rather than factors
directly tied to the climate state. In these examples many global
social, political, health, and economic factors are the primary causes
of global green house gas emission, and while the climate system may
affect these factors, the historical evidence suggests that the
climate system exerts a relatively small impact
\citep{arto2014drivers}.

\begin{figure}
  \includegraphics[]{forcing-graph.pdf}
  \caption{A generic graph asserting an assumption that there are
    forcing external to the evolution of the state-space}
  \label{fig:forcing}
\end{figure}

Generally this logic applies to many systems on the "human-climate"
interface, such as land-use land-cover change in urban centers where
urban planning is relatively independent of recent climate
history. The general graph in Figure \ref{fig:forcing} is applicable
to any analyses for which: 1) we wish to examine the effect of human
behavior on the environment, and 2) we can assume human behavior is
approximately independent of the climate state. Because the climate
state space does not affect the cause (human behavior), there are no
unblocked backdoor paths through the unobserved portions of the state
space. Causal inference is particularly tractable for this class of
problems. *discuss ``human confounding'' (e.g, with covid?*

\section{Conclusions}

In summary, we conclude that:

\begin{itemize}
\item Causal graphs concisely and clearly encode assumptions about
  causal dependencies between processes. Including a causal graph
  benefits any observational analysis, including those that use
  regression. Depending on the observations available and the causal
  structure of the system, regression analyses can be interpreted as
  an average, generalized, functional mapping from causes to
  effects. This causal approach opens up a new path for success for
  situations where we either do not know the functional form a priori,
  or it is too computationally intractable to calculate.
\item Whether or not a causal effect can be calculated from data is
  determined exclusively by the causal graph. Thus the tractability of
  a causal analyses, or the strength of assumptions necessary to make
  an analysis tractable, is determined and assessed before collecting,
  generating, or manipulating data (which can cost a tremendous amount
  in terms of researchers' time, computational resources, and/or
  funding). We recommend early causal analyses to determine
  tractability during a project's conception, before resources are
  spent obtaining or analyzing data.
\item Because the Earth system evolves as a dynamical system through
  time, we can construct broadly applicable, generic Earth system
  causal graphs. However, causal inference in Earth science also
  presents challenges: we only partially observe the state space of
  the system.
\item These challenges can be alleviated by applying causal theory to
  generic causal graphs of the Earth system and identifying the
  assumptions that allow for causal inference from data. These are
  assumptions that:
  \begin{itemize}
  \item The state space of the system is reconstructable
    from lagged observations of the system, as allowed by
    Takens' theorem (Section \ref{sec:stat-reconstr-state}, Section \ref{sec:miss-temp-observ}), or
  \item The effect of interest is only causally
    affected by the observed portion of the state space (Section
    \ref{sec:observ-port-state}), or
  \item The cause of interest can be assumed to be independent of the
    evolution of the system's state (e.g. forcing) (Section
    \ref{human}).
  \end{itemize}
\end{itemize}

Here we focus on the fundamentals of calculating causal effects from
data. However, causal inference is a thriving active area of research,
and there are many other causal inference techniques and abstractions
that could benefit the Earth system research community. For example,
there are techniques for representing variables observed under
selection bias in the causal graph and analyzing whether a causal
effect can be calculated (i.e. identified) given the selection bias
\citep[e.g.,][]{bareinboim2014recovering}. Selection bias is very
relevant in Earth science. For example, satellite observations are
almost always collected under selection bias (e.g. they sample at
certain local times of the day, clouds obscure surface data,
etc.). Additionally, transportability
\citep[e.g.,][]{bareinboim2012transportability} identifies whether one
can calculate a causal effect in a passively observed target domain,
by merging experiments from source domains that may differ from the
target domain. A potential application for transportability in earth
sciences would be to merge numerical model experiments (e.g., global
climate models, cloud models, etc.) and formally transport their
results to the real world. In this case, numerical models are the
source domains that differ from the target domain (``real world'') due
to approximations. Given the limitations of explicit experiments in
Earth science, we hope that causal methods gain wider adoption in
Earth science and that this manuscript provides the necessary
foundation for proper application of causal inference in Earth
science.

\paragraph{Acknowledgments} Thank you to Beth Tellman, James
Doss-Gollin, David Farnham, and Masa Haraguchi for very thoughtful
feedback and comments that greatly improved this manuscript.


\bibliography{references.bib}

\appendix
\section{Basic probability and syntax}
\label{prob-theory}

In this paper we use capital letters to represent random variables
(e.g., ``$X$''). For example, $P(X)$ is the probability distribution
of a random variable $X$. $P(X)$ is a function of one variable that
outputs a probability (or density, in the case of continuous
variables) given a specific value for $X$. We represent specific
values that a random variable can take with lowercase letters (e.g.,
$x$ in the case of $X$). $P(X)$ is shorthand; a more descriptive but
less concise way to write $P(X)$ is $P(X=x)$ which represents the fact
that $P(X)$ is a function of a specific value of $X$, represented by
$x$. We use both notations, and $P(X)$ has the same meaning as
$P(X=x)$.

For the unfamiliar reader, there are a few basic rules and definitions
in probability that provide relatively complete foundations for
building deeper understanding of probability. These are the \textbf{sum rule}:

\begin{equation}
  P(X=x) = \sum_Y P(X=x,\, Y=y)
  \label{eq:sum}
\end{equation}

and the \textbf{product rule}:

\begin{equation}
  P(X=x, \, Y=y) = P(X = x \, | \, Y=y ) P(Y=y) = P(Y = y \, | \, X=x ) P(X=x)
  \label{eq:product}
\end{equation}

The \textit{joint probability distribution} ($P(X=x,Y=y)$) is the
probability that the random variable $X$ equals some value $x$ \emph{and} the
random variable $Y$ equals $y$. The joint distribution is a function
of two variables, $x$ and $y$ which are values in the domains of the
random variables $X$ and $Y$ respectively. The \textit{conditional
  probability distribution} ($p(X = x \, | \, Y=y )$) is also a
function of two variables $x$ and $y$, but it is the probability of
observing $X$ equal to $x$, given that we have observed $Y$ equal to
$y$. In other words, if we filter our domain to only values where
$Y=y$, then $p(X = x \, | \, Y=y )$ is the probability of
observing $X=x$ in this sub-domain where $Y=y$. The \textit{marginal
  probability distribution} ($P(Y=y)$) is just the probability that
$Y$ equals some value $y$, and is a function of only $y$. We can
calculate the marginal probability from the joint distribution by
summing over all possible values values of the other random variables
in the joint (the ``sum rule'' - Equation (\ref{eq:sum})). Additionally,
the joint distribution can factorize into a product of conditional and
marginal distributions (``the product rule'' - Equation
(\ref{eq:product})). These two simple rules can be used to build much of the
theory and applications of probability theory (e.g., Bayes' theorem
$P(Y|X) =\frac{P(X|Y) P(Y)}{P(X)}$). While Equations (\ref{eq:sum})
deals with probability distributions of discrete random variables,
there is also a sum rule analog for continuous random variables and
probability density functions (the syntax of the product rule is the
same):

\begin{equation*}
  P(X=x) = \int_Y P(X=x,\, Y=y) \, dy
\end{equation*}

where $\int_{Y}$ represents an integral over the domain of $Y$ (e.g.,
$\int_{-\infty}^{\infty}$ if $Y$ is a Gaussian random variable).


\end{document}