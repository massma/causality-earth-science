\documentclass[12pt]{article}
\input{def}
\graphicspath{{figs/}}

\begin{document}

\title{Causal inference in earth science}

\author{Adam Massmann\thanks{Corresponding author:
    akm2203@columbia.edu}, Pierre Gentine, need to contact: Elias
  Bareinboim, Jakob Runge}

\maketitle

\section{Introduction}

Controlled experimentation is the traditional path to scientific
discovery. A scientist designs experiments where parameters are
systematically varied to test hypotheses about a system's
nature. Climate and Earth system scientists primarily use numerical
models for experimentation \citep[e.g.,][]{eyring-cmip6-2016}, but
real world experiment is also used to a lesser degree
\citep[e.g.,][]{ainsworth-face-2005}. However, it may be logistically
impossible or unethical to execute many real world experiments, and
numerical experiments may rely on approximations that bias
experimental results relative to the real world
\citep[e.g.,][]{kim-cmip5,stillmann-cmip5-extremes}. Given the
limitations of real world and numerical experiments in Earth science,
researchers require additional tools for scientific discovery.
\citet{pearl-1994-do-calculus} introduced one such tool: the
\textit{do-}calculus for calculating the causal effects of
experimental interventions based on passive observations of a system
and assumptions about causal dependencies in the system. In other
words, given observational data about a system one can use
\textit{do}-calculus to calculate an experimental effect from data
without conducting a specific experiment. This is a powerful tool for
Earth scientists that complements numerical experimentation. When
numerical modeling assumptions break down, causal inference may be a
tractable path towards scientific discovery.

However, causal inference from data presents its own challenges; the
causal effect must be identifiable from assumptions about the causal
dependencies of system processes and available observations. If a
causal effect is unidentifiable, then the causal effect cannot be
calulated from data, even with samples spanning the entire joint
distribution of observed variables \citep[][]{shpitser2006}. Specific
to problems in Earth science, the identification of causal effects is
challenging given two fundamental issues: 1) the system evolves
through time according to an underlying dynamical system, and 2) we
only partially observe the state space of that dynamical system
\citep{majda-state}. The main contribution of this paper is the
identification of the necessary assumptions for applying causal
inference in Earth systems. We identify these assumptions by applying
graph theory developed in \citet{pearl1995causal} to generic Earth
science scenarios. There is the potential for applying causal
inference when we can assume:

\begin{itemize}
\item The effect of interest is only causally affected by the observed
  portion of the state space (Section \ref{sec:observ-port-state}), or
\item The cause of interest is independent of the evolution of the
  system's state (e.g. forcing) (Section \ref{human}), or
\item The state space of the system is statistically reconstructable
  from available observations (Section \ref{sec:stat-reconstr-state},
  Section \ref{sec:miss-temp-observ})

\end{itemize}

Our theoretical results identifying tractable problems in Earth
science require a few fundamentals from the causal inference
literature, so we introduce causal inference theory, causal graphs,
and \citet{pearl2009}'s \textit{do-}calculus for the unfamiliar reader
(Section \ref{sec:causal-graphs-pearls}), and compare with recent
Earth science literature on the related field of causal discovery
(causal discovery attempts to ``discover'' the causal graph from
observations, see Section \ref{sec:discovery}). Causal effects, due to
their underlying logic and clear interpretation, are an exciting tool
for scientific discovery and understanding
\citep{hannart-da,naveau-2020}. This manuscript establishes the
conditions required for the proper application of causal inference in
Earth science.

\section{Causal graphs and Pearl's do calculus}
\label{sec:causal-graphs-pearls}
% intro causal graphs}

Causal graphs, introduced in \citet{pearl1995causal}, are directed
acyclic graphs (DAGs) that encode our assumptions about the causal
dependencies of a system. Causal graphs are useful tools because they
can be drawn by any domain expert with no required knowledge of math
or probability, but they also represent formal mathematical objects
with specific meaning. A domain expert simply draws directed edges
(e.g. arrows) from variables that are causes to effects. We illustrate
causal graphs and their mathematical consequences with a simplified
toy example examining clouds, aerosols, and surface solar
radiation/sunlight (Figure \ref{fig:toy}). Our causal graph consists
of:

\begin{figure}
  % % consider \noindent\include... [width=0.75\textwidth]...
  % \includegraphics[height=0.4\textheight]{cloud-aerosol-bidirected.pdf}\\
  \scalebox{1.0}{\input{figs/cloud-aerosol.tex}}
  \caption{A relatable toy example to demonstrate basic causal theory.}
  \label{fig:toy}
\end{figure}

\begin{enumerate}
\item An edge from aerosols to clouds because aerosols serve as cloud
  condensation nuclei and affect the probability of water vapor
  conversion to cloud.
\item An edge from aerosols to surface solar radiation, because
  aerosols can reflect sunlight back to space and reduce sunlight
  at the surface.
\item An edge from clouds to sunlight, because clouds also reflect
  sunlight back to space and can reduce sunlight at the surface.
\end{enumerate}

Causal graphs encode our assumptions about how the system behaves, and
the nodes and edges that are \textit{missing} from the graph often
represent strong assumptions. For example, in the
cloud-aerosol-sunlight example, clouds also affect aerosols; e.g. by
increasing the likelihood that aerosol will be scavenged from the
atmosphere during precipitation
\citep[e.g.,][]{radke-scavenge-1980}. By not including an edge from
cloud to aerosol, we are making a strong assumption that we are
ignoring the effect of clouds on aerosols. Considering this example is
intended to be pedagogical for introducing causal theory to the
readers, we will continue with the graph as drawn in Figure
\ref{fig:toy} (Section \ref{sec:necess-cond-caus} explores realistic
Earth system graphs).

Even though probablistic reasoning is not required to construct a
causal graph, the resulting graph encodes specific probablistic
meaning. Interpreted as a general probabilistic graphical model, our
example graph in Figure \ref{fig:toy} represents a specific
factorization of the joint distribution:

\begin{equation}
  P(A, C, S) = P(S \, | \,C, A) \, P(C \, | \, A) \, P(A),
\end{equation}

where $A$ represents aerosol, $C$ represents cloud, and $S$
represents surface sunlight/solar radiation. Interpreted causally, as
in \citet{pearl1995causal} and this manuscript, the directed edges
encode causal dependencies in addition to a factorization of the
joint. More specifically, the graph represents the assumed Structural
Causal Model \citep[SCM,][]{pearl2009}, which is the set of functions
that determines how variables are generated by their causes. Each
variable in the graph is determined by a function with inputs
corresponding to inward edges to the variable of interest, as well as
randomness due to the variables not included in the causal graph
(``exogenous variables'').  In the cloud-aerosol-radiation example the
SCM is:

\begin{equation}
  SCM =
  \begin{cases}
    f_{aerosol} &: U_{aerosol} \\
    f_{cloud} &: aerosol, U_{cloud}  \\
    f_{sunlight} &: aerosol, cloud, U_{sunlight},
  \end{cases}
  \label{eq:1}
\end{equation}

where $U$ are random variables due to all the factors not represented
explicitly in the SCM and corresponding causal graph. The SCM asserts
that each variable is generated from a deterministic function, and the
randomness randomness is due to the exogenous variables ($U$). For
example, sources of aerosol variability not considered include
anthropogenic aerosol emission, the biosphere, fires, volcanoes,
etc. For cloud, this includes synoptic forcing, moisture content,
etc. For radiation, this includes variability of top of atmosphere
radiation, etc. For the causal graph, as drawn, we assume that all of
these sources of randomness are independent of each other. That is,
$U_{aerosol}$, $U_{cloud}$, and $U_{radiation}$ are independent of
each other. The $U$ variables are powerful tools: by positing an SCM
and causal graph, we are not stating that the variables in the graph
are the only processes in the system. Instead, we are stating that all
other processes not included in the graph induce variations in the
causal variables that are independent of each other. In some
scenarios, this assumption may be unreasonable and we would need to
encode dependencies between variables due to shared $U$ terms; that is,
co-variability induced between variables due to exogenous
processes. This can be encoded in the graph as a bi-directed dashed
edge between the two variables with shared exogenous factors. For
example, if aerosol in Figure \ref{fig:toy} were instead considered to
be exogenous, we would represent the graph instead as in Figure
\ref{fig:toy}, and the corresponding SCM would be:

\begin{equation}
  SCM =
  \begin{cases}
    f_{cloud} &: U_{cloud,radiation}  \\
    f_{radiation} &: cloud, U_{cloud,radiation}
  \end{cases},
  \label{eq:2}
\end{equation}

where cloud and radiation now share an exogenous term. In this paper
we do not include the bi-directed dashed edge notation, because in
Earth science we can usually identify the relevant variables and their
dependencies, which is sufficient information to include them
explicitly in the graph as nodes, even if we do not know the
functional form of their dependencies or cannot observe them.

\textit{/include this discussion barienboim's notation (which I do not
  like) of including and representing exogenous variation that
  affects multiple variables with a dashed line? not as applicable for
  Earth science, where I *think* we have a general idea of the main
  players (e.g. state), and how they relate to each other. I prefer to
  represent these instead as unobservable $V$ than $U$. However, show
  it in this example by just saying, if we did not include aerosol as
  an endogenous variable we would just represent that as a bi-directed
  dashed arrow from $V$ to $U$./}

We can apply causal graph theory
\citep[e.g.,][]{pearl1995causal,shpitser2006} to the assumptions
encoded in our causal graph to identify which distributions we must
estimate from data in order to calculate a causal effect of
interest. This process of identifying the necessary distributions is
formally termed \emph{causal identification}. If a causal effect is
not identifiable (\emph{un}-identifiable), for example if calculating
a causal effect requires distributions of variables that we do not
observe, then we cannot use causal inference to calculate a causal
effect, even with an infinite sample of data.

% backdoor path}

A necessary condition for unidentifiability is the presence of an
unblocked backdoor path from cause to effect. Backdoor paths are any
paths going through parents of the cause to the effect. We can block
these paths by selectively observing variables such that no
information passes through them \citep{geiger-d-sep}. If we can
observe variables along the backdoor paths such that they are blocked,
then we have satisfied the \emph{back-door criterion}
\citep{pearl2009} and we can calculate unbiased causal effects from
data.

\begin{figure}
  \noindent\includegraphics[]{mutilated-cloud-aerosol.pdf}\\
  \caption{A mutilation of Figure \ref{fig:toy}, where we have removed
    directed causal paths from the cause (cloud) to the effect (surface
    solar radiation). We can see that there is covariability between
    cloud and surface solar radiation in the data, that is not
    explained by a causal connection between cloud and surface solar
    radiation, but instead is because of induced co-variability caused
    by aerosol.}
  \label{fig:mutilated-toy}
\end{figure}

% backdoor path with example}
Understanding backdoor paths and the backdoor criterion is helped by
example. Returning to our toy example (Figure \ref{fig:toy}), we will
attempt to calculate the causal effect of clouds on sunlight. In other
words, we want to isolate the variability of sunlight due to the
causal link from cloud to sunlight. However, aerosols both affect
cloud (edge from aerosol to cloud), and sunlight, so if we naively
calculate a causal effect we would get a biased estimate of the mean
effect of cloud on sunlight. To demonstrate, consider generated
data where the ``true'' SCM is:

\begin{equation}
  SCM =
  \begin{cases}
    f_{aerosol} &: U_{aerosol} \sim \text{uniform (0, 1]}\\
    f_{cloud} &: \text{Cloudy if } U_{cloud} + aerosol > 1; \;
    U_{cloud} \sim \text{uniform (0, 1]}\\
    f_{sunlight} &: \begin{cases}
      \text{Cloudy} &: 0.6 \cdot \text{clear sky radiation}  \\
      \text{Clear} &: \text{clear sky radiation}
    \end{cases}
  \end{cases}
\end{equation}

where:

\begin{equation*}
  \text{clear sky radiation} = U_{sunlight} \cdot (1 - aerosol); \;
  U_{sunlight} \sim \text{Normal(340, 30)}
\end{equation*}

Now, consider not knowing the underlying SCM, but instead just
passively observing cloud and sunlight. If one were interested in
calculating the effect of cloud on sunlight, and aerosol data were not
available or one where very naive, one approach would be to bin the
data by cloudy and clear conditions and compare the amount of sunlight
between cloudy and clear observations (Figure
\ref{fig:naive-cloud-sunlight}). This approach suggests that clouds
reduce sunlight by, on average, 160 W m$^{-2}$, which is a massive
overestimation of the true average effect of clouds derived from the
SCM of -68 W m$^{-2}$. Aerosol induces co-variability between cloud
and aerosol that is unrelated to the causal link from cloud to
aerosol. Graphically, this is clarified by removing all edges from our
cause (cloud) to children of our cause (in this case sunlight) (Figure
\ref{fig:mutilated-toy}). We see that cloud is not independent of
surface solar radiation in the mutilated graph.  However if aerosol
were fixed (e.g. observed or not varying), cloud and sunlight would be
independent of each other in Figure \ref{fig:mutilated-toy}, and
in Figure \ref{fig:toy} all co-variability between cloud and sunlight
would be only due to the causal edge between cloud and sunlight.
Mathematically incorporating this requirement that we must condition
on aerosol to isolate the causal effect of cloud on radiation gives
the identification of the causal effect of cloud and aerosol according
to the backdoor criterion:

\begin{figure}
  \includegraphics[]{naiveCloudSunlight.pdf}
  \caption{A naive approach to estimating the ``effect'' of clouds on
    sunlight: bin observations by cloudy and clear day, and compare
    the values of sunlight. This approach yields a massive
    overestimation of the true causal effect of clouds on sunlight,
    which is -68.0 W m$^{-2}$}
  \label{fig:naive-cloud-sunlight}
\end{figure}

\begin{equation}
  P(S | do(C = c)) = \int_{a} P(S \, | \, C = c,
  A=a) \, P(A=a) \; da,
  \label{eq:3}
\end{equation}

where the \textit{do}-calculus \citep{pearl2009} term
($P(S \, | \, do(C\, = \,c))$) represents the probability of sunlight
if we did an experiment where we intervened and set cloud to a value
of our choosing (in this case $c$). In the case that observations of
aerosols are not available, our causal effect is not identifiable and
we cannot use causal inference no matter how large the sample sizes of
clouds and aerosols. This is a powerful time saving research tool:
without having to manipulate data or estimate marginal or conditional
distributions, we can determine whether it is possible to calculate a
causal effect of interest, given the available observations and our
assumptions about the causal dependencies in the system.  We later use
this theory to theoretically assess which general problems are
tractable in Earth science using causal inference (Section
\ref{sec:necess-cond-caus}).

Once we have established that a causal effect is identifiable from
data, we must use estimate the required observational distributions
(Equation (\ref{eq:3}) from data. Often it may be more computationally
tractable to calculate an average causal effect, rather than the full
causal distribution $P(S | do(C=c))$. Returning to our toy example
(Figure \ref{fig:toy}), the average effect is defined as:

\begin{equation}
  \mathbb{E}(S | do(C = c)) = \int_{s} s \, P(S = s
  | do(C=c)) \, ds,
  \label{eq:4}
\end{equation}

Substituting Equation (\ref{eq:3}) into Equation (\ref{eq:4})
rearranging gives:

\begin{equation}
  \mathbb{E}(S | do(C = c))  = \int_{a} P(A=a) \; \mathbb{E}(S=s |
  C=c, A=a) \, d a,
  \label{eq:5}
\end{equation}

Where $\mathbb{E}(S=s \, | \, C=c, A=a)$ is just a regression of sunlight on
cloud and aerosol. Estimating the marginal $P(A)$ is difficult, but
if we assume that our observations are independent and identically
distributed (IID) and we have a large enough sample, we can use the
law of large numbers to approximate Equation (\ref{eq:5}) with:

\begin{equation}
  \mathbb{E}(S | do(C = c))  \approx \frac{1}{n} \sum_{i=1}^n \mathbb{E}(S=s_i |
  C=c, A=a_i).
  \label{eq:6}
\end{equation}

Data or prior knowledge can inform the regression function for
$\mathbb{E}(S=s_i | C=c, A=a_i)$. In the toy example, a linear model
conditional on cloud appears to be a good choice of regression
function (Figure \ref{fig:linear}). The causal effect of clouds on
sunlight as calculated using Equation (\ref{eq:6})) (e.g.
$\mathbb{E}(S | do(C = \text{cloudy})) - \mathbb{E}(S | do(C =
\text{clear}))$) is -68.52 W m$^{-2}$, which closely matches the true
causal effect from the SCM of -68 W m$^{-2}$. This example
demonstrates how causal inference and theory can be used to calculate
unbiased average effects using regression. Further, causal inference
can be used to justify and communicate assumptions in any
observational analyses employing regression. In the best case, the
causal effect is identifiable from the available observations, and
the regression analysis can be framed as an average causal effect. In
the worst case that identification is not possible from the available
observations, one may present the regression as observed associations
between variables. However, presentation of a causal graph still aids
the reader: the reader can see from the causal graph what the
confounders and unobserved sources of covariability are between the
predictors and the output. In all cases, the presentation of a causal
graph makes explicit the assumptions about the causal dependencies of
the system. Wherever possible, we commend including causal graphs with
any observation-based analyses.

In summary of the main points of this introduction to causal graphical
models, structural causal models, and \textit{do-}calculus:

\begin{itemize}
\item Graphical causal models encode our assumptions about causal
  dependencies in a system (edges are drawn \emph{from} causes
  \emph{to} effects).
\item Each graphical causal model corresponds to a structural causal
  model, which are a set of functions that map causes and random
  variations to effects.
\item In order to calculate an unbiased causal effect from data, we
  must remove all covariability between our cause and effect that is
  not due to the directed causal path from cause to effect. The
  presence of non-causal dependencies between the cause and effect can
  be deduced from the causal graph: the presence of an unblocked
  backdoor path from the cause to the effect leads to non-causal
  dependencies (and co-variation).
\item The backdoor criterion identifies the distributions we must
  calculate from data in order to block a backdoor path, remove
  non-causal dependence between the cause and effect, and calculate an
  unbiased causal effect from data.
\item The \emph{average} causal effect can be reliably approximated
  with regression (Equation (\ref{eq:6})) derived from the backdoor
  criterion. In this scenario, causal theory and graphs identify the
  variables that should (and should not be) included in the regression
  to calculate an unbiased causal effect.
\item Causal identification is a flexible tool that provides the
  distributions that must be estimated by data, while making no
  assumptions about the forms of those distribution. However,
  parametric assumptions can be applied to make the calculation of
  those distributions from data more computationally tractable.
\end{itemize}

\begin{figure}
  \includegraphics[]{aerosolSunlight.pdf}
  \caption{A linear relationship between aerosol and sunlight,
    conditional on cloud. If we use linear regression to calculate the
    average causal effect of cloud on sunlight, as in Equation
    (\ref{eq:6}), our result is very close to the true causal effect
    of -68.0 W m$^{-2}$.}
  \label{fig:linear}
\end{figure}

Here we focused on the backdoor criterion to block backdoor paths. An
un-blockable backdoor path from the cause to the effect is a necessary
condition for unidentifiability. However, it is not sufficient
(e.g. there are other identification strategies like the front door
criterion and instrumental variables that do not rely on observing
variables along the backdoor path). For a complete discussion of
sufficient conditions for unidentifiability we refer you to
\citet{shpitser2006}. For the purpose of identifying generally
tractable causal inference approaches in Earth science (Section
\ref{sec:necess-cond-caus}), we focus the backdoor criterion. Given
that the Earth system evolves continuously according to an underlying
dynamical system, we only partially observe the state space, and that
the available observations are generally consistent through time,
these other identification strategies are not as applicable, and an
unblockable backdoor path is usually a sufficient condition for
unidentifiability in the types of graphs that are representative of
Earth science systems (Figure \ref{fig:generic}).

\section{Necessary conditions for causal identification in the Earth
  systems}
\label{sec:necess-cond-caus}

Earth science systems are dynamical systems evolving through time
according to an underlying system state. This offers both advantages
and challenges for causal inference. Challenges involve our partial
observation of the system's state space, while advantages include the
temporal ordering of events; we know that future events can have no
causal effect on the past.

Causal identification and tractable causal inference to Earth science
requires assumptions about the unobserved portion of the state
space. For example, without assumptions the unobserved portion of the
state space will introduce confounding for any causal affect of
interest (Figure \ref{fig:generic}). We do not observe the state space
at every time (e.g. $S(t-1/2)$ in Figure \ref{fig:generic}), and at
any given time, we do not observe the state space at all locations and
for all state variables (e.g. $S(t)$ and $S(t-1)$ in Figure
\ref{fig:generic}). So, if we are interested in the causal effect of
any state variable on some variable ($E$) at time $t+1$, then the
causal effect will be confounded by the unobserved portions of the
state space, and calculating a causal effect is impossible
(un-identifiable) without additional assumptions. We will apply causal
graph theory to identify such additional assumptions that would make
the calculations of causal effects tractable, and may be reasonable in
many Earth science scenarios.

\begin{figure}
  \includegraphics[]{generic-graph.pdf}
  \caption{A generic graph of the Earth system state sequence, limited
    to a 3 time sequence subset of the infinite sequence. Unobserved
    nodes are outlined by dashed lines.  In the scenario that we are
    interested in calculating the causal effect of any portion of the
    state space at time $t$ on some effect ($E$) at time $t+1$, the
    causal effect will be confounded by the unobserved portions of the
    state space, and calculating the causal effect is impossible
    (un-identifiable) without additional assumptions.}
  \label{fig:generic}
\end{figure}

\subsection{Statistical reconstruction of the state space with time
  lagged observations}
\label{sec:stat-reconstr-state}

Takens's theorem implies that we can reconstruct the unobserved
portions of the state space using lagged observations back in time. In
this case, the causal graph is greatly simplified (Figure
\ref{fig:reconstructed}). If we assume that the state is
reconstructable, then we can calculate the causal effect of any
reconstructed state on any future variable or process. The primary
advantages of this approach is that it is the minimum assumption
required to calculate a causal effect in the generic Earth system
proposed in Figure \ref{fig:generic}. However there is no free lunch:
the significant disadvantage of this approach is that we cannot
examine the causal effect of a specific variable (e.g. soil moisture
at time $t$) on another (e.g. evapotranspiration at time
$t+1$). Instead, we limit ourselves to only examining the causal
effect of changes in the entire state holistically. Additionally, this
approach requires a shift in interpretation from the relatively
straightforward interventions on observable variables we considered
thus far.

For example, consider that we reconstructed our state space from
available observations, and this reconstruction reduced to a discrete
state space of 10 states, with associated patterns in the observations
at time $\leq t$. If we are interested in the effect of a change in
state on a process at time $t+1$, for example a change from state $1$
to state $2$, this corresponds to an intervention on the
\textit{entire state space at time $t$}. This includes the unobserved
portions of the state space. So, the intervention no longer consists
of just intervening on the observed variables to change them from
observations consistent with state $1$ to state $2$, but instead
intervening on the observed variables \emph{and all unobserved
  variables consistent with the system and the changes in the observed
  variables from state $1$ to $2$.}  Conceptualizing unknowable
changes in unobserved variables represents a significant barrier to
interpretation, and motivates the exploration of stronger assumptions
that result in a clearer interpretation (at the cost of an increased
likelihood that the assumptions are violated : Section
\ref{sec:miss-temp-observ}, \ref{sec:observ-port-state}, \ref{human}).

In practice we also do not know the number of lagged observations of
the state space that are required for reconstruction at time
$t-1$. One approach is to use the data for guidance. This involves
predicting the effect at time $t+1$ with iteratively increasing
numbers of lags. When the addition of more time lags does not improve
the prediction of variables at time $t$, we have some confidence that
the relevant portions of state space at time $t$ has been
reconstructed by the time series. However even this approach can be
problematic; while predictive power may plateau as we add more
temporal observations back in time, there are no guarantees that we
would not gain causally relevant knowledge from observations further
back in time. For example, a significant drought last year may impact
ecosystem state in the current year, but predictive power may locally
plateau going back in time 2 months. This example highlights the
challenges associated with any method relying on state space
reconstruction with lagged observations: to be sure we reconstruct the
state space we must include observations from a potentially infinite
temporal extent.

\begin{figure}
  \includegraphics[]{reconstruction.pdf}
  \caption{The causal graph under an assumption that we can
    reconstruct the state space, for a two time step sequence. Each
    node S(t) is reconstructed from the observable potions of the
    state space at lagged times $< t$. We can examine the causal
    effect of the reconstructed state on any future observed process,
    represented by $E(t+1)$.}
  \label{fig:reconstructed}
\end{figure}

\subsection{Missing temporal observations induce independent random
  variations in cause and effect}
\label{sec:miss-temp-observ}

If we can assume that the missing temporal observations
(e.g. $S(t-1/2)$ in Figure \ref{fig:generic}) induce independent
random variations in the cause and effect, conditional on $S(t-1)$,
then the causal graph reduces to Figure \ref{fig:no-temporal}. In this
case, if we can reconstruct the state space at time $t-1$ using lagged
observations at time t $\leq t-1$, then we can block all backdoor
paths between our cause $C(t)$ and any future effect $E(t+1)$. In this
case, the causal effect would be calculated as:

\begin{equation}
  P(E(t+1)| do(C(t)=c)) = \int_{S(t-1)} P(E(t+1) \, | \, C(t)=c,
  S(t-1) = s
  )\; P(S(t-1)=s) \, d s,
\end{equation}

where $S(t-1)$ is reconstructed from time lags of observations at
times $\leq t-1$. From the graph it may appear that we could also
block backdoor paths by conditioning on $S'(t)$. However, under these
assumptions $S'(t)$ is incalculable because if we attempt to
reconstruct $S'(t)$ using lagged observations of the state space, the
reconstruction will estimate $S$ rather than $S'$, which includes
$C(t)$ because $C$ is a part of the state space. So, our cause will be
shadowed by our reconstruction of the state space and our causal
effect will be biased.

The assumption that missing temporal observations induce independent
random variations in the cause and effect is required because
otherwise there would be an open backdoor path between the cause and
effect through the unobserved time slice (e.g. at time
($t-1/2$)). Relative to Section \ref{sec:stat-reconstr-state}, the
advantage of this approach to causal inference is that we can
calculate the causal effects of individual observations (e.g. soil
moisture), rather than needing to interpret the causal impact of the
entire state holistically. However, this approach requires an
additional assumption that the missing temporal observations do not
induce dependencies between the cause and effect of interest. As with
Section \ref{sec:stat-reconstr-state}, we must be able to reconstruct
the state space, which may not always be possible, and may also muddy
interpretation.

\begin{figure}
  \includegraphics[]{no-temporal.pdf}
  \caption{The causal graph under an assumption that missing temporal
    observations (e.g. $S(t-1/2)$ in  Figure \ref{fig:generic}) induce
    independent random variations in the cause ($C(t)$) and effect
    ($E(t+1)$). $S'(t)$ denotes the state space, not including the
    cause $C(t)$.}
  \label{fig:no-temporal}
\end{figure}

\subsection{The unobserved portion of the state space does not affect
  the cause}
\label{sec:observ-port-state}

If we assume that we observe all portions of the state space that
affect the effect, then we can calculate the effect of any
state variable on future processes. In this case, the graph is as in
Figure \ref{fig:observed}. If we can assume that there are no
interactions between observations at time $t$ then we can calculate
the causal effect as:

\begin{equation}
  P(E(t+1)| do(C(t)=c)) = \int_{Obs'(t)} P(E(t+1) \, | \, C(t)=c,
  Obs'(t) = o
  )\; P(Obs'(t-1)=o) \, d \, o,
\end{equation}

where $Obs'(t)$ are all observations at time $t$, not including the
cause $C(t)$. Whether or not there are interactions between
observations at time $t$ is a function of the temporal and spatial
extent of the observations. If observations are instantaneous point
observations precisely indexed in time, then interactions between them
can likely be ignored. However, often the spatial and/or temporal
extents of observations overlap, and in this case an assumption of
zero interactions between observations is not justified. In this case,
we can still block backdoor paths by conditioning on $Obs(t-1)$:

\begin{equation}
  P(E(t+1)| do(C(t)=c)) = \int_{Obs(t-1)} P(E(t+1) \, | \, C(t)=c,
  Obs(t-1) = o
  )\; P(Obs(t-1)=o) \, d \, o.
\end{equation}

The assumption that we observe all variables relevant to an effect is
a strong assumption. However, it provides significant benefits both in
terms of the statistical complexity of estimating the causal effect,
as well as in interpretation of the causal effect. We do not need to
reconstruct the state space  using lagged observations, which can be a
statistically and computationally challenging problem. Additionally,
the assumption that we observe everything relevant to the effect is
much easier to interpret relative to an assumption about the degree to
which we can (or cannot) reconstruct the relevant state space with
lagged observations.

\begin{figure}
  \includegraphics[]{observe-everything.pdf}
  \caption{The causal graph under an assumption that we observe all
    portions of the state causally relevant to the effect. $Obs'$ are
    all of the observations excluding $C$.}
  \label{fig:observed}
\end{figure}

\subsection{Applications at the human-Earth system interface: when the
  cause is approximately independent of the system}
\label{human}

Causal inference becomes substantially more tractable under an
assumption that our causes of interest are independent from the
evolution of the state space (Figure \ref{fig:forcing}). While the
Earth system certainly affects all processes on Earth, in some cases
this may still be a reasonable assumption. For example, recent human
history demonstrates that global human actions are relatively
independent of the climate state \citep{arto2014drivers}. That is, we
have failed to reduce green house gas emissions even as global
temperature increased. Instances of reduced rises in global green
house gas emissions are usually due to global economic recession
(e.g. the 2008 financial crisis) rather than factors directly tied to
the climate state. In this example many global social, political and
economic factors are the primary causes of global green house gas
emission, and while the climate system may effect these factors, the
historical evidence suggests that the climate system exerts a
relatively small impact (with tragic consequences)
\citep{arto2014drivers}.

\begin{figure}
  \includegraphics[]{forcing-graph.pdf}
  \caption{A generic graph asserting an assumption that there are
    forcing external to the evolution of the state-space}
  \label{fig:forcing}
\end{figure}

Generally this logic applies to many scenarios on the "human-climate"
interface, such as land-use land-cover change in urban centers where
urban planning is relatively independent of recent climate
history. The general graph in Figure \ref{fig:forcing} is
representative of many such scenarios at the human-climate interface,
and because the state space does not affect the cause, there are no
unblocked backdoor paths through the unobserved portions of the state
space. Causal inference is particularly tractable for this class of
problems.

\section{Relation to previous work and ``causal discovery''}
\label{sec:discovery}

The term ``causal inference'' has been used to describe two
techniques:

\begin{enumerate}
\item \textbf{Causal effect inference}: Calculating the causal effect
  of some processes on other, given data and assumptions about the
  causal structure of the system.
\item \textbf{Causal structure discovery}: Inferring the causal
  structure (e.g. the causal graph) of the system using data.
\end{enumerate}

This paper focused on causal inference as (1): calculating causal
effects from data. Inferring the causal structure of the system (2),
is generally much more difficult and also requires additional
assumptions. For example, some causal structure discovery algorithms
rely on assumptions that we observe all relevant variables to the
system (violated because we partially observe the state space) and/or
possibly arbitrary parameters for statistical independence
tests. Additionally, some methods invoke linearity assumptions about
the relationships between processes, which is not generally true for
the Earth system.

There are other reasons to focus on (1) rather than (2) in
Earth science: often in Earth science we know or have a strong a
priori belief about the causal graph of our system. For example, in
the climate system we can identify the state variables and the state
at time \(t\) determines the state at time \(t+1\), even if the exact
functional form of the dependency through time is not
known. Therefore, we can write down a causal graph and do not need to
infer graph structure from data (Section
\ref{sec:necess-cond-caus}). Additionally, calculating an effect of
some processes upon others illuminates more information about the
system than the binary existence of a link or no link, as is output
by causal structure discovery algorithms.

\textit{/ TODO: tactfully critique causal discovery? a messy start is
  here:}

\textit{
  However, there has been considerable work and effort in applying
  causal structure discovery (2) in Earth science
  \citep[e.g.,][]{ebert-uphoff2012,
    samarasinghe-casuality,runge-causal-timeseries,runge2019inferring}. A
  common application and motivation of these efforts is to filter and
  ignore causal links in the system through structure discovery. The
  ignored links are a function of the significance parameters used in
  the causal discovery algorithms. Causal inference of effects, as we
  explore here, represents a different approach where we do not rely on
  assumptions about the significance of effects, but instead make
  explicit assumptions about the causal structure of the system. To
  reiterate, given our domain knowledge of the Earth science system we
  generally have high confidence about the causal structure of the
  system, and as we will see (Section \ref{sec:necess-cond-caus}) we can
  construct quite general graphs that are faithful to our knowledge
  about how dynamical systems evolve. It is possible some links in these
  graphs correspond to small effects, and these links would be removed
  through causal structure discovery. However, directly interpreting
  what constitutes a ``negligibly small'' effect calculation presented in
  physical units and probabilities, as calculated with causal effect
  inference, may be more transparent than interpreting missing links
  derived from causal structure discovery significance parameters. In
  other words, direct calculation of effects may be more transparent and
  interpretable for many readers, relative to a causal graph derived
  from significance parameters with more abstract meaning. We hope to
  motivate further research effort in causal effect inference to match
  recent efforts in causal structure discovery. Ideally causal effect
  inference and causal structure discovery will co-evolve as
  complementary abstractions for causal interpretation; researchers and
  readers can choose the method that suits their assumptions and
  needs./}

\textit{
  TODO: talk to Elias about ``no mixing'' theorem; from what he
  described it seems like it leads to the invalidation of ``causal
  discovery''
}

\section{Discussion}

To summarize:

\begin{itemize}
\item Causal inference from data is a new tool with the potential to
  complement traditional scientific methods, including numerical and
  real world experimentation. In Earth science, numerical models rely
  on approximations that deviate their behavior from reality, and real
  world experimentation may be intractable or unethical. Causal
  inference is a third tool to calculate the effects of physical
  processes that has a different set of advantages and
  disadvantages, and is a powerful complement to numerical and real
  world experimentation.
\item Causal graphs concisely and clearly encode assumptions about
  causal dependencies between processes. Including a causal graph
  benefits any observational analysis, but particularly those that use
  regression. Depending on the observations available and the causal
  structure of the system, regression analyses can be interpreted as
  an average causal effect.
\item Whether or not a causal effect can be calculated from data is
  determined exclusively by the causal graph. Thus the tractability of
  a causal analyses, or the strength of assumptions necessary to make
  an analysis tractable, is determined and assessed before touching
  data (which can be a significant time sink).
\item Because the Earth system evolves as a dynamical system through
  time, we can construction generic Earth system causal graphs
  applicable to a wide range of scenarios. However, causal inference
  in Earth science also presents challenges: we only partially observe
  the state space of the system, so we must reconstruct the full state
  space using time lagged observations or make strong assumptions
  about the independence of processes from the unobserved portions of
  the state space.
\item We apply causal theory to generic causal graphs of the Earth
  system to identify the assumptions necessary for causal inference
  from data. These are assumption that:
  \begin{itemize}
  \item The state space of the system is reconstructable
    from lagged observations of the system, as allowed by
    Takens's theorem (Section \ref{sec:stat-reconstr-state}, Section \ref{sec:miss-temp-observ}), or
  \item The effect of interest is only causally
    affected by the observed portion of the state space (Section
    \ref{sec:observ-port-state}), or
  \item The cause of interest can be assumed to be independent of the
    evolution of the system's state (e.g. forcing) (Section
    \ref{human}).
  \end{itemize}
\end{itemize}

Here we focus on the fundamentals of calculating causal effects from
data. However, causal inference is a thriving active area of
research, and there are many other causal inference techniques and
abstractions that would benefit the Earth system research
community. For example, there are techniques for representing
variables observed under selection bias in the causal graph, and
analyzing whether a causal effect can be calculated (e.g. identified)
given the selection bias
\citep[e.g.,][]{bareinboim2014recovering}. Selection bias is very
relevant, for example satellite observations are almost always
collected under selection bias (e.g. only certain times of day, clouds
obscure surface data, etc.). Additionally, transportability
\citep[e.g.,][]{bareinboim2012transportability} identifies whether one
can calculate a causal effect in a passively observed target domain,
by merging experiments from source domains that may differ from the
target domain. We are currently working to formally transport global
Earth system model experiments to the real world, where numerical
models are the source domains that differ from the target domain
(``real world'') due to approximations \citep[][in
prep]{massmann}. Given the limitations of explicit experiments in
Earth science, we hope that causal methods gain wider adoption in
Earth science and that this manuscript provides the necessary
foundation for proper application of causal inference in Earth
science.

\bibliography{references.bib}

\end{document}