\documentclass[12pt]{article}
\input{def}
\graphicspath{{figs/}}

\begin{document}

\title{Causal inference in Earth science}

\author{Adam Massmann\thanks{Corresponding author:
    akm2203@columbia.edu}, Pierre Gentine, Jakob Runge?}

\maketitle
\begin{abstract}
  Causal inference uses data, rather than experiments, to calculate
  the effect of experimental interventions on causes. In Earth
  science, causal inference could be an important tool to complement
  more traditional methods of experimentation. Traditional tools like
  numerical models suffer from approximations that may bias results,
  and real world experiments may be logistically impossible or
  unethical to execute. While causal inference does not suffer from
  the same limitations as numerical and real world experimentation,
  the assumptions behind causal inference must be theoretically
  justified prior to application. Here, we apply causal theory to
  identify the necessary assumptions for calculating causal effects in
  generic Earth sceince systems. Causal inference is justified under
  three different assumptions that: (1) the state space of the system
  is reconstructable from lagged observations of the system;
  alternatively: (2) the effect of interest is only causally affected
  by the observed portion of the state space; alternatively: (3) The
  cause of interest can be assumed to be independent of the evolution
  of the systemâ€™s state.
\end{abstract}

\section{Introduction}

Controlled experimentation is the traditional path to scientific
discovery. The scientist tests hypotheses about a system's nature by
systematically varying experiment parameters and measuring the
response. Climate and Earth system scientists primarily use numerical
models for experimentation \citep[e.g.,][]{eyring-cmip6-2016}, but
real world experiment is also used to a lesser degree
\citep[e.g.,][]{ainsworth-face-2005}. However, it may be logistically
impossible or unethical to execute many real world experiments (e.g.,
geoengineering), and numerical experiments (e.g., climate modeling)
may rely on approximations that bias experimental results relative to
the real world
\citep[e.g.,][]{kim-cmip5,stillmann-cmip5-extremes}. Given the
limitations of real world and numerical experiments in Earth sciences,
researchers require additional tools for scientific discovery.
\citet{pearl-1994-do-calculus} introduced one such tool: the
\textit{do-}calculus for calculating the causal effects of
experimental interventions based on passive observations of a system
and assumptions about causal dependencies in the system. In other
words, given observational data about a system one can use
\textit{do}-calculus to calculate an experimental effect from data
without conducting a specific experiment. This is a powerful tool for
Earth scientists that complements numerical experimentation. When
numerical modeling assumptions break down, causal inference may be a
tractable path towards scientific discovery.

However, causal inference from data presents its own challenges; the
causal effect must be identifiable from assumptions about the causal
dependencies of system processes and available observations. If a
causal effect is unidentifiable, then the causal effect cannot be
calculated from data, even with samples spanning the entire joint
distribution of observed variables \citep[][]{shpitser2006}. Specific
to problems in Earth science, the identification of causal effects is
challenging given two fundamental issues: 1) the system evolves
through time according to the underlying dynamics, and 2) we only
partially observe the state space of that dynamical system
\citep{majda-state}. The main contribution of this paper is the
identification of the necessary assumptions for applying causal
inference in Earth systems. We identify these assumptions by applying
graph theory developed in \citet{pearl1995causal} to generic Earth
science scenarios. There is the potential for applying causal
inference when we can assume:

\begin{itemize}
\item The effect of interest is only causally affected by the observed
  portion of the state space (Section \ref{sec:observ-port-state}), or
\item The cause of interest is external to the system's evolution, as
  is the case with common ``radiative forcing'' experiments in climate
  modeling. In other more technical terms, the cause is independent of
  the evolution system's state (Section \ref{human}). Or,
\item The state space of the system is statistically reconstructable
  from available observations (Section \ref{sec:stat-reconstr-state},
  Section \ref{sec:miss-temp-observ})

\end{itemize}

Our theoretical results identifying tractable problems in Earth
science require a few fundamentals from the causal inference
literature, so we introduce causal inference theory, causal graphs,
and \citet{pearl2009}'s \textit{do-}calculus for the unfamiliar reader
(Section \ref{sec:causal-graphs-pearls}), and compare with recent
Earth science literature on the related but different field of causal
discovery (causal discovery attempts to ``discover'' the causal graph
from observations, see Section \ref{sec:discovery}). Causal effects,
due to their underlying logic and clear interpretation, are an
exciting tool for scientific discovery and understanding
\citep{hannart-da,naveau-2020}. This manuscript establishes the
conditions required for the proper application of causal inference in
Earth science.


\section{Causal graphs and Pearl's do calculus}
\label{sec:causal-graphs-pearls}
% intro causal graphs}

Causal graphs, introduced in \citet{pearl1995causal}, are directed
acyclic graphs (DAGs)\footnote{define DAG?} that encode our
assumptions about the causal dependencies of a system. Causal graphs
are useful tools because they can be drawn by any domain expert with
no required knowledge of math or probability, but they also represent
formal mathematical objects with specific meaning. A domain expert
simply draws directed edges (i.e. arrows) from variables that are
causes to effects. We illustrate causal graphs and their mathematical
consequences with a simplified toy example examining the causal
interaction between clouds, aerosols, and surface solar
radiation/sunlight (Figure \ref{fig:toy}A). Our causal graph consists
of:

\begin{figure}
  % % consider \noindent\include... [width=0.75\textwidth]...
  % \includegraphics[height=0.4\textheight]{cloud-aerosol-bidirected.pdf}\\
  \scalebox{1.0}{\input{figs/cloud-aerosol.tex}}
  \caption{A toy graph example to demonstrate basic causal theory,
    involving cloud (C), aerosol (A), and surface solar radiation
    (S). In \textbf{A)} we observe all variables, while in \textbf{B)}
    we do not observe aerosol and we use the semantic of a dashed node
    to denote the unobserved variable. \textbf{C)} presents an
    alternative notation for representing an unobserved or hidden
    common cause that is popular in causal literature \citep[e.g.,
    ``semi-markovian graphs'',][]{shpitser2006}. When using this
    notation it is common practice to only include observed processes
    as nodes in the graph. However in Earth Science we often observe
    much less of the system relative to our knowledge of causal
    dependencies in the system, so we find it more conceptually clear
    to include unobserved common causes explicitly in the graph, and
    prefer the notation in \textbf{B)} to \textbf{C}). Any
    semi-markovian graph can be represented as a graph with unobserved
    nodes, and vice-versa \citep[e.g.,][]{lee2019structural}.}
  \label{fig:toy}
\end{figure}

\begin{enumerate}
\item An edge from aerosols to clouds because aerosols serve as cloud
  condensation nuclei and affect the probability of water vapor
  conversion to cloud.
\item An edge from aerosols to surface solar radiation, because
  aerosols can reflect sunlight back to space and reduce sunlight
  at the surface.
\item An edge from clouds to sunlight, because clouds also reflect
  sunlight back to space and can reduce sunlight at the surface.
\end{enumerate}

Causal graphs encode our assumptions about how the system behaves, and
the nodes and edges that are \textit{missing} from the graph often
represent strong assumptions. For example, in the
cloud-aerosol-sunlight example, clouds also affect aerosols; e.g., by
increasing the likelihood that aerosol will be scavenged from the
atmosphere during precipitation \citep[e.g.,][]{radke-scavenge-1980,
  JURADO20087931, blanco-alegre2018}. By not including an edge from
cloud to aerosol, we are making a strong assumption that we are
ignoring the effect of clouds on aerosols. Considering this example is
intended to be pedagogical for introducing causal theory to the
readers, we will continue with the graph as drawn in Figure
\ref{fig:toy} (Section \ref{sec:necess-cond-caus} explores realistic
Earth system graphs).

Even though probabilistic reasoning is not required to construct a
causal graph, the resulting graph encodes specific probabilistic
meaning. Interpreted as a general probabilistic graphical model, our
example graph in Figure \ref{fig:toy}A represents a specific
factorization of the joint distribution into conditional and marginal
factors:

\begin{equation}
  P(A, C, S) = P(S \, | \,C, A) \, P(C \, | \, A) \, P(A),
\end{equation}

where $A$ represents aerosol, $C$ represents cloud, $S$ represents
surface sunlight/solar radiation, and $|$ denotes conditional
probability (Appendix \ref{prob-theory} describes the notation used in
this paper and a brief introduction to probability theory for
unfamiliar readers). Interpreted causally, as in
\citet{pearl1995causal} and this manuscript, the directed edges encode
causal dependencies in addition to a factorization of the joint. More
specifically, each node is causally determined by its parents, as well
as some random variation due to processes not explicitly considered in
the graph. For example, sources of aerosol variability not considered
in Figure \ref{fig:toy}A include anthropogenic aerosol emission, the
biosphere, fires, volcanoes, etc. For cloud, this includes synoptic
forcing, atmospheric humidity, etc. For radiation, this includes
variability of top of atmosphere radiation, etc. The causal graph, as
drawn, encodes the assumption that all of these sources of randomness
are independent of each other. The representation of randomness in
causal graphs is a powerful tool: by positing a causal graph, we are
not stating that the variables in the graph are the only processes in
the system. Instead, we are stating that all other processes not
included in the graph induce variations in the causal variables that
are independent of each other. For a deeper look at causal graphs and
their underlying theory based on structural causal models (SCMs) we
refer the reader to \citet{pearl2009}. We find that the causal graph
representation is more intuitive to domain experts than the underlying
SCM-based theory, so we focus on graph-based theory in our application
of causal inference to Earth science.

We can apply causal graph theory
\citep[e.g.,][]{pearl1995causal,shpitser2006} to the assumptions
encoded in our causal graph to identify which distributions must be
estimated from data in order to calculate a causal effect of
interest. More precisely, ``calculating a causal effect'' refers to
estimating the probability distribution of a response (e.g. sunlight)
to an experimental intervention on our cause where we artificially set
it to a value of our choosing (e.g. presence or absence of a
cloud). The challenge of causal inference is to derive the response to
the intervention in terms of only observed distributions. This process
of identifying the necessary observed distributions is formally termed
\emph{causal identification}. If a causal effect is not identifiable
(\emph{un}-identifiable), for example if calculating a causal effect
requires distributions of variables that we do not observe, then we
cannot use causal inference to calculate a causal effect, even with an
infinite sample of data.

% backdoor path}

A necessary condition for unidentifiability is the presence of an
unblocked backdoor path from cause to effect. Backdoor paths are any
paths going through parents of the cause to the effect. We can block
these paths by selectively observing variables such that no
information passes through them \citep{geiger-d-sep}. If we can
observe variables along the backdoor paths such that they are blocked,
then we have satisfied the \emph{back-door criterion}
\citep{pearl2009} and we can calculate unbiased causal effects from
data.

\begin{figure}
  \input{figs/mutilated-cloud-aerosol.tex}
  \caption{A mutilation of Figure \ref{fig:toy}(A), where we have
    removed directed causal paths from the cause (cloud) to the effect
    (surface solar radiation). There is covariability between cloud
    and surface solar radiation that is not due to the causal
    connection between cloud and surface solar radiation, but is
    instead due to aerosol's role as a common driver.}
  \label{fig:mutilated-toy}
\end{figure}

% backdoor path with example}
Understanding backdoor paths and the backdoor criterion is helped by
example. Returning to our toy example (Figure \ref{fig:toy}A), we
attempt to calculate the causal effect of clouds on sunlight. In other
words, we want to isolate the variability of sunlight due to the
causal link from cloud to sunlight (Figure \ref{fig:toy}A). However,
aerosols both affect cloud and sunlight, so if we naively calculate a
causal effect using correlations between sunlight and cloud, we would
get a biased estimate. To demonstrate this, consider simulated cloud,
aerosol, and sunlight data with causal dependencies consistent with
Figure \ref{fig:toy}A.

\begin{align}
  aerosol &\sim \text{uniform (0, 1]}\\
  cloud &\sim \text{bernoulli (aerosol)}\\
  sunlight &:= \begin{cases}
    \text{Cloudy} &: 0.6 \cdot \text{downwelling clear sky radiation}  \\
    \text{Clear} &: \text{downwelling clear sky radiation}
  \end{cases},
                   \label{eq:1}
\end{align}

and:

\begin{equation*}
  \text{downwelling clear sky radiation} = TOA \, \cdot \, (1 - aerosol); \;
  TOA \sim \text{Normal(340 W m$^{-2}$, 30 \, W m$^{-2}$)}
\end{equation*}

Now, consider not knowing the underlying generative processes, but
instead just passively observing cloud and sunlight. If one were
interested in calculating the effect of cloud on sunlight, and aerosol
data were not available or one were very naive, one approach would be
to bin the data by cloudy and clear conditions and compare the amount
of sunlight between cloudy and clear observations (Figure
\ref{fig:naive-cloud-sunlight}). This approach suggests that clouds
reduce sunlight by, on average, 160 W m$^{-2}$; this is is a strong
overestimation of the true average effect of clouds (-68 W m$^{-2}$),
derived from Equation (\ref{eq:1}). Aerosol induces co-variability
between cloud and aerosol that is unrelated to the causal link from
cloud to aerosol. Graphically, this is clarified by removing all edges
from our cause (cloud) to children of our cause (in this case
sunlight) to create a ``mutilated'' graph (Figure
\ref{fig:mutilated-toy}). We see that clouds are not independent of
surface solar radiation in the mutilated graph.  However if aerosol
were fixed (e.g. observed or not varying), cloud and sunlight would be
independent of each other in Figure \ref{fig:mutilated-toy}. In other
words, conditional on aerosol, cloud and sunlight are independent in
the mutilated graph (Figure \ref{fig:mutilated-toy}), which does not
include the causal path from cloud to sunlight. And, conditional on
aerosol in the true system (Figure \ref{fig:toy}(A)), all
co-variability between cloud and sunlight is only due to the causal
edge between cloud and sunlight.  We can mathematically incorporate
the requirement that we must condition on aerosol to isolate the
causal effect of cloud on radiation. Doing so gives the identification
of the causal effect of cloud and aerosol and satisfies the backdoor
criterion with \textit{adjustment} on aerosol:

\begin{figure}
  \includegraphics[]{naiveCloudSunlight.pdf}
  \caption{A naive approach to estimating the ``effect'' of clouds on
    sunlight: bin observations by cloudy and clear day, and compare
    the values of sunlight. This approach yields an average difference
    of 160.43 W m$^{-2}$ between cloudy and clear days, and is a large
    overestimation of the true causal effect of clouds on sunlight
    (-68.0 W m$^{-2}$) in this synthetic dataset.}
  \label{fig:naive-cloud-sunlight}
\end{figure}

\begin{equation}
  P(S | do(C = c)) = \int_{a} P(S \, | \, C = c,
  A=a) \, P(A=a) \; da,
  \label{eq:3}
\end{equation}

where the \textit{do}-calculus \citep{pearl2009} term
($P(S \, | \, do(C\, = \,c))$) represents the probability of sunlight
if we did an experiment where we intervened and set cloud to a value
of our choosing (in this case $c$, which could be ``True'' for the
presence of a cloud, or ``False'' for no cloud). In the case that
observations of aerosols are not available (e.g., Figure
\ref{fig:toy}B, C), our causal effect is not identifiable and we
cannot use causal inference no matter how large the sample sizes of
clouds and sunlight. This is a powerful research tool: after encoding
our domain knowledge in a causal graph, we can analyze the causal
graph and available observations to determine whether a causal
calculation is possible, \textit{without needing to collect, download,
  or manipulate any data}. For more complicated graphs, causal
identification can be automated \citep{shpitser2006}. We later use
this theory to theoretically assess which general problems are
tractable in Earth science using causal inference (Section
\ref{sec:necess-cond-caus}).

Once we have established that a causal effect is identifiable from
data, we must estimate the required observational distributions
(Equation (\ref{eq:3})) from data. Often it may be more computationally
tractable to calculate an average causal effect, rather than the full
causal distribution $P(S | do(C=c))$. Returning to our toy example
(Figure \ref{fig:toy}(A)), the average effect is defined as:

\begin{equation}
  \mathbb{E}(S | do(C = c)) = \int_{s} s \, P(S = s
  | do(C=c)) \, ds,
  \label{eq:4}
\end{equation}

where $\mathbb{E}$ is the expected value. Substituting Equation
(\ref{eq:3}) into Equation (\ref{eq:4}), and rearranging gives:

\begin{equation}
  \mathbb{E}(S | do(C = c))  = \int_{a} P(A=a) \; \mathbb{E}(S \, | \,
  C=c, A=a) \, d a,
  \label{eq:5}
\end{equation}

Where $\mathbb{E}(S \, | \, C=c, A=a)$ is just a regression of sunlight on
cloud and aerosol. Estimating the marginal $P(A)$ is difficult, but
if we assume that our observations are independent and identically
distributed (IID) and we have a large enough sample, we can use the
law of large numbers to approximate Equation (\ref{eq:5}). The law of
large numbers states that if we observe $n$ IID samples of some process, in
this case $A$ (e.g., $a_1$, $a_2$, $\ldots$, $a_n$), then for any
function $f$:

\begin{equation}
  \frac{1}{n} \sum_{i=1}^n f(a_i) \to \int_a P(A=a) f(a) \, d a.
  \label{eq:lln}
\end{equation}

In Equation (\ref{eq:5}), $c$ is fixed by the intervention, so
$\mathbb{E}(S| C=c, A=a)$ is just a function of $a$, and we can use
Equation (\ref{eq:lln}) to justify an approximation to Equation
(\ref{eq:5}) with:

\begin{equation}
  \mathbb{E}(S | do(C = c))  \approx \frac{1}{n} \sum_{i=1}^n
  \mathbb{E}(S \, | \,
  C=c, A=a_i).
  \label{eq:6}
\end{equation}

Data or prior knowledge can inform the regression function for
$\mathbb{E}(S | C=c, A=a_i)$. In the toy example, a linear model
conditional on cloud appears to be a good choice of regression
function (Figure \ref{fig:linear}). The causal effect of clouds on
sunlight as calculated using Equation (\ref{eq:6})) (e.g.
$\mathbb{E}(S | do(C = \text{cloudy})) - \mathbb{E}(S | do(C =
\text{clear}))$) is -68.52 W m$^{-2}$, which closely matches the true
causal effect from Equation (\ref{eq:1}) of -68 W m$^{-2}$. This
example demonstrates how causal inference and theory can be used to
calculate unbiased average effects using regression. Further, causal
inference can be used to justify and communicate assumptions in any
observational analyses employing regression. In the best case, the
causal effect is identifiable from the available observations, and the
regression analysis can be framed as an average causal effect. In the
worst case that identification is not possible from the available
observations, one may present the regression as observed associations
between variables. However, presentation of a causal graph still aids
the reader: the reader can see from the causal graph what the
confounders and unobserved sources of covariability are between the
predictors and the output. In all cases, the presentation of a causal
graph makes explicit the assumptions about the causal dependencies of
the system. Wherever possible, we recommend including causal graphs
with any observation-based analyses.

In summary of the main points of this introduction to causal graphical
models and \textit{do-}calculus:

\begin{itemize}
\item Graphical causal models encode our assumptions about causal
  dependencies in a system (edges are drawn \emph{from} causes
  \emph{to} effects).
\item In order to calculate an unbiased causal effect from data, we
  must isolate the covariability between cause and effect that is due
  to the directed causal path from cause to effect. The presence of
  non-causal dependencies between the cause and effect can be deduced
  from the causal graph: the presence of an unblocked backdoor path
  from the cause to the effect leads to non-causal dependencies (and
  co-variation).
\item The backdoor criterion identifies the distributions we must
  calculate from data in order to block all backdoor paths, remove
  non-causal dependence between the cause and effect, and calculate an
  unbiased causal effect from data.
\item The \emph{average} causal effect can be reliably approximated
  with regression (Equation (\ref{eq:6})) derived from the backdoor
  criterion. In this scenario, causal theory and graphs identify the
  variables that should (and should not be) included in the regression
  in order to calculate an unbiased causal effect.
\item Causal identification is a flexible tool that provides the
  distributions that must be estimated from data, while making no
  assumptions about the forms of those distributions. However,
  parametric assumptions can be applied to make the calculation of
  those distributions from data more computationally tractable.
\end{itemize}

\begin{figure}
  \includegraphics[]{aerosolSunlight.pdf}
  \caption{A linear relationship between aerosol and sunlight,
    conditional on cloud. If we use linear regression to calculate the
    average causal effect of cloud on sunlight, as in Equation
    (\ref{eq:6}), our result is very close to the true causal effect
    of -68.0 W m$^{-2}$.}
  \label{fig:linear}
\end{figure}

Here we focused on the backdoor criterion to block backdoor paths. An
un-blockable backdoor path from the cause to the effect is a necessary
condition for unidentifiability. However, it is not sufficient
(e.g. there are other identification strategies like the front door
criterion and instrumental variables that do not rely on observing
variables along the backdoor path). For a complete discussion of
sufficient conditions for unidentifiability we refer you to
\citet{shpitser2006}. For the purpose of identifying generally
tractable causal inference approaches in Earth science (Section
\ref{sec:necess-cond-caus}), we focus the backdoor criterion. Given
that the Earth system evolves continuously according to an underlying
dynamical system and we only partially observe the state space in both
space and time, these other identification strategies are not as
applicable, and an unblockable backdoor path is a sufficient condition
for unidentifiability in the types of graphs that are representative
of Earth science systems (Figure \ref{fig:generic})
\citep{tian2002general}. In other words, blocking backdoor paths is a
requirement for calculating a causal effect in graphs of the form
presented in Figure \ref{fig:generic}.

\section{Relation to previous work, ``causal discovery'', and
  clarification on terminology}
\label{sec:discovery}


\textit{/ TODO: a messy start to compare and contrast with causal
  discovery is here; clean this up. Also ask Jakob if he wants to be a
  coauthor and fill this out or rewrite it, especially for
  perspectives on causal discovery. The goal is for readers to: 1)
  understand the difference between ``discovery'' and ``estimating
  effects,'' and 2) appreciate that we may often know the causal
  dependencies of physical systems, and when we do, ``estimating
  effects'' is a tractable path of analysis./}

The term ``causal inference'' has been used to describe two
techniques:

\begin{enumerate}
\item \textbf{Causal effect inference}: Calculating the causal effect
  of some processes on other, given data and assumptions about the
  causal structure of the system.
\item \textbf{Causal structure discovery}: Inferring the causal
  structure (e.g. the causal graph) of the system using data.
\end{enumerate}

To summarize, \textit{causal effect inference (1)} calculates the
magnitude of a causal effect given: 1) a causal graph drawn by a
domain expert, and 2) data. On the other hand, \textit{causal
  structure discovery (2)} does not calculate any causal effects at
all, but instead generates a causal graph from data.  This paper
focuses on causal inference as (1): calculating causal effects from
data (Section \ref{sec:causal-graphs-pearls}). Inferring the causal
structure of the system (2), is generally much more difficult and also
requires additional assumptions. For example, some causal structure
discovery algorithms rely on assumptions that we observe all relevant
variables to the system and/or possibly arbitrary parameters for
statistical independence tests
\citep{runge2019inferring}. Additionally, some methods invoke
linearity assumptions about the relationships between processes
\citep{krich2019causal}, which is not generally true for the Earth
system \citep{palmer-nonlinaer-1999}.

However, there has been considerable work and effort in applying
causal structure discovery (2) in Earth science
\citep[e.g.,][]{ebert-uphoff2012,
  samarasinghe-casuality,runge-causal-timeseries,runge2019inferring,goodwell-causality-2020}. Causal
discovery algorithms filter and infer the direction of causal links in
the system, usually using conditional independence detection
algorithms that rely on significance parameters. In contrast to causal
inference of effects, which we explore in this paper, causal discovery
algorithms do not directly incorporate domain knowledge on the causal
dependencies of processes in the system (although domain knowledge may
guide assumptions about linearity of processes, and the observations
that must be included in the causal discovery algorithm). Indeed, our
perspective here is that we have often acquired substantial
understanding of the mechanisms at play and their causal
relationships, which we want to exploit: that is formally combine
domain knowledge with inferences from data. For example, given our
domain knowledge of the Earth science system we generally have high
confidence about the causal structure of the system. We can identify
the state variables and know that the state at time \(t\) determines
the state at time \(t+1\), even if the exact functional form of the
dependency through time is not known. Therefore, we can write down a
causal graph and do not need to infer graph structure from data
(Section \ref{sec:necess-cond-caus}). It is possible some links in
these causal graphs correspond to small effects, and these links would
be removed through causal structure discovery. However, directly
interpreting what constitutes a ``negligibly small'' effect
calculation presented in physical units and probabilities, as
calculated with causal effect inference, may be more transparent than
interpreting missing links derived from causal structure discovery
significance parameters. In other words, direct calculation of effects
may be more transparent and interpretable for many readers, relative
to a causal graph derived from significance parameters with more
abstract meaning. Additionally, calculating an effect of some
processes upon others illuminates more information about the system
than just he presence and direction of a causal edge, as is output by
causal structure discovery algorithms.

However, ultimately we view causal effect inference and causal
structure discovery as complementary tools. Causal effect inference is
more useful in scenarios where elevated domain knowledge gives a
priori confidence in causal graph structure, while causal structure
discovery is more useful when we have very limited domain knowledge
but access to observations of all relevant processes to a
problem. Additionally, causal effect inference can be used as a second
step after causal discovery to calculate individual causal effects. We
hope to motivate further research effort in causal effect inference to
match recent efforts in causal structure discovery in Earth
science. Ideally causal effect inference and causal structure
discovery will co-evolve as complementary abstractions for causal
interpretation; researchers and readers can choose the method that
suits their assumptions, available data, and level of domain
knowledge.

\section{Necessary conditions for causal identification in Earth
  systems}
\label{sec:necess-cond-caus}

\textit{/TODO: pierre gave it to me, but in coronavirus chaos I lost
  the second ``lorenz'' citation (note on my desk?). think it was a
  different year, maybe (1995/6, or 2005). check w/ pierre./}

Earth science systems are dynamical systems evolving through time
according to an underlying system state
\citep{lorenz-1963,lorenz1996predictability,majda-state}. This offers
both advantages and challenges for causal inference. When constructing
causal graphs we benefit from the temporal ordering of events: we know
that future events can have no causal effect on the past. However,
confounding due to incomplete observation of the system's state space
introduces challenges.


Causal identification and tractable causal inference to Earth science
requires assumptions about the unobserved portions of the state
space. Without such assumptions the unobserved portions of the state
space will introduce confounding for any causal affect of interest
(Figure \ref{fig:generic}a). For example, we generally do not observe
the state space at every time (e.g. $S(t-1/2)$ in Figure
\ref{fig:generic}a), and at any given time, we do not observe the
state space at all locations and for all state variables (e.g. $S(t)$
and $S(t-1)$ in Figure \ref{fig:generic}a). So, if we are interested
in the causal effect of any state variable at time $t$ on some
variable at time $t+1$ (e.g., $E$ in Figure \ref{fig:generic}a), then
the causal effect will be confounded by the unobserved portions of the
state space, and calculating a causal effect is impossible
(un-identifiable) without additional assumptions. We will apply causal
graph theory to identify the additional assumptions that would make
the calculations of causal effects tractable, and may be reasonable in
many Earth science situations.

\begin{figure}
  \input{figs/generic-graph.tex}
  \caption{Generic graphs of the Earth system state sequence, limited
    to a 3 time sequence subset of the infinite sequence. \textbf{A):}
    The reality of the observed earth system: unobserved nodes are
    outlined by dashed lines. We only observe the state space at
    certain times (e.g., no observations at $S(t-1/2)$). At times with
    observations, we only partially observe the full state ($S(t)$,
    $S(t-1)$). In the scenario that we are interested in calculating
    the causal effect of any portion of the state space at time $t$ on
    some effect ($E$) at time $t+1$, the causal effect will be
    confounded by the unobserved portions of the state space, and
    calculating the causal effect is impossible (un-identifiable)
    without additional assumptions. \textbf{B):} The reduction of the
    earth system graph under an assumption that we can reconstruct the
    state $S(t)$ from the observable portions of the state space at
    lagged times $< t$ (see Section
    \ref{sec:stat-reconstr-state}). \textbf{C):} The reduction of the
    earth system graph under an assumption that missing temporal
    observations (e.g. $S(t-1/2)$ in \textbf{A)}) induce independent
    random variations in the cause ($C(t)$) and effect
    ($E(t+1)$). $S'(t)$ denotes the state space, not including the
    cause $C(t)$ (see Sections
    \ref{sec:miss-temp-observ},\ref{sec:observ-port-state}).}
  \label{fig:generic}
\end{figure}

\subsection{Statistical reconstruction of the state space with time
  lagged observations}
\label{sec:stat-reconstr-state}

Takens' theorem implies that we can reconstruct the unobserved
portions of the state space using lagged observations back in time
\citep{takens1981detecting,deyle2011generalized,Sugihara496}. In this
case, the causal graph is greatly simplified (Figure
\ref{fig:generic}b). If we assume that the state is reconstructable,
then we can calculate the causal effect of any reconstructed state on
any future variable or process. The primary advantages of this
approach is that it is the minimum assumption required to calculate a
causal effect in the generic Earth system graph proposed in Figure
\ref{fig:generic}a. However there is no free lunch: the significant
disadvantage of this approach is that we cannot examine the causal
effect of a specific variable (e.g. $C(t)$) on another
(e.g. $E(t+1)$), because the mapping from individual observations to a
state space reconstruction transforms the individual observation's
importance to additionally include the unknowable and observed
portions of the state space. So, an intervention on any individual
observation is of ambiguous meaning (e.g. we do not know what are the
unobserved variables we are intervening on). Instead, we limit
ourselves to only examining the causal effect of changes in the entire
state holistically. Additionally, this approach requires a shift in
interpretation from the relatively straightforward interventions on
observable variables we have considered thus far to one where we
intervene on the entire state.

For example, consider that we reconstructed our state space from
available observations, and this reconstruction reduced to a discrete
state space of 10 states, with associated patterns in the observations
at time $\leq t$. If we are interested in the effect of a change in
state on a process at time $t+1$, for example a change from state $1$
to state $2$, this corresponds to an intervention on the
\textit{entire state space at time $t$}. This includes the unobserved
portions of the state space. So, the intervention no longer consists
of just intervening on the observed variables to change them from
observations consistent with state $1$ to state $2$, but instead
intervening on the observed variables \emph{and all unobserved
  variables consistent with the system and changes from state $1$ to
  $2$.}  Conceptualizing unknowable changes in unobserved variables
represents a significant barrier to interpretation, and motivates the
exploration of stronger assumptions that result in a clearer
interpretation (see Section \ref{sec:miss-temp-observ},
\ref{sec:observ-port-state}, \ref{human}).

In practice we also do not know the number of lagged observations that
are required for reconstruction of the state space at time $t$. One
approach is to use the data for guidance. This involves predicting the
effect at time $t+1$ with iteratively increasing numbers of lags. When
the addition of more time lags does not improve the prediction of
variables at time $t+1$, we have some confidence that the relevant
portions of state space at time $t$ has been reconstructed by the
lagged time series (e.g., we have defined the embedding dimension of
the attractor) \citep{Sugihara496}. However even this approach can be
problematic; while predictive power may plateau as we add more
temporal observations back in time, there are no guarantees that we
would not gain causally relevant knowledge from observations further
back in time. For example, a significant drought last year may impact
ecosystem state in the current year, but predictive power may locally
plateau going back in time two months (i.e. when the system exhibits
both long and short term memory). This example highlights the
challenges associated with any method relying on state space
reconstruction with lagged observations: to be sure we reconstruct the
state space we must include observations from a potentially infinite
temporal extent, and there might not be any way to check that we
successfully reconstructed the state space.

\subsection{Missing temporal observations induce independent random
  variations in cause and effect}
\label{sec:miss-temp-observ}

If we can assume that the missing temporal observations
(e.g. $S(t-1/2)$ in Figure \ref{fig:generic}a) induce independent
random variations in the cause and effect, conditional on $S(t-1)$,
then the causal graph reduces to Figure \ref{fig:generic}c. In this
case, if we can reconstruct the state space at time $t-1$ using lagged
observations at time t $\leq t-1$, then we can block all backdoor
paths between our cause $C(t)$ and any future effect $E(t+1)$. In this
case, the causal effect would be calculated as:

\begin{equation}
  P(E(t+1)| do(C(t)=c)) = \int_{S(t-1)} P(E(t+1) \, | \, C(t)=c,
  S(t-1) = s
  )\; P(S(t-1)=s) \, d s,
\end{equation}

where $S(t-1)$ is reconstructed from time lags of observations at
times $\leq t-1$. From the graph it may appear that we could also
block backdoor paths by conditioning on $S'(t)$. However, under these
assumptions $S'(t)$ is incalculable because if we attempt to
reconstruct $S'(t)$ using lagged observations of the state space, the
reconstruction will estimate $S$ rather than $S'$, which includes
$C(t)$ because $C$ is a part of the state space. So, a portion of the
cause's role in the system's evolution will be falsely incorporated
into the reconstruction of the state space, and our causal effect will
be biased.

The assumption that missing temporal observations induce independent
random variations in the cause and effect is required because
otherwise there would be an open backdoor path between the cause and
effect through the unobserved time slice (e.g. at time $t-1/2$ in
Figure \ref{fig:generic}a). Relative to Section
\ref{sec:stat-reconstr-state}, the advantage of this approach to
causal inference is that we can calculate the causal effects of
individual observations (e.g, $C(t)$ on $E(T)$), rather than needing
to interpret the causal impact of the entire state holistically (e.g.,
$S(t)$ on $E(T)$). However, this approach requires an additional
assumption that the missing temporal observations do not induce
dependencies between the cause and effect of interest. As with Section
\ref{sec:stat-reconstr-state}, we must be able to reconstruct the
state space, which may not always be possible, and may also confuse
interpretation.


\subsection{The unobserved portion of the state space does not affect
  the effect}
\label{sec:observ-port-state}

If we assume that we observe all portions of the state space that
affect the effect, then we can calculate the effect of any state
variable on future processes. In this case, the graph is as in Figure
\ref{fig:generic}c, but $S'(t)$ corresponds to all observations at
time $t$ not including $C$, and so can be used to block all backdoor
paths. If we can assume that there are no interactions between
observations at time $t$ then we can calculate the causal effect as:

\begin{equation}
  P(E(t+1)| do(C(t)=c)) = \int_{S'(t)} P(E(t+1) \, | \, C(t)=c,
  S'(t) = s
  )\; P(S'(t-1)=s) \, d \, s,
\end{equation}

where $S'(t)$ are all observations at time $t$, not including the
cause $C(t)$. However, when blocking backdoor paths with simultaneous
observations it is important to consider whether there are
interactions between observations at time $t$, and whether the
observations are truly simultaneous. Whether there are interactions
between observations is a function of the temporal and spatial extent
of the observations. If observations are instantaneous point
observations indexed in time, then interactions between them can
likely be ignored. However, often the spatial and/or temporal extents
of observations overlap, and in this case an assumption of zero
interactions between observations is not justified. In this case, we
can still block backdoor paths by conditioning on past observations
($S(t-1)$):

\begin{equation}
  P(E(t+1)| do(C(t)=c)) = \int_{S(t-1)} P(E(t+1) \, | \, C(t)=c,
  S(t-1) = s
  )\; P(S(t-1)=s) \, d \, s.
\end{equation}

The assumption that we observe all variables relevant to an effect is
a strong assumption. However, it provides significant benefits both in
terms of the statistical complexity of estimating the causal effect,
as well as in interpretation of the causal effect. We do not need to
reconstruct the state space  using lagged observations, which can be a
statistically and computationally challenging problem. Additionally,
the assumption that we observe everything relevant to the effect is
much easier to interpret relative to an assumption about the degree to
which we can (or cannot) reconstruct the relevant state space with
lagged observations.

\subsection{Applications at the human-Earth system interface: when the
  cause is approximately independent of the system.}
\label{human}

Causal inference becomes substantially more tractable under an
assumption that our causes of interest are independent from the
evolution of the state space (Figure \ref{fig:forcing}). While such a
strong assumption may seem unjustifiable due to tight coupling within
the Earth system, recent historical examples suggest that this
assumption may be applicable to some scenarios. For example,
coordinated global human response to global warming is relatively
independent of the climate state \citep{arto2014drivers}. We have
failed to reduce green house gas emissions even as global temperature
increased. Instances of reduced rises in global green house gas
emissions are usually due to global economic recession (e.g. the 2008
financial crisis) or pandemic (COVID-19 crisis) rather than factors
directly tied to the climate state. In these examples many global
social, political, health, and economic factors are the primary causes
of global green house gas emission, and while the climate system may
affect these factors, the historical evidence suggests that the
climate system exerts a relatively small impact
\citep{arto2014drivers}.

\begin{figure}
  \includegraphics[]{forcing-graph.pdf}
  \caption{A generic graph asserting an assumption that there are
    forcing external to the evolution of the state-space}
  \label{fig:forcing}
\end{figure}

Generally this logic applies to many scenarios on the "human-climate"
interface, such as land-use land-cover change in urban centers where
urban planning is relatively independent of recent climate
history. The general graph in Figure \ref{fig:forcing} is applicable
to any analyses for which: 1) we wish to examine the effect of human
behavior on the environment, and 2) we can assume human behavior is
approximately independent of the climate state. Because the climate
state space does not affect the cause (human behavior), there are no
unblocked backdoor paths through the unobserved portions of the state
space. Causal inference is particularly tractable for this class of
problems.

\section{Conclusions}

In summary, we conclude that:

\begin{itemize}
\item Causal inference from data is a new tool with the potential to
  complement traditional scientific methods, such as numerical and
  real world experimentation. In Earth science, numerical models rely
  on approximations that deviate modeled physics from reality, and
  real world experimentation may be intractable or unethical. Causal
  inference is a third tool to estimate the effect of prescribed
  experimentation on physical processes. Causal inference has a
  different set of advantages and disadvantages, and is a powerful
  complement to numerical and real world experimentation.
\item Causal graphs concisely and clearly encode assumptions about
  causal dependencies between processes. Including a causal graph
  benefits any observational analysis, including those that use
  regression. Depending on the observations available and the causal
  structure of the system, regression analyses can be interpreted as
  an approximation to the average causal effect.
\item Whether or not a causal effect can be calculated from data is
  determined exclusively by the causal graph. Thus the tractability of
  a causal analyses, or the strength of assumptions necessary to make
  an analysis tractable, is determined and assessed before collecting,
  generating, or manipulating data (which can cost a tremendous amount
  in terms of researchers' time, computational resources, and/or
  funding). We recommend early causal analyses to determine
  tractability during a project's conception, before resources are
  spent obtaining or analyzing data.
\item Because the Earth system evolves as a dynamical system through
  time, we can construct generic Earth system causal graphs
  applicable to a wide range of scenarios. However, causal inference
  in Earth science also presents challenges: we only partially observe
  the state space of the system.
\item These challenges can be alleviated by applying causal theory to
  generic causal graphs of the Earth system and identifying the
  assumptions necessary for causal inference from data. These are
  assumptions that:
  \begin{itemize}
  \item The state space of the system is reconstructable
    from lagged observations of the system, as allowed by
    Takens' theorem (Section \ref{sec:stat-reconstr-state}, Section \ref{sec:miss-temp-observ}), or
  \item The effect of interest is only causally
    affected by the observed portion of the state space (Section
    \ref{sec:observ-port-state}), or
  \item The cause of interest can be assumed to be independent of the
    evolution of the system's state (e.g. forcing) (Section
    \ref{human}).
  \end{itemize}
\end{itemize}

Here we focus on the fundamentals of calculating causal effects from
data. However, causal inference is a thriving active area of research,
and there are many other causal inference techniques and abstractions
that would benefit the Earth system research community. For example,
there are techniques for representing variables observed under
selection bias in the causal graph and analyzing whether a causal
effect can be calculated (i.e. identified) given the selection bias
\citep[e.g.,][]{bareinboim2014recovering}. Selection bias is very
relevant in Earth science. For example, satellite observations are
almost always collected under selection bias (e.g. they sample at
certain local times of the day, clouds obscure surface data,
etc.). Additionally, transportability
\citep[e.g.,][]{bareinboim2012transportability} identifies whether one
can calculate a causal effect in a passively observed target domain,
by merging experiments from source domains that may differ from the
target domain. A potential application for transportability in earth
sciences would be to merge numerical model experiments (e.g., global
climate models, cloud models, etc.) and formally transport their
results to the real world. In this case, numerical models are the
source domains that differ from the target domain (``real world'') due
to approximations. Given the limitations of explicit experiments in
Earth science, we hope that causal methods gain wider adoption in
Earth science and that this manuscript provides the necessary
foundation for proper application of causal inference in Earth
science.



\bibliography{references.bib}

\appendix
\section{Basic probability and syntax}
\label{prob-theory}

In this paper we use capital letters to represent random variables
(e.g., ``$X$''). For example, $P(X)$ is the probability distribution
of a random variable $X$. $P(X)$ is a function of one variable that
outputs a probability (or density, in the case of continuous
variables) given a specific value for $X$. We represent specific
values that a random variable can take with lowercase letters (e.g.,
$x$ in the case of $X$). $P(X)$ is shorthand; a more descriptive but
less concise way to write $P(X)$ is $P(X=x)$ which represents the fact
that $P(X)$ is a function of a specific value of $X$, represented by
$x$. We use both notations, and $P(X)$ has the same meaning as
$P(X=x)$.

For the unfamiliar reader, there are a few basic rules and definitions
in probability that provide relatively complete foundations for
building deeper understanding of probability. These are the \textbf{sum rule}:

\begin{equation}
  P(X=x) = \sum_Y P(X=x,\, Y=y)
  \label{eq:sum}
\end{equation}

and the \textbf{product rule}:

\begin{equation}
  P(X=x, \, Y=y) = P(X = x \, | \, Y=y ) P(Y=y) = P(Y = y \, | \, X=x ) P(X=x)
  \label{eq:product}
\end{equation}

The \textit{joint probability distribution} ($P(X=x,Y=y)$) is the
probability that the random variable $X$ equals some value $x$ \emph{and} the
random variable $Y$ equals $y$. The joint distribution is a function
of two variables, $x$ and $y$ which are values in the domains of the
random variables $X$ and $Y$ respectively. The \textit{conditional
  probability distribution} ($p(X = x \, | \, Y=y )$) is also a
function of two variables $x$ and $y$, but it is the probability of
observing $X$ equal to $x$, given that we have observed $Y$ equal to
$y$. In other words, if we filter our domain to only values where
$Y=y$, then $p(X = x \, | \, Y=y )$ is the probability of
observing $X=x$ in this sub-domain where $Y=y$. The \textit{marginal
  probability distribution} ($P(Y=y)$) is just the probability that
$Y$ equals some value $y$, and is a function of only $y$. We can
calculate the marginal probability from the joint distribution by
summing over all possible values values of the other random variables
in the joint (the ``sum rule'' - Equation (\ref{eq:sum})). Additionally,
the joint distribution can factorize into a product of conditional and
marginal distributions (``the product rule'' - Equation
(\ref{eq:product})). These two simple rules can be used to build much of the
theory and applications of probability theory (e.g., Bayes' theorem
$P(Y|X) =\frac{P(X|Y) P(Y)}{P(X)}$). While Equations (\ref{eq:sum})
deals with probability distributions of discrete random variables,
there is also a sum rule analog for continuous random variables and
probability density functions (the syntax of the product rule is the
same):

\begin{equation*}
  P(X=x) = \int_Y P(X=x,\, Y=y) \, dy
\end{equation*}

where $\int_{Y}$ represents an integral over the domain of $Y$ (e.g.,
$\int_{-\infty}^{\infty}$ if $Y$ is a Gaussian random variable).


\end{document}