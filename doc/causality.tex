\documentclass[12pt]{article}
\input{def}
\graphicspath{{figs/}}

\begin{document}

\title{Causal inference in Earth science}

\author{Adam Massmann\thanks{Corresponding author:
    akm2203@columbia.edu}, Pierre Gentine, need to contact: Elias
  Bareinboim, Jakob Runge?}

\maketitle

\section{Introduction}

Controlled experimentation is the traditional path to scientific
discovery. The scientist tests hypotheses about a system's nature by
systematically varying experiment parameters and measuring the
response. Climate and Earth system scientists primarily use numerical
models for experimentation \citep[e.g.,][]{eyring-cmip6-2016}, but
real world experiment is also used to a lesser degree
\citep[e.g.,][]{ainsworth-face-2005}. However, it may be logistically
impossible or unethical to execute many real world experiments, and
numerical experiments may rely on approximations that bias
experimental results relative to the real world
\citep[e.g.,][]{kim-cmip5,stillmann-cmip5-extremes}. Given the
limitations of real world and numerical experiments in Earth science,
researchers require additional tools for scientific discovery.
\citet{pearl-1994-do-calculus} introduced one such tool: the
\textit{do-}calculus for calculating the causal effects of
experimental interventions based on passive observations of a system
and assumptions about causal dependencies in the system. In other
words, given observational data about a system one can use
\textit{do}-calculus to calculate an experimental effect from data
without conducting a specific experiment. This is a powerful tool for
Earth scientists that complements numerical experimentation. When
numerical modeling assumptions break down, causal inference may be a
tractable path towards scientific discovery.

However, causal inference from data presents its own challenges; the
causal effect must be identifiable from assumptions about the causal
dependencies of system processes and available observations. If a
causal effect is unidentifiable, then the causal effect cannot be
calulated from data, even with samples spanning the entire joint
distribution of observed variables \citep[][]{shpitser2006}. Specific
to problems in Earth science, the identification of causal effects is
challenging given two fundamental issues: 1) the system evolves
through time according to an underlying dynamical system, and 2) we
only partially observe the state space of that dynamical system
\citep{majda-state}. The main contribution of this paper is the
identification of the necessary assumptions for applying causal
inference in Earth systems. We identify these assumptions by applying
graph theory developed in \citet{pearl1995causal} to generic Earth
science scenarios. There is the potential for applying causal
inference when we can assume:

\begin{itemize}
\item The effect of interest is only causally affected by the observed
  portion of the state space (Section \ref{sec:observ-port-state}), or
\item The cause of interest is independent of the evolution of the
  system's state (e.g. forcing) (Section \ref{human}), or
\item The state space of the system is statistically reconstructable
  from available observations (Section \ref{sec:stat-reconstr-state},
  Section \ref{sec:miss-temp-observ})

\end{itemize}

Our theoretical results identifying tractable problems in Earth
science require a few fundamentals from the causal inference
literature, so we introduce causal inference theory, causal graphs,
and \citet{pearl2009}'s \textit{do-}calculus for the unfamiliar reader
(Section \ref{sec:causal-graphs-pearls}), and compare with recent
Earth science literature on the related field of causal discovery
(causal discovery attempts to ``discover'' the causal graph from
observations, see Section \ref{sec:discovery}). Causal effects, due to
their underlying logic and clear interpretation, are an exciting tool
for scientific discovery and understanding
\citep{hannart-da,naveau-2020}. This manuscript establishes the
conditions required for the proper application of causal inference in
Earth science.


\section{Causal graphs and Pearl's do calculus}
\label{sec:causal-graphs-pearls}
% intro causal graphs}

Causal graphs, introduced in \citet{pearl1995causal}, are directed
acyclic graphs (DAGs)\footnote{define DAG?} that encode our
assumptions about the causal dependencies of a system. Causal graphs
are useful tools because they can be drawn by any domain expert with
no required knowledge of math or probability, but they also represent
formal mathematical objects with specific meaning. A domain expert
simply draws directed edges (e.g. arrows) from variables that are
causes to effects. We illustrate causal graphs and their mathematical
consequences with a simplified toy example examining clouds, aerosols,
and surface solar radiation/sunlight (Figure \ref{fig:toy}A). Our
causal graph consists of:

\begin{figure}
  % % consider \noindent\include... [width=0.75\textwidth]...
  % \includegraphics[height=0.4\textheight]{cloud-aerosol-bidirected.pdf}\\
  \scalebox{1.0}{\input{figs/cloud-aerosol.tex}}
  \caption{A toy graph example to demonstrate basic causal theory,
    involving cloud (C), aerosol (A), and surface solar radiation
    (S). In \textbf{A)} we observe all variables, while in \textbf{B)}
    we do not observe aerosol and we use the semantic of a dashed node
    to denote the unobserved variable. \textbf{C)} presents an
    alternative notation for representing an unobserved or hidden
    common cause that is popular in causal literature \citep[e.g.,
    ``semi-markovian graphs'',][]{shpitser2006} and usually only
    includes observed quantites as nodes in the graph. However in
    Earth Science we often observe much less of the system relative to
    our knowledge of causal dependencies in the system, so we find it
    more conceptually clear to include unobserved common causes
    explicitly in the graph, and prefer the notation in \textbf{B)} to
    \textbf{C}). Any semi-markovian graph can be represented as a
    graph with unobserved nodes, and vice-versa
    \citep[e.g.,][]{lee2019structural}.}
  \label{fig:toy}
\end{figure}

\begin{enumerate}
\item An edge from aerosols to clouds because aerosols serve as cloud
  condensation nuclei and affect the probability of water vapor
  conversion to cloud.
\item An edge from aerosols to surface solar radiation, because
  aerosols can reflect sunlight back to space and reduce sunlight
  at the surface.
\item An edge from clouds to sunlight, because clouds also reflect
  sunlight back to space and can reduce sunlight at the surface.
\end{enumerate}

Causal graphs encode our assumptions about how the system behaves, and
the nodes and edges that are \textit{missing} from the graph often
represent strong assumptions. For example, in the
cloud-aerosol-sunlight example, clouds also affect aerosols; e.g., by
increasing the likelihood that aerosol will be scavenged from the
atmosphere during precipitation
\citep[e.g.,][]{radke-scavenge-1980}. By not including an edge from
cloud to aerosol, we are making a strong assumption that we are
ignoring the effect of clouds on aerosols. Considering this example is
intended to be pedagogical for introducing causal theory to the
readers, we will continue with the graph as drawn in Figure
\ref{fig:toy} (Section \ref{sec:necess-cond-caus} explores realistic
Earth system graphs).

Even though probablistic reasoning is not required to construct a
causal graph, the resulting graph encodes specific probablistic
meaning. Interpreted as a general probabilistic graphical model, our
example graph in Figure \ref{fig:toy}A represents a specific
factorization of the joint distribution into conditional and marginal
factors:

\begin{equation}
  P(A, C, S) = P(S \, | \,C, A) \, P(C \, | \, A) \, P(A),
\end{equation}

where $A$ represents aerosol, $C$ represents cloud, and $S$ represents
surface sunlight/solar radiation (for the reader unfamiliar with basic
probability calculations, a brief introduction is provided in Appendix
XX). Interpreted causally, as in \citet{pearl1995causal} and this
manuscript, the directed edges encode causal dependencies in addition
to a factorization of the joint. More specifically, each node is
causally determined by its parents, as well as some random variation
due to processes not explicitly considered in the graph. For example,
sources of aerosol variability not considered in Figure \ref{fig:toy}A
include anthropogenic aerosol emission, the biosphere, fires,
volcanoes, etc. For cloud, this includes synoptic forcing, atmospheric
humdity, etc. For radiation, this includes variability of top of
atmosphere radiation, etc. The causal graph, as drawn, encdoes the
assumption that all of these sources of randomness are independent of
each other. The representation of ramdomness in causal graphs is a
powerful tool: by positing a causal graph, we are not stating that the
variables in the graph are the only processes in the system. Instead,
we are stating that all other processes not included in the graph
induce variations in the causal variables that are independent of each
other. For a deeper look at causal graphs and their underlying theory
based on structural causal models (SCMs) we refer the reader to
\citet{pearl2009}. We find that the causal graph representation is
more intuitive to domain experts than the underlying SCM-based theory,
so we focus on graph-based theory in our application of causal
inference to earth science.

We can apply causal graph theory
\citep[e.g.,][]{pearl1995causal,shpitser2006} to the assumptions
encoded in our causal graph to identify which distributions we must
estimate from data in order to calculate a causal effect of
interest. More precisely, ``caluclating a causal effect'' refers to
estimating the probability distribution of a response (e.g. sunlight)
to an experimental intervention on our cause where we artificially set
it to a value of our choosing (e.g. presence or absence of a
cloud). The challenge of causal inference is to derive the response to
the intervention in terms of only observed distributions. This process
of identifying the necessary observed distributions is formally termed
\emph{causal identification}. If a causal effect is not identifiable
(\emph{un}-identifiable), for example if calculating a causal effect
requires distributions of variables that we do not observe, then we
cannot use causal inference to calculate a causal effect, even with an
infinite sample of data.

% backdoor path}

A necessary condition for unidentifiability is the presence of an
unblocked backdoor path from cause to effect. Backdoor paths are any
paths going through parents of the cause to the effect. We can block
these paths by selectively observing variables such that no
information passes through them \citep{geiger-d-sep}. If we can
observe variables along the backdoor paths such that they are blocked,
then we have satisfied the \emph{back-door criterion}
\citep{pearl2009} and we can calculate unbiased causal effects from
data.

\begin{figure}
  \input{figs/mutilated-cloud-aerosol.tex}
  \caption{A mutilation of Figure \ref{fig:toy}(A), where we have
    removed directed causal paths from the cause (cloud) to the effect
    (surface solar radiation). There is covariability between cloud
    and surface solar radiation that is not due to the causal
    connection between cloud and surface solar radiation, but is
    instead due to aerosol's role as a common driver.}
  \label{fig:mutilated-toy}
\end{figure}

% backdoor path with example}
Understanding backdoor paths and the backdoor criterion is helped by
example. Returning to our toy example (Figure \ref{fig:toy}A), we
attempt to calculate the causal effect of clouds on sunlight. In other
words, we want to isolate the variability of sunlight due to the
causal link from cloud to sunlight (Figure \ref{fig:toy}A). However,
aerosols both affect cloud (edge from aerosol to cloud), and sunlight,
so if we naively calculate a causal effect we would get a biased
estimate of the mean effect of cloud on sunlight. To demonstrate this,
consider simulated cloud, aerosol, and sunlight data with causal
dependencies consistent with Figure \ref{fig:toy}A.

\begin{align}
  aerosol &\sim \text{uniform (0, 1]}\\
  cloud &\sim \text{bernoulli (aerosol)}\\
  sunlight &:= \begin{cases}
    \text{Cloudy} &: 0.6 \cdot \text{downwelling clear sky radiation}  \\
    \text{Clear} &: \text{downwelling clear sky radiation}
  \end{cases},
                   \label{eq:1}
\end{align}

and:

\begin{equation*}
  \text{downwelling clear sky radiation} = TOA \, \cdot \, (1 - aerosol); \;
  TOA \sim \text{Normal(340 W m$^{-2}$, 30 \, W m$^{-2}$)}
\end{equation*}

Now, consider not knowing the underlying generative processes, but
instead just passively observing cloud and sunlight. If one were
interested in calculating the effect of cloud on sunlight, and aerosol
data were not available or one were very naive, one approach would be
to bin the data by cloudy and clear conditions and compare the amount
of sunlight between cloudy and clear observations (Figure
\ref{fig:naive-cloud-sunlight}). This approach suggests that clouds
reduce sunlight by, on average, 160 W m$^{-2}$, which is a strong
overestimation of the true average effect of clouds (-68 W m$^{-2}$),
derived from Equation (\ref{eq:1}). Aerosol induces co-variability
between cloud and aerosol that is unrelated to the causal link from
cloud to aerosol. Graphically, this is clarified by removing all edges
from our cause (cloud) to children of our cause (in this case
sunlight) to create a ``mutilated'' graph (Figure
\ref{fig:mutilated-toy}). We see that clouds are not independent of
surface solar radiation in the mutilated graph.  However if aerosol
were fixed (e.g. observed or not varying), cloud and sunlight would be
independent of each other in Figure \ref{fig:mutilated-toy}. So with
aerosol fixed, all co-variability between cloud and sunlight is only
due to the causal edge between cloud and sunlight in Figure
\ref{fig:toy}(A).  Mathematically incorporating the requirement that
we must condition on aerosol to isolate the causal effect of cloud on
radiation gives the identification of the causal effect of cloud and
aerosol according by satisfying the backdoor criterion with
\textit{adjustment} on aerosol:

\begin{figure}
  \includegraphics[]{naiveCloudSunlight.pdf}
  \caption{A naive approach to estimating the ``effect'' of clouds on
    sunlight: bin observations by cloudy and clear day, and compare
    the values of sunlight. This approach yields a large
    overestimation of the true causal effect of clouds on sunlight,
    which is -68.0 W m$^{-2}$}
  \label{fig:naive-cloud-sunlight}
\end{figure}

\begin{equation}
  P(S | do(C = c)) = \int_{a} P(S \, | \, C = c,
  A=a) \, P(A=a) \; da,
  \label{eq:3}
\end{equation}

where the \textit{do}-calculus \citep{pearl2009} term
($P(S \, | \, do(C\, = \,c))$) represents the probability of sunlight
if we did an experiment where we intervened and set cloud to a value
of our choosing (in this case $c$, which could be ``True'' for the
presence of a cloud, or ``False'' for no cloud). In the case that
observations of aerosols are not available (e.g., Figure
\ref{fig:toy}B, C), our causal effect is not identifiable and we
cannot use causal inference no matter how large the sample sizes of
clouds and sunlight. This is a powerful time saving research tool:
after encoding our domain knowledge in a causal graph, we can analyze
the causal graph and available observations to determine whether a
causal calculation is possible, \textit{without needing to collect,
  download, or manipulate any data}. For more complicated graphs,
causal identification can also be automated \citep{shpitser2006}. We
later use this theory to theoretically assess which general problems
are tractable in Earth science using causal inference (Section
\ref{sec:necess-cond-caus}).

Once we have established that a causal effect is identifiable from
data, we must estimate the required observational distributions
(Equation (\ref{eq:3})) from data. Often it may be more computationally
tractable to calculate an average causal effect, rather than the full
causal distribution $P(S | do(C=c))$. Returning to our toy example
(Figure \ref{fig:toy}(A)), the average effect is defined as:

\begin{equation}
  \mathbb{E}(S | do(C = c)) = \int_{s} s \, P(S = s
  | do(C=c)) \, ds,
  \label{eq:4}
\end{equation}

where $\mathbb{E}$ is the expected value. Substituting Equation
(\ref{eq:3}) into Equation (\ref{eq:4}), and rearranging gives:

\begin{equation}
  \mathbb{E}(S | do(C = c))  = \int_{a} P(A=a) \; \mathbb{E}(S=s |
  C=c, A=a) \, d a,
  \label{eq:5}
\end{equation}

Where $\mathbb{E}(S=s \, | \, C=c, A=a)$ is just a regression of sunlight on
cloud and aerosol. Estimating the marginal $P(A)$ is difficult, but
if we assume that our observations are independent and identically
distributed (IID) and we have a large enough sample, we can use the
law of large numbers to approximate Equation (\ref{eq:5}). The law of
large numbers states that if we observe $n$ IID samples of some process, in
this case $A$ (e.g., $a_1$, $a_2$, $\ldots$, $a_n$), then for any
function $f$:

\begin{equation}
  \frac{1}{n} \sum_{i=1}^n f(a_i) \to \int_a P(A=a) f(a) \, d a.
  \label{eq:lln}
\end{equation}

In Equation (\ref{eq:5}), $c$ is fixed by the intervention, so
$\mathbb{E}(S=s | C=c, A=a)$ is just a function of $a$, and we can use
Equation (\ref{eq:lln}) to justify an approximation to Equation
(\ref{eq:5}) with:

\begin{equation}
  \mathbb{E}(S | do(C = c))  \approx \frac{1}{n} \sum_{i=1}^n \mathbb{E}(S=s_i |
  C=c, A=a_i).
  \label{eq:6}
\end{equation}

Data or prior knowledge can inform the regression function for
$\mathbb{E}(S=s_i | C=c, A=a_i)$. In the toy example, a linear model
conditional on cloud appears to be a good choice of regression
function (Figure \ref{fig:linear}). The causal effect of clouds on
sunlight as calculated using Equation (\ref{eq:6})) (e.g.
$\mathbb{E}(S | do(C = \text{cloudy})) - \mathbb{E}(S | do(C =
\text{clear}))$) is -68.52 W m$^{-2}$, which closely matches the true
causal effect from Equation (\ref{eq:1}) of -68 W m$^{-2}$. This
example demonstrates how causal inference and theory can be used to
calculate unbiased average effects using regression. Further, causal
inference can be used to justify and communicate assumptions in any
observational analyses employing regression. In the best case, the
causal effect is identifiable from the available observations, and the
regression analysis can be framed as an average causal effect. In the
worst case that identification is not possible from the available
observations, one may present the regression as observed associations
between variables. However, presentation of a causal graph still aids
the reader: the reader can see from the causal graph what the
confounders and unobserved sources of covariability are between the
predictors and the output. In all cases, the presentation of a causal
graph makes explicit the assumptions about the causal dependencies of
the system. Wherever possible, we recommend including causal graphs
with any observation-based analyses.

In summary of the main points of this introduction to causal graphical
models and \textit{do-}calculus:

\begin{itemize}
\item Graphical causal models encode our assumptions about causal
  dependencies in a system (edges are drawn \emph{from} causes
  \emph{to} effects).
\item In order to calculate an unbiased causal effect from data, we
  must isolate the covariability between cause and effect that is due
  to the directed causal path from cause to effect. The presence of
  non-causal dependencies between the cause and effect can be deduced
  from the causal graph: the presence of an unblocked backdoor path
  from the cause to the effect leads to non-causal dependencies (and
  co-variation).
\item The backdoor criterion identifies the distributions we must
  calculate from data in order to block a backdoor path, remove
  non-causal dependence between the cause and effect, and calculate an
  unbiased causal effect from data.
\item The \emph{average} causal effect can be reliably approximated
  with regression (Equation (\ref{eq:6})) derived from the backdoor
  criterion. In this scenario, causal theory and graphs identify the
  variables that should (and should not be) included in the regression
  to calculate an unbiased causal effect.
\item Causal identification is a flexible tool that provides the
  distributions that must be estimated from data, while making no
  assumptions about the forms of those distributions. However,
  parametric assumptions can be applied to make the calculation of
  those distributions from data more computationally tractable.
\end{itemize}

\begin{figure}
  \includegraphics[]{aerosolSunlight.pdf}
  \caption{A linear relationship between aerosol and sunlight,
    conditional on cloud. If we use linear regression to calculate the
    average causal effect of cloud on sunlight, as in Equation
    (\ref{eq:6}), our result is very close to the true causal effect
    of -68.0 W m$^{-2}$.}
  \label{fig:linear}
\end{figure}

Here we focused on the backdoor criterion to block backdoor paths. An
un-blockable backdoor path from the cause to the effect is a necessary
condition for unidentifiability. However, it is not sufficient
(e.g. there are other identification strategies like the front door
criterion and instrumental variables that do not rely on observing
variables along the backdoor path). For a complete discussion of
sufficient conditions for unidentifiability we refer you to
\citet{shpitser2006}. For the purpose of identifying generally
tractable causal inference approaches in Earth science (Section
\ref{sec:necess-cond-caus}), we focus the backdoor criterion. Given
that the Earth system evolves continuously according to an underlying
dynamical system and we only partially observe the state space in both
space and time, these other identification strategies are not as
applicable, and an unblockable backdoor path is a sufficient condition
for unidentifiability in the types of graphs that are representative
of Earth science systems (Figure \ref{fig:generic})
\citep{tian2002general}. In other words, blocking backdoor paths is a
requirement for calculating a causal effect in graphs of the form
presented in Figure \ref{fig:generic}.

\section{Relation to previous work, ``causal discovery'', and
  clarification on terminology}
\label{sec:discovery}

The term ``causal inference'' has been used to describe two
techniques:

\begin{enumerate}
\item \textbf{Causal effect inference}: Calculating the causal effect
  of some processes on other, given data and assumptions about the
  causal structure of the system.
\item \textbf{Causal structure discovery}: Inferring the causal
  structure (e.g. the causal graph) of the system using data.
\end{enumerate}

To summarize, \textit{causal effect inference (1)} calculates the
magnitude of a causal effect given: 1) a causal graph drawn by a
domain expert, and 2) data. On the other hand, \textit{causal
  structure discovery (2)} does not caclualte any causal effects at
all, but instead generates a causal graph from data.  This paper
focuses on causal inference as (1): calculating causal effects from
data (Section \ref{sec:causal-graphs-pearls}). Inferring the causal
structure of the system (2), is generally much more difficult and also
requires additional assumptions. For example, some causal structure
discovery algorithms rely on assumptions that we observe all relevant
variables to the system (violated because we partially observe the
state space) and/or possibly arbitrary parameters for statistical
independence tests \citep{runge2019inferring}. Additionally, some
methods invoke linearity assumptions about the relationships between
processes \citep{krich2019causal}, which is not generally true for the
Earth system \citep{palmer-nonlinaer-1999}.

\textit{/ TODO: a messy start to tactfully critique causal discovery
  is here; clean this up. think pierre wanted it here, but I rewrote
  both so see how it all flows together and reorganize as
  necessary. also add jakob to maybe fill this out, especially re: the
  motivation of causal discovery. not sure how hard to come down on
  causal discovery. my heart wants to hammer it, but my brain tells me
  that is a bad idea.}

However, there has been considerable work and effort in applying
causal structure discovery (2) in Earth science
\citep[e.g.,][]{ebert-uphoff2012,
  samarasinghe-casuality,runge-causal-timeseries,runge2019inferring,goodwell-causality-2020}. Causal
discovery algorithms filter and infer the direction of causal links in
the system, usually using conditional independence detection
algorithms that rely on signficiance parameters. In contrast to causal
inference of effects, which we explore in this paper, causal discovery
algoirthms do not directly incorporate domain knowledge on the causal
dependencies of processes in the system (although domain knowledge may
guide assumptions about linearity of processes, and the observations
that must be included in the causal discovery algorithm). Indeed, our
persepctive here is that we have often acquired substantial
understanding of the mechanisms at play and their causal
relationships, which we want to exploit: that is formally combine
domain knowledge with data science. For example, given our domain
knowledge of the Earth science system we generally have high
confidence about the causal structure of the system. We can identify
the state variables and know that the state at time \(t\) determines
the state at time \(t+1\), even if the exact functional form of the
dependency through time is not known. Therefore, we can write down a
causal graph and do not need to infer graph structure from data
(Section \ref{sec:necess-cond-caus}). It is possible some links in
these causal graphs correspond to small effects, and these links would
be removed through causal structure discovery. However, directly
interpreting what constitutes a ``negligibly small'' effect
calculation presented in physical units and probabilities, as
calculated with causal effect inference, may be more transparent than
interpreting missing links derived from causal structure discovery
significance parameters. In other words, direct calculation of effects
may be more transparent and interpretable for many readers, relative
to a causal graph derived from significance parameters with more
abstract meaning. Additionally, calculating an effect of some
processes upon others illuminates more information about the system
than the binary existence of a link or no link, as is output by causal
structure discovery algorithms.

However, ultimately we view causal effect inference and causal
structure discovery as complementary tools. Causal effect inference is
more useful in scnearios where elevated domain knowledge gives a
priori confidence in causal graph structure, while causal structure
discovery is more useful when we have very limited domain knowledge
but access to observations of all relevant processes to a
problem. Additionally, causal effect inference can be used as a second
step after causal dsicovery to calculate individual causal effects. We
hope to motivate further research effort in causal effect inference to
match recent efforts in causal structure discovery in Earth
science. Ideally causal effect inference and causal structure
discovery will co-evolve as complementary abstractions for causal
interpretation; researchers and readers can choose the method that
suits their assumptions, available data, and level of domain
knowledge.

\textit{TODO: make a conceptual graph with amount of data and amount
  of knowledge?}

\textit{ TODO: talk to Elias about ``no mixing'' theorem; from what he
  described it seems like it could lead to the invalidation of
  ``causal discovery''}

\section{Necessary conditions for causal identification in Earth
  systems}
\label{sec:necess-cond-caus}

\textit{pierre gave it to me, but in coronavirus chaos I lost the
  ``lorenz 1995/6'' citation. think it was a different year, maybe
  2005. check w/ pierre}

Earth science systems are dynamical systems evolving through time
according to an underlying system state
\citep{lorenz-1963,majda-state}. This offers both advantages and
challenges for causal inference. Challenges involve our partial
observation of the system's state space, while advantages include the
temporal ordering of events: we know that future events can have no
causal effect on the past.

Causal identification and tractable causal inference to Earth science
requires assumptions about the unobserved portions of the state
space. Without assumptions the unobserved portions of the state space
will introduce confounding for any causal affect of interest (Figure
\ref{fig:generic}a). For example, we generally do not observe the state
space at every time (e.g. $S(t-1/2)$ in Figure \ref{fig:generic}a), and
at any given time, we do not observe the state space at all locations
and for all state variables (e.g. $S(t)$ and $S(t-1)$ in Figure
\ref{fig:generic}a). So, if we are interested in the causal effect of
any state variable at time $t$ on some variable at time $t+1$ (e.g.,
$E$ in Figure \ref{fig:generic}a), then the causal effect will be
confounded by the unobserved portions of the state space, and
calculating a causal effect is impossible (un-identifiable) without
additional assumptions. We will apply causal graph theory to identify
the additional assumptions that would make the calculations of causal
effects tractable, and may be reasonable in many Earth science
situations.

\begin{figure}
  \input{figs/generic-graph.tex}
  \caption{Generic graphs of the Earth system state sequence, limited
    to a 3 time sequence subset of the infinite sequence. \textbf{A):}
    The reality of the observed earth system: unobserved nodes are
    outlined by dashed lines. We only observe the state space at
    certain times (e.g., no observations at $S(t-1/2)$). At times with
    observations, we only partially observe the full state ($S(t)$,
    $S(t-1)$). In the scenario that we are interested in calculating
    the causal effect of any portion of the state space at time $t$ on
    some effect ($E$) at time $t+1$, the causal effect will be
    confounded by the unobserved portions of the state space, and
    calculating the causal effect is impossible (un-identifiable)
    without additional assumptions. \textbf{B):} The reduction of the
    earth system graph under an assumption that we can reconstruct the
    state $S(t)$ from the observable portions of the state space at
    lagged times $< t$ (see Section
    \ref{sec:stat-reconstr-state}). \textbf{C):} The reduction of the
    earth system graph under an assumption that missing temporal
    observations (e.g. $S(t-1/2)$ in \textbf{A)}) induce independent
    random variations in the cause ($C(t)$) and effect
    ($E(t+1)$). $S'(t)$ denotes the state space, not including the
    cause $C(t)$ (see Sections
    \ref{sec:miss-temp-observ},\ref{sec:observ-port-state}).}
  \label{fig:generic}
\end{figure}

\subsection{Statistical reconstruction of the state space with time
  lagged observations}
\label{sec:stat-reconstr-state}

Takens' theorem implies that we can reconstruct the unobserved
portions of the state space using lagged observations back in time. In
this case, the causal graph is greatly simplified (Figure
\ref{fig:generic}b). If we assume that the state is reconstructable,
then we can calculate the causal effect of any reconstructed state on
any future variable or process. The primary advantages of this
approach is that it is the minimum assumption required to calculate a
causal effect in the generic Earth system graph proposed in Figure
\ref{fig:generic}a. However there is no free lunch: the significant
disadvantage of this approach is that we cannot examine the causal
effect of a specific variable (e.g. soil moisture at time $t$) on
another (e.g. evapotranspiration at time $t+1$), because individual
observations used to reconstruct the state space represent the
unknowable unobserved subsets of the state space, so an intervention
on any indiviual observation is of ambiguous meaning (e.g. we do not
know what are the unobserved variables we are intervening
on). Instead, we limit ourselves to only examining the causal effect
of changes in the entire state holistically. Additionally, this
approach requires a shift in interpretation from the relatively
straightforward interventions on observable variables we have
considered thus far to one where we intervene on the entire state.

For example, consider that we reconstructed our state space from
available observations, and this reconstruction reduced to a discrete
state space of 10 states, with associated patterns in the observations
at time $\leq t$. If we are interested in the effect of a change in
state on a process at time $t+1$, for example a change from state $1$
to state $2$, this corresponds to an intervention on the
\textit{entire state space at time $t$}. This includes the unobserved
portions of the state space. So, the intervention no longer consists
of just intervening on the observed variables to change them from
observations consistent with state $1$ to state $2$, but instead
intervening on the observed variables \emph{and all unobserved
  variables consistent with the system and changes from state $1$ to
  $2$.}  Conceptualizing unknowable changes in unobserved variables
represents a significant barrier to interpretation, and motivates the
exploration of stronger assumptions that result in a clearer
interpretation (at the cost of an increased likelihood that the
assumptions are violated; see Section \ref{sec:miss-temp-observ},
\ref{sec:observ-port-state}, \ref{human}).

In practice we also do not know the number of lagged observations that
are required for reconstruction of the state space at time $t$. One
approach is to use the data for guidance. This involves predicting the
effect at time $t+1$ with iteratively increasing numbers of lags. When
the addition of more time lags does not improve the prediction of
variables at time $t$, we have some confidence that the relevant
portions of state space at time $t$ has been reconstructed by the
lagged time series (e.g., we have defined the embedding dimension of
the attractor) \citep{Sugihara496}. However even this approach can be
problematic; while predictive power may plateau as we add more
temporal observations back in time, there are no guarantees that we
would not gain causally relevant knowledge from observations further
back in time. For example, a significant drought last year may impact
ecosystem state in the current year, but predictive power may locally
plateau going back in time two months (i.e. when the system exhibits
long and short term memory). This example highlights the challenges
associated with any method relying on state space reconstruction with
lagged observations: to be sure we reconstruct the state space we must
include observations from a potentially infinite temporal extent.

\subsection{Missing temporal observations induce independent random
  variations in cause and effect}
\label{sec:miss-temp-observ}

If we can assume that the missing temporal observations
(e.g. $S(t-1/2)$ in Figure \ref{fig:generic}a) induce independent
random variations in the cause and effect, conditional on $S(t-1)$,
then the causal graph reduces to Figure \ref{fig:generic}c. In this
case, if we can reconstruct the state space at time $t-1$ using lagged
observations at time t $\leq t-1$, then we can block all backdoor
paths between our cause $C(t)$ and any future effect $E(t+1)$. In this
case, the causal effect would be calculated as:

\begin{equation}
  P(E(t+1)| do(C(t)=c)) = \int_{S(t-1)} P(E(t+1) \, | \, C(t)=c,
  S(t-1) = s
  )\; P(S(t-1)=s) \, d s,
\end{equation}

where $S(t-1)$ is reconstructed from time lags of observations at
times $\leq t-1$. From the graph it may appear that we could also
block backdoor paths by conditioning on $S'(t)$. However, under these
assumptions $S'(t)$ is incalculable because if we attempt to
reconstruct $S'(t)$ using lagged observations of the state space, the
reconstruction will estimate $S$ rather than $S'$, which includes
$C(t)$ because $C$ is a part of the state space. So, our cause will be
shadowed by our reconstruction of the state space and our causal
effect will be biased.

The assumption that missing temporal observations induce independent
random variations in the cause and effect is required because
otherwise there would be an open backdoor path between the cause and
effect through the unobserved time slice (e.g. at time
($t-1/2$)). Relative to Section \ref{sec:stat-reconstr-state}, the
advantage of this approach to causal inference is that we can
calculate the causal effects of individual observations (e.g. soil
moisture), rather than needing to interpret the causal impact of the
entire state holistically. However, this approach requires an
additional assumption that the missing temporal observations do not
induce dependencies between the cause and effect of interest. As with
Section \ref{sec:stat-reconstr-state}, we must be able to reconstruct
the state space, which may not always be possible, and may also
confuse interpretation.


\subsection{The unobserved portion of the state space does not affect
  the cause}
\label{sec:observ-port-state}

If we assume that we observe all portions of the state space that
affect the effect, then we can calculate the effect of any state
variable on future processes. In this case, the graph is as in Figure
\ref{fig:generic}c, but $S'(t)$ correspondes to all observations at
time $t$ not including $C$, and so can be used to block all backdoor
paths. If we can assume that there are no interactions between
observations at time $t$ then we can calculate the causal effect as:

\begin{equation}
  P(E(t+1)| do(C(t)=c)) = \int_{S'(t)} P(E(t+1) \, | \, C(t)=c,
  S'(t) = o
  )\; P(S'(t-1)=o) \, d \, o,
\end{equation}

where $S'(t)$ are all observations at time $t$, not including the
cause $C(t)$. Whether or not there are interactions between
observations at time $t$ is a function of the temporal and spatial
extent of the observations. If observations are instantaneous point
observations indexed in time, then interactions between them can
likely be ignored. However, often the spatial and/or temporal extents
of observations overlap, and in this case an assumption of zero
interactions between observations is not justified. In this case, we
can still block backdoor paths by conditioning on past observations
($S(t-1)$):

\begin{equation}
  P(E(t+1)| do(C(t)=c)) = \int_{S(t-1)} P(E(t+1) \, | \, C(t)=c,
  S(t-1) = o
  )\; P(S(t-1)=o) \, d \, o.
\end{equation}

The assumption that we observe all variables relevant to an effect is
a strong assumption. However, it provides significant benefits both in
terms of the statistical complexity of estimating the causal effect,
as well as in interpretation of the causal effect. We do not need to
reconstruct the state space  using lagged observations, which can be a
statistically and computationally challenging problem. Additionally,
the assumption that we observe everything relevant to the effect is
much easier to interpret relative to an assumption about the degree to
which we can (or cannot) reconstruct the relevant state space with
lagged observations.

\subsection{Applications at the human-Earth system interface: when the
  cause is approximately independent of the system}
\label{human}

Causal inference becomes substantially more tractable under an
assumption that our causes of interest are independent from the
evolution of the state space (Figure \ref{fig:forcing}). While the
Earth system certainly affects all processes on Earth, historically
some processes are approximately decoupled from the Earth system's
state, paricularly at the human-climate interface. For example, recent
human history demonstrates that global human actions are relatively
independent of the climate state \citep{arto2014drivers}. That is, we
have failed to reduce green house gas emissions even as global
temperature increased. Instances of reduced rises in global green
house gas emissions are usually due to global economic recession
(e.g. the 2008 financial crisis) rather than factors directly tied to
the climate state. In this example many global social, political and
economic factors are the primary causes of global green house gas
emission, and while the climate system may effect these factors, the
historical evidence suggests that the climate system exerts a
relatively small impact (with tragic consequences)
\citep{arto2014drivers}.

\begin{figure}
  \includegraphics[]{forcing-graph.pdf}
  \caption{A generic graph asserting an assumption that there are
    forcing external to the evolution of the state-space}
  \label{fig:forcing}
\end{figure}

Generally this logic applies to many scenarios on the "human-climate"
interface, such as land-use land-cover change in urban centers where
urban planning is relatively independent of recent climate
history. The general graph in Figure \ref{fig:forcing} is
representative of many such scenarios at the human-climate interface,
and because the state space does not affect the cause, there are no
unblocked backdoor paths through the unobserved portions of the state
space. Causal inference is particularly tractable for this class of
problems.


\section{Discussion}

To summarize:

\begin{itemize}
\item Causal inference from data is a new tool with the potential to
  complement traditional scientific methods, including numerical and
  real world experimentation. In Earth science, numerical models rely
  on approximations that deviate their behavior from reality, and real
  world experimentation may be intractable or unethical. Causal
  inference is a third tool to calculate the effects of physical
  processes that has a different set of advantages and
  disadvantages, and is a powerful complement to numerical and real
  world experimentation.
\item Causal graphs concisely and clearly encode assumptions about
  causal dependencies between processes. Including a causal graph
  benefits any observational analysis, but particularly those that use
  regression. Depending on the observations available and the causal
  structure of the system, regression analyses can be interpreted as
  an average causal effect.
\item Whether or not a causal effect can be calculated from data is
  determined exclusively by the causal graph. Thus the tractability of
  a causal analyses, or the strength of assumptions necessary to make
  an analysis tractable, is determined and assessed before touching
  data (which can be a significant time sink).
\item Because the Earth system evolves as a dynamical system through
  time, we can construction generic Earth system causal graphs
  applicable to a wide range of scenarios. However, causal inference
  in Earth science also presents challenges: we only partially observe
  the state space of the system, so we must reconstruct the full state
  space using time lagged observations or make strong assumptions
  about the independence of processes from the unobserved portions of
  the state space.
\item We apply causal theory to generic causal graphs of the Earth
  system to identify the assumptions necessary for causal inference
  from data. These are assumption that:
  \begin{itemize}
  \item The state space of the system is reconstructable
    from lagged observations of the system, as allowed by
    Takens' theorem (Section \ref{sec:stat-reconstr-state}, Section \ref{sec:miss-temp-observ}), or
  \item The effect of interest is only causally
    affected by the observed portion of the state space (Section
    \ref{sec:observ-port-state}), or
  \item The cause of interest can be assumed to be independent of the
    evolution of the system's state (e.g. forcing) (Section
    \ref{human}).
  \end{itemize}
\end{itemize}

Here we focus on the fundamentals of calculating causal effects from
data. However, causal inference is a thriving active area of
research, and there are many other causal inference techniques and
abstractions that would benefit the Earth system research
community. For example, there are techniques for representing
variables observed under selection bias in the causal graph, and
analyzing whether a causal effect can be calculated (e.g. identified)
given the selection bias
\citep[e.g.,][]{bareinboim2014recovering}. Selection bias is very
relevant, for example satellite observations are almost always
collected under selection bias (e.g. only certain times of day, clouds
obscure surface data, etc.). Additionally, transportability
\citep[e.g.,][]{bareinboim2012transportability} identifies whether one
can calculate a causal effect in a passively observed target domain,
by merging experiments from source domains that may differ from the
target domain. We are currently working to formally transport global
Earth system model experiments to the real world, where numerical
models are the source domains that differ from the target domain
(``real world'') due to approximations \citep[][in
prep]{massmann}. Given the limitations of explicit experiments in
Earth science, we hope that causal methods gain wider adoption in
Earth science and that this manuscript provides the necessary
foundation for proper application of causal inference in Earth
science.

\bibliography{references.bib}

\end{document}