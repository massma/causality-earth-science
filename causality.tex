\documentclass[12pt]{article}
\input{def}

\begin{document}

\title{Causal inference in earth science}

\author{Adam Massmann\thanks{Corresponding author: akm2203@columbia.edu}}

\maketitle

\section{Introduction}

Controlled experimentation is the traditional path to scientific
discovery. A scientist designs controlled experiments where parameters
are systematically varied to test hypotheses about a system's
nature. Climate and earth system scientists primarily use numerical
models for experimentation \citep[e.g.,][]{eyring-cmip6-2016}, but
real world experiment is also used to a lesser degree
\citep[e.g.,][]{ainsworth-face-2005}. However, it may be logisically
impossible or unethical to execute many real world experiments, and
numerical experiments may rely on approximations that bias
experimental results realtive to the real world
\citep[e.g.,][]{kim-cmip5,stillmann-cmip5-extremes}. Are these the
only tools available for \textit{do}-ing experiments?
\citet{pearl-1994-do-calculus} introduced \textit{do-}calculus for
calculating the causal effects of experimenatal interventions based on
passive observations of a system and assumptions about causal
dependencies in the system. This is a powerful tool for earth
scientists that complements numerical experimentation due to a
completely orthogonal set of strengths, weaknesses, and assumptions.

However, causal inference from data presents its own challenges; the
causal effect must be identifiable from assumptions about the causal
dependencies of variables in the system, and the available
observations. If a causal effect is determined to be unidentifiable,
then it is impossible to calculate the causal effect of interest, even
with an infinite sample of data \citep[][]{shpitser2006}. Specific to
problems in earth science, the identification of causal effects is
challenging given two fundamental properties of many generic earth
science problems: the system evolves through time according to an
underlying dynamical system, and we only ever partially observe the
state space of that dynamical system \citep{majda-state}. Using graph
theory developed in \citep{pearl1995causal} we determine the generic
problems causal inference is justified for, and the necessary
assumptions for applying causal inference. There is the potential for
applying causal inference in two scenarios: (1) under an assumption
that the cause is independent of the system's state space (e.g. at the
human-climate interface, anthropogenic green house gas emission, land
use change) (Section \ref{human}); or (2) under certain conditions
where we can estimate the state space of the system from time lagged
observations (Section \ref{state-space}).  Our theoretical results
identifying tractable problems in earth science require a few
fundamentals from the causal inference literature, so we introduce
causal inference theory, causal graphs, and \citet{pearl2009}'s
\textit{do-}calculus for the unfamiliar reader (Section
\ref{sec:causal-graphs-pearls}), and compare with recent earth science
literature on the related field of causal discovery (Section
\ref{sec:discovery}). Causal effects, due to their underlying logic
and clear interpretation, are an exciting tool for scientific
discovery and understanding \citep{hannart-da,naveau-2020}. This
manuscript establishes the conditions required for the proper
application of causal inference in earth science.

\section{Causal graphs and Pearl's do calculus}
\label{sec:causal-graphs-pearls}
% intro causal graphs}

Causal graphs, introduced in \citep{pearl1995causal}, are directed
acyclic graphs (DAGs) that encode our assumptions about the causal
dependencies of a system. One draws directed edges (e.g. arrows) from
variables that are causes to effects. We will demonstrate causal
graphs with a simplified toy example examining clouds, aerosols, and
surface solar radiation (Figure \ref{fig:toy}). The causal graph
consists of:

\begin{figure}
  % consider \noindent\include... [width=0.75\textwidth]...
  \includegraphics[height=0.4\textheight]{./cloud-aerosol.pdf}\\
  \caption{A relatable toy example to demonstrate basic causal theory.}
  \label{fig:toy}
\end{figure}

\begin{enumerate}
\item An edge from aerosols to clouds because aerosols serve as cloud
  condensation nuclei.
\item An edge from aerosols to surface solar radiation, because
  aerosols can reflect sunlight back to space and reduce sunlight
  at the surface.
\item An edge from clouds to surface solar radiation, because clouds
  also reflect sunlight back to space and can reduce sunlight at
  the surface.
\end{enumerate}

Causal graphs encode our assumptions about how the system behaves, and
the nodes and edges that are \textit{missing} from the graph often
represent strong assumptions. For example, in the
cloud-aerosol-sunlight example, clouds also affect aerosols; e.g. by
increasing the likelihood that aerosol will be scoured from the
atmosphere during precipitation. By not including an edge from cloud
to aerosol, we are making a strong assumption that we are ignoring the
effect of clouds on aerosols. Considering this example is intended to
be pedagogical for introducing causal theory to the readers, we will
continue with the graph as drawn in Figure \ref{fig:toy} (Section
\ref{state-space} explores realistic earth system graphs). Causal
graphs are very useful tools because they can be drawn by any domain
expert with no required knowledge of math or probability, but they
also represent formal mathematical objects with a very specific
meanings. For example, as a general probabilistic graphical model, the
graph in Figure \ref{fig:toy} represents a specific factorization of
the joint distribution:

\begin{equation}
  P(cloud, aerosol, rad) = P(rad | cloud, aerosol) \, P(cloud |
  aerosol) \,
  P(aerosol)
\end{equation}

Interpreted causally, as in \citet{pearl1995causal} and this
manuscript, the directed edges encode causal dependencies in addition
to a factorization of the joint. More specifically, interpretted
causally, the graph represents the assumed Structural Causal Model
\citet[SCM,][]{pearl2009}, which is the set of functions that
determines how variables are generated. Each variable in the graph is
determined by a function with inputs corresponding to inward edges of
the variable of interest, as well as randomness due to the variables
not included in the causal graph (``exogenous variables'').  In the
cloud-aerosol-radiation example,

\begin{equation}
  SCM =
  \begin{cases}
    f_{aerosol} &: U_{aerosol} \\
    f_{cloud} &: aerosol, U_{cloud}  \\
    f_{radiation} &: aerosol, cloud, U_{radiation}
  \end{cases}
  \label{eq:1}
\end{equation}

The SCM asserts that each variable is generated from a deterministic
function. The randomness is due to exogonous variables ($U$) that
represent all the factors not represented explicitly in the SCM and
corrresponding causal graph. For example, sources of aerosol
variability not considered include anthropogenic aerosol release,
biosphere plant release, fires, volcanoes, etc. For cloud, this
includes synoptic forcing, moisture content, etc. For radiation, this
includes variability of top of atmosphere radiation, etc. For the
causal graph, as drawn, we assume that all of these sources of
randomness are idnependent of each other. That is, $U_{aerosol}$,
$U_{cloud}$, and $U_{radiation}$ are independent of each other. These
$U$ variables are powerful tools: by positing an SCM and causal graph,
we are not stating that the variables in the graph are the only
processes in the system. Instead, we are stating that all other
processes not included the graph induce variations in the causal
variables that are uncorrelated with each other. In some scenarios,
this assumption may be unreasonable and we would need to encode
correlations between $U$ terms; that is, co-variability induced
between variables due to exogenous processes. This can be encoded in
the graph as a bi-directed dashed edge between two variables with the
statistical depedence induced by exogenous processes. For example, if
aerosol in Figure \ref{fig:toy} were istead considered to be
exogenous, we would represen the graph instead as in Figure
\ref{fig:bi-directed}, and the corresponding SCM would be:

\begin{figure}
  \includegraphics[]{bidirected.pdf}
  \caption{A graph equivalent to Figure \ref{fig:toy}, but under an
    assumption that aerosol, a source of variability in both cloud and
    surface radation, is exogenous. In this case, there is a dependency
    between the randomness of cloud and radiation.}
  \label{fig:bi-directed}
\end{figure}

\begin{equation}
  SCM =
  \begin{cases}
    f_{cloud} &: U_{cloud,radiation}  \\
    f_{radiation} &: cloud, U_{cloud,radiation}
  \end{cases},
  \label{eq:2}
\end{equation}

where cloud and radiation now share an exogenous term.

\textit{/discuss barienboim's notation (which I do not like) of
  including and representing exogoneous variation that affects
  multiple variables with a dashed line? not as applicable for earth
  science, where I *think* we have a general idea of the main players
  (e.g. state), and how they relate to each other. I prefer to
  represent these instead as unobservable $V$ than $U$. However, show
  it in this example by just saying, if we did not include aerosol as
  an endogenous variable  we would just represent that as a
  bi-directed dashed arrow from $V$ to $U$./}

We can apply causal graph theory
\citep[e.g.,][]{pearl1995causal,shpitser2006} to the assumptions
encoded in our graph to identify which distributions we must estimate
from data in order to calculate a causal effect of interest. This
process of identifying the necessary distributions is formally termed
\emph{causal identification}. If a causal effect is not identifiable
(\emph{un}-identifiable), for example if calculating a causal effect
requires distributions of variables that we do not observe, then we
cannot use causal inference to calculate a causal effect, even with an
infinite sample of data.

% backdoor path}

A necessary condition for unidentifiability is the presence of an
unblocked backdoor path from cause to effect. Backdoor paths are any
paths going through parents of the cause to the effect. We can block
these paths by selectively observing variables such that no
information passes through them \citep{geiger-d-sep}. If we can
observe variables such that backdoor paths are blocked, then we have
satisfied the \emph{back-door criterion} \citep{pearl2009} and we can
calculate unbiased causal effects from data.

\begin{figure}
  \noindent\includegraphics[]{./mutilated-cloud-aerosol.pdf}\\
  \caption{A mutilation of Figure \ref{fig:toy}, where we have removed
    directed causal paths from the cause (cloud) to the effect (surface
    solar radiation). We can see that there is covariability between
    cloud and surface solar radiation in the data, that is not
    explained by a causal connection between cloud and surface solar
    radiation, but instead is because of induced co-variability caused
    by aerosol.}
  \label{fig:mutilated-toy}
\end{figure}

% backdoor path with example}
Understanding backdoor paths and the backdoor criterion is helped by
example. Returning to our toy example (Figure \ref{fig:toy}), we will
attempt to calculate the causal effect of clouds on sunlight. In other
words, we want to isolate the variability of sunlight due to the
causal link from cloud to sunlight. However, aerosols both affect
cloud (edge from aerosol to cloud), and sunlight, so if we naively
calculate a causal effect we would get a biased estimate of the mean
causal effect of cloud on sunlight. To demonstrate, consider generated
data where the ``true'' SCM is:

\begin{equation}
  SCM =
  \begin{cases}
    f_{aerosol} &: U_{aerosol} \sim \text{uniform (0, 1]}\\
    f_{cloud} &: Cloudy | Clear \sim \text{bernoulli(aerosol)}     \\
    f_{radiation} &: \begin{cases}
      Cloudy &: 0.6 \cdot \text{clear sky radiation}  \\
      Clear &: \text{clear sky radiation}
    \end{cases}
  \end{cases}
\end{equation}

where:

\begin{equation*}
  \text{clear sky radiation} = U_{aerosol} \cdot (1 - aerosol); \;
  U_{aerosol} \sim \text{Normal(340, 30)}
\end{equation*}

Now, consider not knowing the underlying SCM, but just receiving
passive data of cloud and sunlight data. If one were interested in
calculating the effect of cloud on sunlight, and aerosol data were not
available or one where very naive, an approach would be to bin the
data by cloudy and clear conditions, and comapre the amount of
sunlight in each type of observation (Figure
\ref{fig:naive-cloud-sunlight}). This approach suggests that clouds
reduce sunlight by, on average, 160 W m$^{-2}$, which is a massive
overestimation of the true average effect of clouds derived from the
SCM, which is -68 W m$^{-2}$. Aerosol induces co-variability between
cloud and aerosol that has nothing to do with the causal link from
cloud to aerosol. Graphically, this is clairied by removing all edges
from our cause (cloud) to children of our cause (in this case
sunlight) (Figure \ref{fig:mutilated-toy}). We see that cloud is not
independent of surface solar radiation in the mutilated graph.  How
would we make cloud and sunlight independent in this mutilated graph?
In this case, by observing aerosol. In other words, with aerosol
fixed, any covariability between cloud and surface solar radiation is
due to the causal path between cloud and surface solar radiation
(Figure \ref{fig:toy}).  Mathematically, the identification of the
causal effect of cloud and aerosol according to the backdoor criterion
is:

\begin{figure}
  \includegraphics[]{naiveCloudSunlight.pdf}
  \caption{A naive approach to estimating the ``effect'' of clouds on
    sunlight: bin observations by cloudy and clear day, and compare
    the values of sunlight. This approach yields a massive
    overestimation of the true causal effect of clouds on sunlight,
    which is -68.0 W m$^{-2}$}
  \label{fig:naive-cloud-sunlight}
\end{figure}

\begin{equation}
  P(sunlight | do(cloud = c)) = \int_{aerosol} P(sunlight| cloud = c,
  aerosol) P(aerosols) \, d aerosol,
  \label{eq:3}
\end{equation}

where the \textit{do}-calculus \citep{pearl2009} term
($P(sunlight \, | \, do(cloud\, = \,c))$) represents the probability of
sunlight if we did an experiment where we intervened and set cloud to
a value of our choosing (in this case $c$). In the case that
observations of aerosols are not available, our causal effect is not
identifiable and we cannot use causal inference no matter how large
the sample sizes of clouds and aerosols. This theory is an elegant
tool: without having to touch data or estimate marginal or conditional
distributions, we can determine whether it is possible to calculate a
causal effect of interest, given the available observations and our
assumptions about the causal dependencies in the system. We later use
this theory to theoretically assess which general problems are
tractable in earth science using causal inference (Section
\ref{sec:necess-cond-caus}).

Often it may be more computationally tractable to calculate an average
causal effect, rather than the full causal distribution
$P(sunlight | do(cloud))$. Returning to our toy example (Figure
\ref{fig:toy}), the average effect is defined as:

\begin{equation}
  \mathbb{E}(S | do(C = c)) = \int_{s} s \, P(S = s
  | do(C=c)) \, ds,
  \label{eq:4}
\end{equation}

where we have introduced the shorthand $S$ for solar radiation, $C$
for cloud, and $A$ for aerosol. Substituting Equation (\ref{eq:3})
into Equation (\ref{eq:4}) rearranging gives:

\begin{equation}
  \mathbb{E}(S | do(C = c))  = \int_{a} P(A=a) \, \mathbb{E}(S=s |
  C=c, A=a),
  \label{eq:5}
\end{equation}

Where $\mathbb{E}(S=s | C=c, A=a)$ is just a regression of sunlight on
cloud and aerosol. Estimating the marginal $P(A=a)$ is difficult, but
if we assume that our observations are independent and identically
distributed (IID) and we have a large enough sample, we can use the
law of large numbers to approximate Equation (\ref{eq:5}) with:

\begin{equation}
  \mathbb{E}(S | do(C = c))  = \frac{1}{n} \sum_{i=1}^n \mathbb{E}(S=s_i |
  C=c, A=a_i).
  \label{eq:6}
\end{equation}

Data or aprior knowledge can inform the regression function for
$\mathbb{E}(S=s_i | C=c, A=a_i)$. In the toy example, a linear model,
conditional on $cloud$, appears to be a good choice of regression
function (Figure \ref{fig:linear}). The causal effect of clouds ons
unlight as calculated using Equation (\ref{eq:6})) (e.g.
$\mathbb{E}(S | do(C = 1)) - \mathbb{E}(S | do(C = 0))$) is -68.52 W
m$^{-2}$, which closely matches the true causal effect from the SCM of
-68 W m$^{-2}$.

In summary of the main points of this introduction to causal graphical
models, structural causal models, and \textit{do-}calculus:

\begin{itemize}
\item Graphical causal models encode our assumptions about causal
  dependencies in a system (edges are drawn \emph{from} causes
  \emph{to} effects).
\item Each graphical causal model corresponds to a structural causal
  model, which are a set of functions that map causes and random
  variations to effects.
\item In order to calculate an unbiased causal effect from data, we
  must remove all covariability between our cause and effect that is
  not due to the directed causal path from cause to effect. The
  presence of non-causal covariation between the cause and effect
  can be deduced from the causal graph: the presence of a backdoor
  path from the cause to the effect leads to non-causal covariation.
\item The backdoor criterion identifies the distributions we must
  calculate from data in order to block a backdoor path, remove
  non-causal covariability between the cause and effect, and
  calculate an unbiased causal effect from data.
\item The \emph{average} causal effect can be reliably approximated
  with regression (Equation (\ref{eq:6})) derived from the backdoor
  criterion. In this scenario, causal theory and graphs identify the
  variables that should (and should not be) included in the
  regression to calculate an unbiased causal effect.
\item Causal identification is a flexible tool that provides the
  distributions that must be estimated by data, while making to
  assumptions about the forms of those distribution. However,
  parametric assumptions can be applied to make the calculation of
  those distributions from data more computationally tractable.
\end{itemize}

\begin{figure}
  \includegraphics[]{aerosolSunlight.pdf}
  \caption{A linear relationship between aerosol and sunlight,
    conditional on cloud. If we use linear regression to calculate the
    average causal effect of cloud on sunlight, as in Equation
    (\ref{eq:6}), our result is very close to the true causal effect
    of -68.0 W m$^{-2}$.}
  \label{fig:linear}
\end{figure}

Here we focused on the backdoor criterion to block backdoor paths. An
un-blockable backdoor path from the cause to the effect is a necessary
condition for un-unidentifiability. However, it is not sufficient
(e.g. there are other identification strategies like the front door
criterion, and instrumental variables). For a complete discussion of
sufficient conditions for un-unidentifiability we refer you to
\citet{shpitser2006}. For the purpose of identifying generally
tractable causal inference approaches in earth science (Section
\ref{sec:necess-cond-caus}), we focus the backdoor criterion. Given
that the earth system evolves continuously according to an underlying
dynamical system, and that we only partially observe the state space
(Section \ref{state-space}), these other identification strategies are
not applicable, and an unblockable backdoor path is a sufficient
condition for un-unidentifiability in the types of graphs that are
representative of earth science systems (Figure \ref{fig:generic}).

\textit{/TODO: need to formally prove this or adjust language/}

\subsection{Clarification on terminology and relationship to literature on causal discovery}
\label{sec:discovery}
% causal discovery = infering causal graph from data}
The term ``causal inference'' has been used to describe two
techniques:

\begin{enumerate}
\item \textbf{Causal effect inference}: Calculating the causal effect
  of some processes on other, given data and assumptions about the
  causal structure of the system.
\item \textbf{Causal structure discovery}: Inferring the causal
  structure (e.g. the causal graph) of the system using data.
\end{enumerate}

This paper focuses on causal inference as (1): calculating causal
effects from data. Inferring the causal structure of the system (2),
is generally much more difficult and requires more
assumptions. However, there are other reasons to focus on (1) rather
than (2) in earth science: often in earth science we know or have a
strong a priori belief about the causal graph of our system. For
example, in the climate system we can identify the state variables and
the state at time \(t\) determines the state at time \(t+1\), even if
the exact functional form of the dependency through time is not
known. Therefore, we can write down a causal graph and do not need to
infer graph structure from data (Section \ref{sec:necess-cond-caus}).

\textit{/ TODO: tactfully critique causal discovery. a messy start is
  here:}

\textit{
  However, there has been considerable work and effort in applying
  causal structure discovery (2) in earth science
  \citep[e.g.,][]{ebert-uphoff2012,
    samarasinghe-casuality,runge-causal-timeseries,runge2019inferring}. A
  common application and motivation of these efforts is to filter and
  ignore causal links in the system through structure discovery. The
  ignored links are a function of the significance parameters used in
  the causal discovery algorithms. Causal inference of effects, as we
  explore here, represents a different approach where we do not rely on
  assumptions about the significance of effects, but instead make
  explicit assumptions about the causal structure of the system. To
  reiterate, given our domain knowledge of the earth science system we
  generally have high confidence about the causal structure of the
  system, and as we will see (Section \ref{sec:necess-cond-caus}) we can
  construct quite general graphs that are faithful to our knowledge
  about how dynamical systems evolve. It is possible some links in these
  graphs correspond to small effects, and these links would be removed
  through causal structure discovery. However, directly interpreting
  what constitutes a ``negligibly small'' effect calculation presented in
  physical units and probabilities, as calculated with causal effect
  inference, may be more transparent than interpreting missing links
  derived from causal structure discovery significance parameters. In
  other words, direct calculation of effects may be more transparent and
  interpretable for many readers, relative to a causal graph derived
  from significance parameters with more abstract meaning. We hope to
  motivate further research effort in causal effect inference to match
  recent efforts in causal structure discovery. Ideally causal effect
  inference and causal structure discovery will co-evolve as
  complementary abstractions for causal interpretation; researchers and
  readers can choose the method that suits their assumptions and
  needs./}

\textit{
  TODO: talk to Elias about ``no mixing'' theorem; from what he
  described it seems like it leads to the invalidation of ``causal
  discovery''
}
\section{Necessary conditions for causal identification in the earth
  systems}
\label{sec:necess-cond-caus}
\subsection{Causal identification when the state space is estimable}
\label{state-space}

Earth science systems are stochastic dynamical system evolving through
time according to an underlying state state \citep{majda-state}. This
offers both advantages and challenges for causal inference. Challenges
involve estimating the state space from observations, while advantages
include the temporal ordering of events; we know that future events
can have no causal effect on the past.

First we consider a generic scenario in a simple temporal system with
no spatial component, where we are interested in the causal effect of
$C(t)$ on $E(t+1)$, where $C$ and $E$ are processes within the larger
system's \textit{observed} state $S$. Note that in general we do not
fully observe the state of the system, so there will also be an
unobserved portion of the state space $U$. We denote the portion of
the observed state space excluding $C$ and $E$ as $S'$. $S'(t)$,
$U(t)$, $C(t)$ and $E(t)$ all affect $S'(t+1)$, $U(t+1)$, $C(t+1)$,
and $E(t+1)$ (Figure \ref{fig:generic}). In order to calculate the
causal effect of $C(t)$ on $E(t+1)$, we must block all back door paths
from $C(t)$ to $E(t+1)$. In this generic scenario, this involves
conditioning on $S'(t)$, $U(t)$, and $E(t)$:

\begin{figure}
  \includegraphics[]{./generic-graph.pdf}
  \caption{A generic graph of the earth system sequence, limited to a
    3 time sequence subset of the infinite sequence. $S$ and $U$ refer
    to the observed and unobserved portions of the state space,
    respectively.  At time steps $t$ and $t+1$ the observed portion
    of the state space is broken up into three events: $C$, $E$, and
    $S'(t)$, which is all parts of $S$ excluding $C$ and $E$. $C$ is a
    generic portion of the state space we are interested in as a cause, and $E$ is
    a generic portion of the state space we are interested in as an effect.}
  \label{fig:generic}
\end{figure}

\begin{equation}
  \label{naive}
  P(E(t+1)| do(C(t))) = \int_{S'(t)} \int_{U(t)} \int_{E(t)}  P(E(t+1) | C(t), S'(t),
  U(t), E(t)) \; P(E(t)) \; P(U(t)) \; P(S'(t))
\end{equation}

However, we do not observe $U(t)$, and cannot block the path through $U(t)$. We may,
however, be able to estimate $U(t)$ by leveraging Takens's theorem and
using lagged observations of the partial state space, going back in
time (e.g. $S(t-1)$, $S(t-2)$, etc.). In this application, this
approach presents problems. The reconstruction will estimate $S$
rather than $S'$, which includes $C(t)$ because $C$ is a part of the
state space. Fortunately, we can also block backdoor paths by
conditioning on $S(t-1)$ and $U(t-1)$. If we reconstruct $U(t-1)$
using lagged observations of $S$ before $t-1$, we can block backdoor
paths and calculate a causal effect. So, the more tractable approach
to blocking backdoor paths in the earth system, where we only ever
partially observe the state space, is:

\begin{equation}
  \label{ce}
  P(E(t+1)| do(C(t))) = \int_{S(t-1)} \int_{U(t-1)} P(E(t+1) | C(t), S(t-1),
  U(t-1)) \; P(U(t-1)) \; P(S(t-1)),
\end{equation}

where $U(t-1)$ is statistically reconstructed using lagged
observations of the state space $S(t')$, where
$t' \in \{-\infty, t-2\}$ (justified by Takens's theorem).

To extend this result on a purely temporal dynamical system to a
spatio-temporal system, we apply the concept of lightcones
\citep{PhysRevLett.84.1890,
  montanez2015licors,doi:10.1063/1.5021130}. Lightcones leverage our
general knowledge or assumptions about the speed with the influence of
events can propagate through the system. For a general physical
system, an upper limit on the propagation speed is the speed of
light. For the atmosphere, a useful upper limit is the speed of
sound. However, in many scenarios (e.g. if we do not care about the
effect of soundwaves), we can use a more reasonable speed of
propagation like the advection (wind) speed, or the phase/group speed
of gravity waves. The propagation speed of the system constrains
portions of the state space that can affect an event at a given time
and spatial extent. The past lightcones are the set of all events in a
spatiotemporal system that can \textit{affect} a single event at a
given location and time. The future lightcones are the set of all
events in a spatiotemporal system that are \textit{affected by} an
event at a given location and time. Formally, the past lightcone
($L^-$) is the set of all events defined by:

\begin{equation}
  L^-(r,t) \equiv \left\{ X_{t'}^{r'} \, : \, t' \leq t \text{ and }
    ||r'-r|| \leq c(t-t')\right\},
\end{equation},

where $c$ is the propagation speed. The future lightcone is defined
similarly:

\begin{equation}
  L^+(r,t) \equiv \left\{ X_{t'}^{r'} \, : \, t' \geq t \text{ and }
    ||r'-r|| \leq c(t'-t) \right\}
\end{equation}.

We can use the past lightcones of our cause and out effect to
determine the spatio-temporal locations over which we must $S(t-1)$ to
block backdoor paths.

An example will aid visualizing lightcones (Figure
\ref{fig:lightcone}), and their consequences for causal
inference. Consider a scenario where half-hourly observations are
available, we assume the propagation speed is $25 m/s$, and that we
are interested in the affect of $C(x=0 \, m, y=0 \, m, t=0 \, hr)$ on
$E(x=0 \, m, y=0 \, m , t=0.5 \, hr)$. In this case, we would need to
estimate $S(t=-0.5 \, hr)$, over all locations that could affect
\emph{both} $C(0,0,0)$ and $E(0,0,0.5)$.  For a propagation speed of
$25 m/s$, this requires estimating the state over a circular area
centered at $x=0$, $y=0$, and with a radius
$25 \, m/s \cdot 1800 \, s = $ 45 \, km (Figure
\ref{fig:lightcone}). However, because we only partially observe the
state space, we must use lagged observations going back in time,
including all observations of events within the intersection of the
past lightcones of the cause and effect. For example, at $-1$ hours
our circular radius would be 90 km, at $-1.5$ hr: 135 km (Figure
\ref{fig:lightcone}), and at $-2$ hr: 180 km. As one can observe, the
problem because statistically and computationally harder the more lags
that are required to estimate are state space. If the number of lags
in inversely proportional to the observational coverage of the state
space, the value of earth system observations becomes apparent. A
software package that automatically identifies the spatiotemporal
extent over which the state space must be estimated to block backdoor
paths for a given cause and effect is available at
\url{https://github.com/massma/spacetime-causality}.

\begin{figure}
  \includegraphics[width=0.75\textwidth]{./lightcone.pdf}
  \caption{A graphical aid to understanding lightcones in a two
    dimensional system. Given a maximum propagation speed in our
    system of 25 m/s, the circles depict the areas that may affect
    both the cause and the effect at time $t=-0.5 \, hr$,
    $t=-1.0 \, hr$, and $t=-1.5 \, hr$. In order to block back door
    paths in a spatiotemporal system, we would need to condition on
    the state space over these areas.}
  \label{fig:lightcone}
\end{figure}

In practice we do not know the number of lagged observations of the
state space that are required for reconstruction at time $t-1$. One
approach is to use the data for guidance. This involves predicting the
cause and the effect with iteratively increasing numbers of lags. When
the addition of more time lags does not improve the prediction of the
cause and effect, we have confidence that the relevant portions of
state space at time $t=t-1$ has been reconstructed by the time series.

\textit{/discuss the more holistic approach suggested by shalizi of
  looking at predictive state space reconstructions and examining the
  changes needed to change state?/}

\subsection{Applications at the human-earth system interface: when the
  cause is approximately independent of the system}
\label{human}

Causal inference becomes substantially more tractable under an
assumption that our causes of interest are independent from the
evolution of the state space (Figure \ref{fig:forcing}). While the
earth system certainly affects all processes on earth, in some cases
this may still be a reasonable assumption. For example, recent human
history demonstrates that global human actions are relatively
independent of the climate state \citep{arto2014drivers}. That is, we
have failed to reduce green house gas emissions even as global
temperature increased. Instances of reduced rises in global green
house gas emissions are usually due to global economic recession
(e.g. the 2008 financial crisis) rather than factors directly tied to
the climate state. In this example many global social, political and
economic factors are the primary causes of global green house gas
emission, and while the climate system may effect these factors, the
historical evidence suggests that the climate system exerts a
relatively small impact (with tragic consequences)
\citep{arto2014drivers}.

\emph{/discuss data problem? - we know
  don't observe the future of green house gas emissions/}.

\begin{figure}
  \includegraphics[]{./forcing-graph.pdf}
  \caption{A generic graph asserting an assumption that there are
    forcing external to the evolution of the state-space}
  \label{fig:forcing}
\end{figure}

Generally this logic applies to many scenarios on the "human-climate"
interface, such as land-use land-cover change in urban centers where
urban planning is relatively independent of recent climate
history. The general graph in Figure \ref{fig:forcing} is
representative of many such scenarios at the human-climate interface,
and because the state space does not affect the cause, there are no
unblocked backdoor paths through the unobserved portions of the state
space. Causal inference is particularly tractable for this class of
problems.

\section{Discussion}

\emph{TODO: expand these bullets into a full section}.

\emph{/and add discussion of the role of randomness vs predictive
  power, causes vs effects in an evolving state space system?/}

\begin{itemize}
\item Causal inference from data is a new tool with the potential to
  complement traditional scientific methods, including numerical and
  real world experimentation. In earth science, numerical models rely
  on approximations that deviate their behavior from reality, and real
  world experimentation may be intractable or unethical. Causal
  inference is a third tool to calculate the effects of physical
  processes that has a different set of advantages and
  disadvantages, and is a powerful complement to numerical and real
  world experimentation.
\item The characteristics of earth science systems offer advantages
  for causal inference: the temporal ordering of events and bounds on
  the propagation speed of information in the system allows us to
  filter which events that can affect a process, and identify the
  necessary portions of the state space we must condition on to block
  backdoor paths.
\item Applying causal inference to earth science systems also presents
  challenges: we only ever partially observe the state space of the
  system, so we must reconstruct the full state space using time
  lagged observations. This increases the computational and
  statistical complexity of the problem, and can make some application
  intractable.
\item Given these generic characteristics of earth science systems, we
  have identified two scenarios that meet the necessary conditions for
  applying causal inference:
  \begin{enumerate}
  \item The state space of the system is reconstructable
    from lagged observations of the system, as allowed by
    Takens's theorem, or
  \item The cause of interest can be assumed to be
    independent of the evolution of the system's state
    (e.g. forcing).
  \end{enumerate}
\end{itemize}

% /discuss transportability?/

% /discuss relationship of these ideas to causal discovery (critique
% causal discovery)?/

% /discuss issues with data available and observed range
% (e.g. generalization for cliamte research)?/

\bibliography{references.bib}

\end{document}